{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 22.593023\n",
      "5000 1.7591026\n",
      "10000 1.731347\n",
      "15000 1.7056246\n",
      "20000 1.681723\n",
      "25000 1.6594528\n",
      "30000 1.6386453\n",
      "35000 1.619153\n",
      "40000 1.6008465\n",
      "45000 1.5836114\n",
      "50000 1.567349\n",
      "55000 1.55197\n",
      "60000 1.5373961\n",
      "65000 1.5235587\n",
      "70000 1.5103952\n",
      "75000 1.4978535\n",
      "80000 1.4858799\n",
      "85000 1.474432\n",
      "90000 1.4634734\n",
      "95000 1.452965\n",
      "100000 1.4428719\n",
      "105000 1.4331706\n",
      "110000 1.4238315\n",
      "115000 1.4148316\n",
      "120000 1.4061475\n",
      "125000 1.3977574\n",
      "130000 1.3896511\n",
      "135000 1.3818041\n",
      "140000 1.3742036\n",
      "145000 1.3668319\n",
      "150000 1.3596853\n",
      "155000 1.3527404\n",
      "160000 1.3459913\n",
      "165000 1.3394413\n",
      "170000 1.3330376\n",
      "175000 1.3268324\n",
      "180000 1.3207583\n",
      "185000 1.3148744\n",
      "190000 1.3090965\n",
      "195000 1.3034729\n",
      "200000 1.2979835\n",
      "-----------------------------\n",
      "train_data =  86 test_data =  36\n",
      "[2] [1.0]\n",
      "[2] [2.0]\n",
      "[2] [3.0]\n",
      "[2] [2.0]\n",
      "[2] [2.0]\n",
      "[2] [2.0]\n",
      "[2] [2.0]\n",
      "[3] [3.0]\n",
      "[2] [2.0]\n",
      "[2] [2.0]\n",
      "[2] [2.0]\n",
      "[5] [5.0]\n",
      "[2] [3.0]\n",
      "[2] [3.0]\n",
      "[2] [3.0]\n",
      "[2] [3.0]\n",
      "[2] [3.0]\n",
      "[3] [4.0]\n",
      "[2] [3.0]\n",
      "[2] [2.0]\n",
      "[2] [3.0]\n",
      "[3] [4.0]\n",
      "[3] [4.0]\n",
      "[2] [3.0]\n",
      "[3] [5.0]\n",
      "[2] [3.0]\n",
      "[3] [4.0]\n",
      "[2] [3.0]\n",
      "[5] [5.0]\n",
      "[3] [5.0]\n",
      "[3] [5.0]\n",
      "[2] [2.0]\n",
      "[5] [5.0]\n",
      "[2] [2.0]\n",
      "[2] [2.0]\n",
      "[3] [3.0]\n",
      "[3] [4.0]\n",
      "[5] [6.0]\n",
      "[2] [2.0]\n",
      "[2] [2.0]\n",
      "[2] [1.0]\n",
      "[2] [2.0]\n",
      "[2] [1.0]\n",
      "[2] [2.0]\n",
      "[5] [6.0]\n",
      "[2] [2.0]\n",
      "[3] [5.0]\n",
      "[3] [3.0]\n",
      "[2] [3.0]\n",
      "[2] [0.0]\n",
      "[2] [1.0]\n",
      "[5] [5.0]\n",
      "[2] [0.0]\n",
      "[2] [0.0]\n",
      "[2] [0.0]\n",
      "[0] [0.0]\n",
      "[2] [3.0]\n",
      "[0] [0.0]\n",
      "[2] [0.0]\n",
      "[2] [2.0]\n",
      "[2] [1.0]\n",
      "[5] [5.0]\n",
      "[0] [0.0]\n",
      "[2] [0.0]\n",
      "[3] [4.0]\n",
      "[2] [1.0]\n",
      "[3] [4.0]\n",
      "[2] [3.0]\n",
      "[2] [2.0]\n",
      "[2] [3.0]\n",
      "[2] [2.0]\n",
      "[5] [6.0]\n",
      "[2] [2.0]\n",
      "[2] [3.0]\n",
      "[3] [4.0]\n",
      "[2] [2.0]\n",
      "[2] [2.0]\n",
      "[3] [4.0]\n",
      "[2] [2.0]\n",
      "[3] [4.0]\n",
      "[2] [2.0]\n",
      "[5] [6.0]\n",
      "[2] [1.0]\n",
      "[2] [2.0]\n",
      "[2] [2.0]\n",
      "[2] [1.0]\n",
      "accuracy =  44.18604651162791\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 모델 생성 위한 import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# 단파장 비율 학습 및 테스트 (편차 분포)\n",
    "\n",
    "import_data = np.genfromtxt('./../swr_ratio_classification_test.csv', delimiter=',', dtype='float')\n",
    "\n",
    "x_data = []\n",
    "for i in range(len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][0])\n",
    "    x_data.append(temp)\n",
    "    \n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# x_data = scaler.fit_transform(x_data)\n",
    "test_x = x_data[86:]\n",
    "x_data = x_data[:86]\n",
    "\n",
    "y_data = []\n",
    "test_y = []\n",
    "\n",
    "for i in range(86):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][1])\n",
    "    y_data.append(temp)\n",
    "\n",
    "raw_y = y_data\n",
    "    \n",
    "for i in range(86, len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][1])\n",
    "    test_y.append(temp)\n",
    "    \n",
    "# raw_y = y_data\n",
    "\n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 1])\n",
    "Y = tf.placeholder(\"float\", [None, 7])\n",
    "\n",
    "nb_classes = 7\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    accuracy = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(200001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 5000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "\n",
    "    print('-----------------------------')\n",
    "\n",
    "    print('train_data = ', len(x_data), 'test_data = ', len(test_x))\n",
    "\n",
    "    for i in range(len(x_data)):\n",
    "        a = sess.run(H, feed_dict={X:[x_data[i]]})\n",
    "        print(sess.run(tf.argmax(a, 1)), raw_y[i])\n",
    "        if(sess.run(tf.argmax(a, 1)) ==raw_y[i]):\n",
    "            accuracy += 1\n",
    "    print(\"accuracy = \", float(accuracy / len(raw_y) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5가지 클래스\n",
    "20만회 학습\n",
    "train_data 70.93%\n",
    "test_data 86.11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
