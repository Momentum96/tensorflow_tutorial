{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-19 5:52:00 5:52:00\n",
      "2018-04-19 19:52:00 19:52:00\n",
      "2018-04-19 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-21 5:49:00 5:49:00\n",
      "2018-04-21 19:49:00 19:49:00\n",
      "2018-04-21 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-26 5:43:00 5:43:00\n",
      "2018-04-26 19:43:00 19:43:00\n",
      "2018-04-26 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-27 5:42:00 5:42:00\n",
      "2018-04-27 19:42:00 19:42:00\n",
      "2018-04-27 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-28 5:41:00 5:41:00\n",
      "2018-04-28 19:41:00 19:41:00\n",
      "2018-04-28 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-29 5:40:00 5:40:00\n",
      "2018-04-29 19:40:00 19:40:00\n",
      "2018-04-29 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-30 5:38:00 5:38:00\n",
      "2018-04-30 19:38:00 19:38:00\n",
      "2018-04-30 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-04 5:34:00 5:34:00\n",
      "2018-05-04 19:34:00 19:34:00\n",
      "2018-05-04 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-05 5:33:00 5:33:00\n",
      "2018-05-05 19:33:00 19:33:00\n",
      "2018-05-05 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-08 5:30:00 5:30:00\n",
      "2018-05-08 19:30:00 19:30:00\n",
      "2018-05-08 828 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-10 5:28:00 5:28:00\n",
      "2018-05-10 19:28:00 19:28:00\n",
      "2018-05-10 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-14 5:24:00 5:24:00\n",
      "2018-05-14 19:24:00 19:24:00\n",
      "2018-05-14 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-19 5:20:00 5:20:00\n",
      "2018-05-19 19:20:00 19:20:00\n",
      "2018-05-19 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-21 5:19:00 5:19:00\n",
      "2018-05-21 19:19:00 19:19:00\n",
      "2018-05-21 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-24 5:17:00 5:17:00\n",
      "2018-05-24 19:17:00 19:17:00\n",
      "2018-05-24 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-25 5:17:00 5:17:00\n",
      "2018-05-25 19:17:00 19:17:00\n",
      "2018-05-25 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-26 5:16:00 5:16:00\n",
      "2018-05-26 19:16:00 19:16:00\n",
      "2018-05-26 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-27 5:16:00 5:16:00\n",
      "2018-05-27 19:16:00 19:16:00\n",
      "2018-05-27 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-28 5:15:00 5:15:00\n",
      "2018-05-28 19:15:00 19:15:00\n",
      "2018-05-28 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-29 5:15:00 5:15:00\n",
      "2018-05-29 19:15:00 19:15:00\n",
      "2018-05-29 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-30 5:14:00 5:14:00\n",
      "2018-05-30 19:14:00 19:14:00\n",
      "2018-05-30 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-31 5:14:00 5:14:00\n",
      "2018-05-31 19:14:00 19:14:00\n",
      "2018-05-31 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-01 5:13:00 5:13:00\n",
      "2018-06-01 19:13:00 19:13:00\n",
      "2018-06-01 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-02 5:13:00 5:13:00\n",
      "2018-06-02 19:13:00 19:13:00\n",
      "2018-06-02 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-03 5:13:00 5:13:00\n",
      "2018-06-03 19:13:00 19:13:00\n",
      "2018-06-03 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-05 5:12:00 5:12:00\n",
      "2018-06-05 19:12:00 19:12:00\n",
      "2018-06-05 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-06 5:12:00 5:12:00\n",
      "2018-06-06 19:12:00 19:12:00\n",
      "2018-06-06 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-07 5:12:00 5:12:00\n",
      "2018-06-07 19:12:00 19:12:00\n",
      "2018-06-07 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-08 5:12:00 5:12:00\n",
      "2018-06-08 19:12:00 19:12:00\n",
      "2018-06-08 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-09 5:11:00 5:11:00\n",
      "2018-06-09 19:11:00 19:11:00\n",
      "2018-06-09 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-11 5:11:00 5:11:00\n",
      "2018-06-11 19:11:00 19:11:00\n",
      "2018-06-11 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-13 5:11:00 5:11:00\n",
      "2018-06-13 19:11:00 19:11:00\n",
      "2018-06-13 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-16 5:11:00 5:11:00\n",
      "2018-06-16 19:11:00 19:11:00\n",
      "2018-06-16 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-17 5:11:00 5:11:00\n",
      "2018-06-17 19:11:00 19:11:00\n",
      "2018-06-17 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-18 5:11:00 5:11:00\n",
      "2018-06-18 19:11:00 19:11:00\n",
      "2018-06-18 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-24 5:13:00 5:13:00\n",
      "2018-06-24 19:13:00 19:13:00\n",
      "2018-06-24 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-25 5:13:00 5:13:00\n",
      "2018-06-25 19:13:00 19:13:00\n",
      "2018-06-25 828 data saved.\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 분별 날짜 파일에 있는 날짜 기준으로 DB에서 데이터 받아와서 저장하기\n",
    "\n",
    "import MySQLdb\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# MySQL DB 연결\n",
    "db = MySQLdb.connect('210.102.142.13',\"root\", \"witlab8*\", \"cas_db\")\n",
    "c = db.cursor()\n",
    "\n",
    "# 분별 날짜\n",
    "# date = np.genfromtxt('../data/date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "date = np.genfromtxt('../data/test_date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "\n",
    "# csv 파일로 내보내기\n",
    "# w = open('../data/db_connect_data_rnn.csv', 'w', encoding='utf-8')\n",
    "w = open('../data/db_connect_test_data_rnn.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "data_length = []\n",
    "\n",
    "# 각 날짜별 데이터들 DB에서 가져오고 csv 파일로 저장\n",
    "# 데이터는 cct, swr, uvb, uvi 순\n",
    "for j in range(len(date)):\n",
    "    sql = \"select time(date), date(date), cct, cas_swr from natural_tracker left outer join cas_wave_ratio using(date) where date(date) = '\"+ str(date[j][0]) + \"' order by time(date)\"\n",
    "    c.execute(sql)\n",
    "    rows = c.fetchall()\n",
    "    \n",
    "    # 일출 후 6시간과 일몰 후 6시간 데이터 사용, 일출 혹은 일몰 당시 데이터가 없을 경우 가장 가까운 다른 데이터로 변환\n",
    "    sunrise = datetime.datetime.strptime(date[j][1], '%H:%M:%S')\n",
    "    sunset = datetime.datetime.strptime(date[j][2], '%H:%M:%S')\n",
    "    \n",
    "    standard = datetime.datetime.strptime('1900-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    sunrise = sunrise - standard\n",
    "    sunset = sunset - standard\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        if(rows[i][0] >= sunrise):\n",
    "            start = i\n",
    "            print(date[j][0], rows[start][0], sunrise)\n",
    "            break;\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if(rows[i][0] >= sunset):\n",
    "            end = i\n",
    "            print(date[j][0], rows[end][0], sunset)\n",
    "            break;\n",
    "    \n",
    "    last = int((end - start) / 4)\n",
    "    last = last * 4\n",
    "    \n",
    "#     # start에 저장된 index부터 772개 데이터 가져와서 저장\n",
    "    for l in range(start, start + last):\n",
    "        wr.writerow([rows[l][2], rows[l][3]])\n",
    "    print(date[j][0] + \" \" + str(last) + \" data saved.\")\n",
    "    for l in range(4):\n",
    "        data_length.append(int(last/4))\n",
    "    print('----------------------------------------------')\n",
    "        \n",
    "w.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148,)\n"
     ]
    }
   ],
   "source": [
    "# date = np.genfromtxt('../data/date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "date = np.genfromtxt('../data/test_date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "\n",
    "# 데이터 받아오고 편차 계산히기\n",
    "# import_data = np.loadtxt('../data/db_connect_data_rnn.csv', delimiter=',')\n",
    "import_data = np.loadtxt('../data/db_connect_test_data_rnn.csv', delimiter=',')\n",
    "\n",
    "one = import_data[:,0] # cct\n",
    "two = import_data[:,1] # cas_swr\n",
    "\n",
    "data_index = 0\n",
    "\n",
    "cct = []\n",
    "swr = []\n",
    "\n",
    "delta_cct = []\n",
    "delta_swr = []\n",
    "\n",
    "cct_hap = []\n",
    "swr_hap = []\n",
    "\n",
    "for i in range(len(data_length)):\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    for j in range(data_length[i]):\n",
    "        temp.append(one[j + data_index])\n",
    "        temp2.append(two[j + data_index])\n",
    "    cct.append(temp)\n",
    "    swr.append(temp2)\n",
    "    data_index += data_length[i]\n",
    "\n",
    "for i in range(len(data_length)):\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    for j in range(data_length[i] - 1):\n",
    "        temp.append(cct[i][j+1] - cct[i][j])\n",
    "        temp2.append(swr[i][j+1] - swr[i][j])\n",
    "    delta_cct.append(temp)\n",
    "    delta_swr.append(temp2)\n",
    "    \n",
    "for i in range(len(data_length)):\n",
    "    temp1 = 0\n",
    "    temp2 = 0\n",
    "    for j in range(data_length[i]):\n",
    "        temp1 += cct[i][j]\n",
    "        temp2 += swr[i][j]\n",
    "    cct_hap.append(temp1)\n",
    "    swr_hap.append(temp2)\n",
    "\n",
    "print(np.shape(cct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = open('../data/cct_swr_calculation_rnn.csv', 'w', encoding='utf-8')\n",
    "w = open('../data/cct_swr_calculation_test_rnn.csv', 'w', encoding='utf-8')\n",
    "\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range(len(delta_cct)):\n",
    "    up_dot_25 = 0\n",
    "    up_dot_50 = 0\n",
    "    up_dot_100 = 0\n",
    "    up_dot_150 = 0\n",
    "    up_dot_200 = 0\n",
    "    up_dot_250 = 0\n",
    "    up_dot_300 = 0\n",
    "    up_dot_350 = 0\n",
    "    up_dot_400 = 0\n",
    "    up_dot_450 = 0\n",
    "    up_dot_500 = 0\n",
    "\n",
    "    # 위 변수들을 비율로 계산\n",
    "    percent_1 = 0\n",
    "    percent_2 = 0\n",
    "    percent_3 = 0\n",
    "    percent_4 = 0\n",
    "    percent_5 = 0\n",
    "    percent_6 = 0\n",
    "    percent_7 = 0\n",
    "    percent_8 = 0\n",
    "    percent_9 = 0\n",
    "    percent_10 = 0\n",
    "    percent_11 = 0\n",
    "\n",
    "    # 편차의 합, 평균, 등급 저장\n",
    "    hap = 0\n",
    "    avg = 0\n",
    "    grade = 0\n",
    "\n",
    "    # 편차 절댓값을 기준으로 갯수 저장\n",
    "    for j in range(len(delta_cct[i])):\n",
    "        if(abs(delta_cct[i][j]) >= 25):\n",
    "            up_dot_25 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 50):\n",
    "            up_dot_50 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 100):\n",
    "            up_dot_100 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 150):\n",
    "            up_dot_150 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 200):\n",
    "            up_dot_200 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 250):\n",
    "            up_dot_250 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 300):\n",
    "            up_dot_300 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 350):\n",
    "            up_dot_350 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 400):\n",
    "            up_dot_400 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 450):\n",
    "            up_dot_450 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 500):\n",
    "            up_dot_500 += 1\n",
    "        \n",
    "        # 편차 합 및 평균 저장\n",
    "        hap += abs(delta_cct[i][j])\n",
    "        avg = hap / len(delta_cct[i])\n",
    "\n",
    "        # 편차 갯수들이 차지하는 비율 소수점 둘째짜리까지 계산\n",
    "        percent_1 = round(up_dot_25 / len(cct[i]) * 100, 2)\n",
    "        percent_2 = round(up_dot_50 / len(cct[i]) * 100, 2)\n",
    "        percent_3 = round(up_dot_100 / len(cct[i]) * 100, 2)\n",
    "        percent_4 = round(up_dot_150 / len(cct[i]) * 100, 2)\n",
    "        percent_5 = round(up_dot_200 / len(cct[i]) * 100, 2)\n",
    "        percent_6 = round(up_dot_250 / len(cct[i]) * 100, 2)\n",
    "        percent_7 = round(up_dot_300 / len(cct[i]) * 100, 2)\n",
    "        percent_8 = round(up_dot_350 / len(cct[i]) * 100, 2)\n",
    "        percent_9 = round(up_dot_400 / len(cct[i]) * 100, 2)\n",
    "        percent_10 = round(up_dot_450 / len(cct[i]) * 100, 2)\n",
    "        percent_11 = round(up_dot_500 / len(cct[i]) * 100, 2)\n",
    "\n",
    "    # 등급 선정 기준\n",
    "    if(percent_1 > 30.0):\n",
    "        grade += 1\n",
    "    \n",
    "    if(percent_2 > 20.0):\n",
    "        grade += 1\n",
    "    \n",
    "    if(cct_hap[i] < 950000.0 or cct_hap[i] > 1050000.0):\n",
    "        grade += 1\n",
    "        \n",
    "    if(hap > 15000.0):\n",
    "        grade += 1\n",
    "        \n",
    "        # 편차의 절대값이 0.1 ~ 5이상인 경우의 갯수 저장\n",
    "    up_dot_1 = 0\n",
    "    up_dot_2 = 0\n",
    "    up_dot_3 = 0\n",
    "    up_dot_4 = 0\n",
    "    up_dot_5 = 0\n",
    "    up_dot_6 = 0\n",
    "    up_dot_7 = 0\n",
    "    up_dot_8 = 0\n",
    "    up_dot_9 = 0\n",
    "    up_dot_10 = 0\n",
    "    up_dot_20 = 0\n",
    "    up_dot_30 = 0\n",
    "    up_dot_40 = 0\n",
    "    up_dot_50_2 = 0\n",
    "\n",
    "    # 위의 갯수가 하루 전체 데이터에서 차지하는 비율 저장\n",
    "    percent_1 = 0\n",
    "    percent_2 = 0\n",
    "    percent_3 = 0\n",
    "    percent_4 = 0\n",
    "    percent_5 = 0\n",
    "    percent_6 = 0\n",
    "    percent_7 = 0\n",
    "    percent_8 = 0\n",
    "    percent_9 = 0\n",
    "    percent_10 = 0\n",
    "    percent_20 = 0\n",
    "    percent_30 = 0\n",
    "    percent_40 = 0\n",
    "    percent_50_2 = 0\n",
    "\n",
    "    # 편차의 합, 평균, 등급 저장\n",
    "    hap_2 = 0\n",
    "    avg_2 = 0\n",
    "#     grade = 0\n",
    "\n",
    "    for j in range(len(delta_swr[i])):\n",
    "        if(abs(delta_swr[i][j]) >= 0.1):\n",
    "            up_dot_1 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.2):\n",
    "            up_dot_2 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.3):\n",
    "            up_dot_3 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.4):\n",
    "            up_dot_4 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.5):\n",
    "            up_dot_5 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.6):\n",
    "            up_dot_6 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.7):\n",
    "            up_dot_7 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.8):\n",
    "            up_dot_8 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.9):\n",
    "            up_dot_9 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 1):\n",
    "            up_dot_10 += 1\n",
    "        if(abs(delta_swr[i][j] >= 2)):\n",
    "            up_dot_20 += 1\n",
    "        if(abs(delta_swr[i][j] >= 3)):\n",
    "            up_dot_30 += 1\n",
    "        if(abs(delta_swr[i][j] >= 4)):\n",
    "            up_dot_40 += 1\n",
    "        if(abs(delta_swr[i][j] >= 5)):\n",
    "            up_dot_50_2 += 1\n",
    "\n",
    "        hap_2 += abs(delta_swr[i][j])\n",
    "        avg_2 = hap / len(delta_swr[i])\n",
    "\n",
    "        percent_1 = round(up_dot_1 / len(swr[i]) * 100, 2);\n",
    "        percent_2 = round(up_dot_2 / len(swr[i]) * 100, 2);\n",
    "        percent_3 = round(up_dot_3 / len(swr[i]) * 100, 2);\n",
    "        percent_4 = round(up_dot_4 / len(swr[i]) * 100, 2);\n",
    "        percent_5 = round(up_dot_5 / len(swr[i]) * 100, 2);\n",
    "        percent_6 = round(up_dot_6 / len(swr[i]) * 100, 2);\n",
    "        percent_7 = round(up_dot_7 / len(swr[i]) * 100, 2);\n",
    "        percent_8 = round(up_dot_8 / len(swr[i]) * 100, 2);\n",
    "        percent_9 = round(up_dot_9 / len(swr[i]) * 100, 2);\n",
    "        percent_10 = round(up_dot_10 / len(swr[i]) * 100, 2);\n",
    "        percent_20 = round(up_dot_20 / len(swr[i]) * 100, 2);\n",
    "        percent_30 = round(up_dot_30 / len(swr[i]) * 100, 2);\n",
    "        percent_40 = round(up_dot_40 / len(swr[i]) * 100, 2);\n",
    "        percent_50 = round(up_dot_50 / len(swr[i]) * 100, 2);\n",
    "\n",
    "        # 등급 기준 1\n",
    "#     if(swr_hap[i] <= 15500.0 or swr_hap[i] >= 16500.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     # 등급 기준 2\n",
    "#     # 편차의 절대값이 0.1 이상인 경우가 전체 데이터의 25% + 1, 30%를 넘을 경우 +1, 40%를 넘을 경우 +2, 50%를 넘길 경우 +3\n",
    "#     if(percent_1 >= 25.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     if(percent_1 >= 40.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     # 등급 기준 3\n",
    "#     # 편차의 절대값이 1 이상인 경우가 전체 데이터의 5%를 넘을 경우 +1, 10%를 넘을 경우 +2\n",
    "#     if(percent_10 >= 10.0):\n",
    "#         grade += 1\n",
    "        \n",
    "    wr.writerow([up_dot_25, up_dot_50, up_dot_100, up_dot_150, up_dot_200, up_dot_250, up_dot_300, up_dot_350, up_dot_400, up_dot_450, up_dot_500, up_dot_1, up_dot_2, up_dot_3, up_dot_4, up_dot_5, up_dot_6, up_dot_7, up_dot_8, up_dot_9, up_dot_10, up_dot_20, up_dot_30, up_dot_40, up_dot_50_2, grade])\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0] cost: 2.104830026626587\n",
      "[step: 1] cost: 1.9134016036987305\n",
      "[step: 2] cost: 1.8202064037322998\n",
      "[step: 3] cost: 1.7881104946136475\n",
      "[step: 4] cost: 1.7731164693832397\n",
      "[step: 5] cost: 1.7548116445541382\n",
      "[step: 6] cost: 1.728950023651123\n",
      "[step: 7] cost: 1.6967711448669434\n",
      "[step: 8] cost: 1.6622326374053955\n",
      "[step: 9] cost: 1.630924940109253\n",
      "[step: 10] cost: 1.6076914072036743\n",
      "[step: 11] cost: 1.5935860872268677\n",
      "[step: 12] cost: 1.5848326683044434\n",
      "[step: 13] cost: 1.576008677482605\n",
      "[step: 14] cost: 1.5644197463989258\n",
      "[step: 15] cost: 1.551090121269226\n",
      "[step: 16] cost: 1.5385594367980957\n",
      "[step: 17] cost: 1.5283331871032715\n",
      "[step: 18] cost: 1.5201096534729004\n",
      "[step: 19] cost: 1.512752652168274\n",
      "[step: 20] cost: 1.505383849143982\n",
      "[step: 21] cost: 1.4976317882537842\n",
      "[step: 22] cost: 1.4893895387649536\n",
      "[step: 23] cost: 1.4807443618774414\n",
      "[step: 24] cost: 1.4721498489379883\n",
      "[step: 25] cost: 1.464402437210083\n",
      "[step: 26] cost: 1.4581855535507202\n",
      "[step: 27] cost: 1.4535367488861084\n",
      "[step: 28] cost: 1.44977867603302\n",
      "[step: 29] cost: 1.446004033088684\n",
      "[step: 30] cost: 1.4416905641555786\n",
      "[step: 31] cost: 1.4369601011276245\n",
      "[step: 32] cost: 1.4323633909225464\n",
      "[step: 33] cost: 1.4284310340881348\n",
      "[step: 34] cost: 1.4253408908843994\n",
      "[step: 35] cost: 1.4228681325912476\n",
      "[step: 36] cost: 1.4205595254898071\n",
      "[step: 37] cost: 1.417984962463379\n",
      "[step: 38] cost: 1.4149519205093384\n",
      "[step: 39] cost: 1.4115830659866333\n",
      "[step: 40] cost: 1.408210277557373\n",
      "[step: 41] cost: 1.405153751373291\n",
      "[step: 42] cost: 1.4025413990020752\n",
      "[step: 43] cost: 1.4002630710601807\n",
      "[step: 44] cost: 1.3980605602264404\n",
      "[step: 45] cost: 1.3956952095031738\n",
      "[step: 46] cost: 1.3930983543395996\n",
      "[step: 47] cost: 1.3904051780700684\n",
      "[step: 48] cost: 1.3878453969955444\n",
      "[step: 49] cost: 1.3855715990066528\n",
      "[step: 50] cost: 1.3835562467575073\n",
      "[step: 51] cost: 1.3816344738006592\n",
      "[step: 52] cost: 1.3796449899673462\n",
      "[step: 53] cost: 1.3775384426116943\n",
      "[step: 54] cost: 1.3753843307495117\n",
      "[step: 55] cost: 1.3732998371124268\n",
      "[step: 56] cost: 1.3713676929473877\n",
      "[step: 57] cost: 1.3695884943008423\n",
      "[step: 58] cost: 1.3678849935531616\n",
      "[step: 59] cost: 1.366162657737732\n",
      "[step: 60] cost: 1.3643810749053955\n",
      "[step: 61] cost: 1.3625770807266235\n",
      "[step: 62] cost: 1.3608218431472778\n",
      "[step: 63] cost: 1.3591538667678833\n",
      "[step: 64] cost: 1.3575571775436401\n",
      "[step: 65] cost: 1.3559848070144653\n",
      "[step: 66] cost: 1.3544007539749146\n",
      "[step: 67] cost: 1.3528006076812744\n",
      "[step: 68] cost: 1.351204752922058\n",
      "[step: 69] cost: 1.3496407270431519\n",
      "[step: 70] cost: 1.348119854927063\n",
      "[step: 71] cost: 1.3466309309005737\n",
      "[step: 72] cost: 1.3451526165008545\n",
      "[step: 73] cost: 1.3436740636825562\n",
      "[step: 74] cost: 1.3422011137008667\n",
      "[step: 75] cost: 1.3407453298568726\n",
      "[step: 76] cost: 1.339313268661499\n",
      "[step: 77] cost: 1.3379052877426147\n",
      "[step: 78] cost: 1.3365166187286377\n",
      "[step: 79] cost: 1.3351422548294067\n",
      "[step: 80] cost: 1.3337783813476562\n",
      "[step: 81] cost: 1.3324265480041504\n",
      "[step: 82] cost: 1.3310887813568115\n",
      "[step: 83] cost: 1.329766035079956\n",
      "[step: 84] cost: 1.3284586668014526\n",
      "[step: 85] cost: 1.327165961265564\n",
      "[step: 86] cost: 1.3258858919143677\n",
      "[step: 87] cost: 1.324615478515625\n",
      "[step: 88] cost: 1.3233535289764404\n",
      "[step: 89] cost: 1.322101354598999\n",
      "[step: 90] cost: 1.3208603858947754\n",
      "[step: 91] cost: 1.319631814956665\n",
      "[step: 92] cost: 1.3184139728546143\n",
      "[step: 93] cost: 1.317203402519226\n",
      "[step: 94] cost: 1.3159993886947632\n",
      "[step: 95] cost: 1.3148016929626465\n",
      "[step: 96] cost: 1.313613772392273\n",
      "[step: 97] cost: 1.3124364614486694\n",
      "[step: 98] cost: 1.3112680912017822\n",
      "[step: 99] cost: 1.310106635093689\n",
      "[step: 100] cost: 1.3089511394500732\n",
      "[step: 101] cost: 1.307801365852356\n",
      "[step: 102] cost: 1.3066596984863281\n",
      "[step: 103] cost: 1.3055260181427002\n",
      "[step: 104] cost: 1.3043986558914185\n",
      "[step: 105] cost: 1.3032760620117188\n",
      "[step: 106] cost: 1.302157998085022\n",
      "[step: 107] cost: 1.3010451793670654\n",
      "[step: 108] cost: 1.2999374866485596\n",
      "[step: 109] cost: 1.2988358736038208\n",
      "[step: 110] cost: 1.2977384328842163\n",
      "[step: 111] cost: 1.296645164489746\n",
      "[step: 112] cost: 1.2955557107925415\n",
      "[step: 113] cost: 1.2944704294204712\n",
      "[step: 114] cost: 1.2933892011642456\n",
      "[step: 115] cost: 1.2923122644424438\n",
      "[step: 116] cost: 1.29123854637146\n",
      "[step: 117] cost: 1.290168046951294\n",
      "[step: 118] cost: 1.2891007661819458\n",
      "[step: 119] cost: 1.2880369424819946\n",
      "[step: 120] cost: 1.2869759798049927\n",
      "[step: 121] cost: 1.285918116569519\n",
      "[step: 122] cost: 1.2848631143569946\n",
      "[step: 123] cost: 1.2838108539581299\n",
      "[step: 124] cost: 1.2827610969543457\n",
      "[step: 125] cost: 1.2817140817642212\n",
      "[step: 126] cost: 1.2806693315505981\n",
      "[step: 127] cost: 1.2796270847320557\n",
      "[step: 128] cost: 1.2785872220993042\n",
      "[step: 129] cost: 1.2775495052337646\n",
      "[step: 130] cost: 1.2765138149261475\n",
      "[step: 131] cost: 1.2754806280136108\n",
      "[step: 132] cost: 1.2744494676589966\n",
      "[step: 133] cost: 1.2734203338623047\n",
      "[step: 134] cost: 1.2723932266235352\n",
      "[step: 135] cost: 1.2713685035705566\n",
      "[step: 136] cost: 1.2703453302383423\n",
      "[step: 137] cost: 1.2693244218826294\n",
      "[step: 138] cost: 1.2683054208755493\n",
      "[step: 139] cost: 1.2672884464263916\n",
      "[step: 140] cost: 1.2662731409072876\n",
      "[step: 141] cost: 1.2652599811553955\n",
      "[step: 142] cost: 1.2642483711242676\n",
      "[step: 143] cost: 1.2632390260696411\n",
      "[step: 144] cost: 1.2622312307357788\n",
      "[step: 145] cost: 1.2612253427505493\n",
      "[step: 146] cost: 1.2602211236953735\n",
      "[step: 147] cost: 1.2592189311981201\n",
      "[step: 148] cost: 1.2582186460494995\n",
      "[step: 149] cost: 1.2572201490402222\n",
      "[step: 150] cost: 1.2562233209609985\n",
      "[step: 151] cost: 1.2552282810211182\n",
      "[step: 152] cost: 1.254235029220581\n",
      "[step: 153] cost: 1.2532435655593872\n",
      "[step: 154] cost: 1.2522536516189575\n",
      "[step: 155] cost: 1.2512657642364502\n",
      "[step: 156] cost: 1.2502795457839966\n",
      "[step: 157] cost: 1.2492948770523071\n",
      "[step: 158] cost: 1.248311996459961\n",
      "[step: 159] cost: 1.2473304271697998\n",
      "[step: 160] cost: 1.2463511228561401\n",
      "[step: 161] cost: 1.245373249053955\n",
      "[step: 162] cost: 1.2443969249725342\n",
      "[step: 163] cost: 1.243422269821167\n",
      "[step: 164] cost: 1.242449164390564\n",
      "[step: 165] cost: 1.2414777278900146\n",
      "[step: 166] cost: 1.2405078411102295\n",
      "[step: 167] cost: 1.239539384841919\n",
      "[step: 168] cost: 1.2385724782943726\n",
      "[step: 169] cost: 1.2376070022583008\n",
      "[step: 170] cost: 1.2366429567337036\n",
      "[step: 171] cost: 1.2356804609298706\n",
      "[step: 172] cost: 1.234719157218933\n",
      "[step: 173] cost: 1.2337591648101807\n",
      "[step: 174] cost: 1.2328006029129028\n",
      "[step: 175] cost: 1.2318434715270996\n",
      "[step: 176] cost: 1.2308870553970337\n",
      "[step: 177] cost: 1.229932188987732\n",
      "[step: 178] cost: 1.2289783954620361\n",
      "[step: 179] cost: 1.2280255556106567\n",
      "[step: 180] cost: 1.2270737886428833\n",
      "[step: 181] cost: 1.2261230945587158\n",
      "[step: 182] cost: 1.2251732349395752\n",
      "[step: 183] cost: 1.2242242097854614\n",
      "[step: 184] cost: 1.2232762575149536\n",
      "[step: 185] cost: 1.2223286628723145\n",
      "[step: 186] cost: 1.2213820219039917\n",
      "[step: 187] cost: 1.2204359769821167\n",
      "[step: 188] cost: 1.2194904088974\n",
      "[step: 189] cost: 1.2185454368591309\n",
      "[step: 190] cost: 1.21760094165802\n",
      "[step: 191] cost: 1.2166566848754883\n",
      "[step: 192] cost: 1.2157127857208252\n",
      "[step: 193] cost: 1.2147690057754517\n",
      "[step: 194] cost: 1.2138253450393677\n",
      "[step: 195] cost: 1.2128818035125732\n",
      "[step: 196] cost: 1.2119382619857788\n",
      "[step: 197] cost: 1.2109944820404053\n",
      "[step: 198] cost: 1.2100505828857422\n",
      "[step: 199] cost: 1.2091064453125\n",
      "[step: 200] cost: 1.2081615924835205\n",
      "[step: 201] cost: 1.2072163820266724\n",
      "[step: 202] cost: 1.2062708139419556\n",
      "[step: 203] cost: 1.2053245306015015\n",
      "[step: 204] cost: 1.204377293586731\n",
      "[step: 205] cost: 1.2034293413162231\n",
      "[step: 206] cost: 1.202480435371399\n",
      "[step: 207] cost: 1.2015302181243896\n",
      "[step: 208] cost: 1.200579047203064\n",
      "[step: 209] cost: 1.1996265649795532\n",
      "[step: 210] cost: 1.1986726522445679\n",
      "[step: 211] cost: 1.197717308998108\n",
      "[step: 212] cost: 1.1967601776123047\n",
      "[step: 213] cost: 1.1958014965057373\n",
      "[step: 214] cost: 1.1948410272598267\n",
      "[step: 215] cost: 1.193878412246704\n",
      "[step: 216] cost: 1.1929140090942383\n",
      "[step: 217] cost: 1.1919474601745605\n",
      "[step: 218] cost: 1.1909786462783813\n",
      "[step: 219] cost: 1.1900075674057007\n",
      "[step: 220] cost: 1.1890337467193604\n",
      "[step: 221] cost: 1.1880574226379395\n",
      "[step: 222] cost: 1.187078595161438\n",
      "[step: 223] cost: 1.1860969066619873\n",
      "[step: 224] cost: 1.1851121187210083\n",
      "[step: 225] cost: 1.1841245889663696\n",
      "[step: 226] cost: 1.1831339597702026\n",
      "[step: 227] cost: 1.1821399927139282\n",
      "[step: 228] cost: 1.181142807006836\n",
      "[step: 229] cost: 1.1801420450210571\n",
      "[step: 230] cost: 1.179137945175171\n",
      "[step: 231] cost: 1.178130030632019\n",
      "[step: 232] cost: 1.1771185398101807\n",
      "[step: 233] cost: 1.176103115081787\n",
      "[step: 234] cost: 1.175083875656128\n",
      "[step: 235] cost: 1.174060583114624\n",
      "[step: 236] cost: 1.1730332374572754\n",
      "[step: 237] cost: 1.1720014810562134\n",
      "[step: 238] cost: 1.1709656715393066\n",
      "[step: 239] cost: 1.1699252128601074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 240] cost: 1.1688804626464844\n",
      "[step: 241] cost: 1.1678310632705688\n",
      "[step: 242] cost: 1.1667768955230713\n",
      "[step: 243] cost: 1.1657179594039917\n",
      "[step: 244] cost: 1.164654016494751\n",
      "[step: 245] cost: 1.1635853052139282\n",
      "[step: 246] cost: 1.1625114679336548\n",
      "[step: 247] cost: 1.1614323854446411\n",
      "[step: 248] cost: 1.1603481769561768\n",
      "[step: 249] cost: 1.159258484840393\n",
      "[step: 250] cost: 1.1581636667251587\n",
      "[step: 251] cost: 1.1570631265640259\n",
      "[step: 252] cost: 1.1559569835662842\n",
      "[step: 253] cost: 1.154845118522644\n",
      "[step: 254] cost: 1.153727650642395\n",
      "[step: 255] cost: 1.152604103088379\n",
      "[step: 256] cost: 1.151474952697754\n",
      "[step: 257] cost: 1.1503394842147827\n",
      "[step: 258] cost: 1.1491978168487549\n",
      "[step: 259] cost: 1.1480501890182495\n",
      "[step: 260] cost: 1.1468961238861084\n",
      "[step: 261] cost: 1.145735740661621\n",
      "[step: 262] cost: 1.144568681716919\n",
      "[step: 263] cost: 1.1433954238891602\n",
      "[step: 264] cost: 1.1422151327133179\n",
      "[step: 265] cost: 1.1410285234451294\n",
      "[step: 266] cost: 1.1398348808288574\n",
      "[step: 267] cost: 1.138634443283081\n",
      "[step: 268] cost: 1.1374270915985107\n",
      "[step: 269] cost: 1.136212706565857\n",
      "[step: 270] cost: 1.134990930557251\n",
      "[step: 271] cost: 1.1337623596191406\n",
      "[step: 272] cost: 1.1325262784957886\n",
      "[step: 273] cost: 1.1312830448150635\n",
      "[step: 274] cost: 1.1300321817398071\n",
      "[step: 275] cost: 1.128773808479309\n",
      "[step: 276] cost: 1.1275080442428589\n",
      "[step: 277] cost: 1.1262346506118774\n",
      "[step: 278] cost: 1.124953269958496\n",
      "[step: 279] cost: 1.1236644983291626\n",
      "[step: 280] cost: 1.1223676204681396\n",
      "[step: 281] cost: 1.1210628747940063\n",
      "[step: 282] cost: 1.1197502613067627\n",
      "[step: 283] cost: 1.1184293031692505\n",
      "[step: 284] cost: 1.1171005964279175\n",
      "[step: 285] cost: 1.1157633066177368\n",
      "[step: 286] cost: 1.1144180297851562\n",
      "[step: 287] cost: 1.1130644083023071\n",
      "[step: 288] cost: 1.111702561378479\n",
      "[step: 289] cost: 1.1103321313858032\n",
      "[step: 290] cost: 1.1089531183242798\n",
      "[step: 291] cost: 1.1075657606124878\n",
      "[step: 292] cost: 1.106169581413269\n",
      "[step: 293] cost: 1.1047649383544922\n",
      "[step: 294] cost: 1.103351354598999\n",
      "[step: 295] cost: 1.1019290685653687\n",
      "[step: 296] cost: 1.1004979610443115\n",
      "[step: 297] cost: 1.099057912826538\n",
      "[step: 298] cost: 1.0976089239120483\n",
      "[step: 299] cost: 1.0961509943008423\n",
      "[step: 300] cost: 1.0946838855743408\n",
      "[step: 301] cost: 1.093207597732544\n",
      "[step: 302] cost: 1.0917221307754517\n",
      "[step: 303] cost: 1.090227484703064\n",
      "[step: 304] cost: 1.0887233018875122\n",
      "[step: 305] cost: 1.0872098207473755\n",
      "[step: 306] cost: 1.0856870412826538\n",
      "[step: 307] cost: 1.0841546058654785\n",
      "[step: 308] cost: 1.0826127529144287\n",
      "[step: 309] cost: 1.0810611248016357\n",
      "[step: 310] cost: 1.0794999599456787\n",
      "[step: 311] cost: 1.077928900718689\n",
      "[step: 312] cost: 1.076348066329956\n",
      "[step: 313] cost: 1.0747575759887695\n",
      "[step: 314] cost: 1.0731568336486816\n",
      "[step: 315] cost: 1.071546196937561\n",
      "[step: 316] cost: 1.0699255466461182\n",
      "[step: 317] cost: 1.068294644355774\n",
      "[step: 318] cost: 1.0666537284851074\n",
      "[step: 319] cost: 1.0650025606155396\n",
      "[step: 320] cost: 1.0633409023284912\n",
      "[step: 321] cost: 1.0616692304611206\n",
      "[step: 322] cost: 1.05998694896698\n",
      "[step: 323] cost: 1.0582941770553589\n",
      "[step: 324] cost: 1.0565910339355469\n",
      "[step: 325] cost: 1.0548771619796753\n",
      "[step: 326] cost: 1.0531526803970337\n",
      "[step: 327] cost: 1.0514177083969116\n",
      "[step: 328] cost: 1.0496718883514404\n",
      "[step: 329] cost: 1.0479154586791992\n",
      "[step: 330] cost: 1.0461480617523193\n",
      "[step: 331] cost: 1.0443699359893799\n",
      "[step: 332] cost: 1.0425808429718018\n",
      "[step: 333] cost: 1.040781021118164\n",
      "[step: 334] cost: 1.0389699935913086\n",
      "[step: 335] cost: 1.0371482372283936\n",
      "[step: 336] cost: 1.0353153944015503\n",
      "[step: 337] cost: 1.0334714651107788\n",
      "[step: 338] cost: 1.0316165685653687\n",
      "[step: 339] cost: 1.0297504663467407\n",
      "[step: 340] cost: 1.0278735160827637\n",
      "[step: 341] cost: 1.0259853601455688\n",
      "[step: 342] cost: 1.0240859985351562\n",
      "[step: 343] cost: 1.022175669670105\n",
      "[step: 344] cost: 1.0202540159225464\n",
      "[step: 345] cost: 1.0183215141296387\n",
      "[step: 346] cost: 1.0163778066635132\n",
      "[step: 347] cost: 1.014423131942749\n",
      "[step: 348] cost: 1.0124574899673462\n",
      "[step: 349] cost: 1.0104820728302002\n",
      "[step: 350] cost: 1.0084999799728394\n",
      "[step: 351] cost: 1.0065253973007202\n",
      "[step: 352] cost: 1.0046130418777466\n",
      "[step: 353] cost: 1.0029932260513306\n",
      "[step: 354] cost: 1.002504825592041\n",
      "[step: 355] cost: 1.0050294399261475\n",
      "[step: 356] cost: 1.0079474449157715\n",
      "[step: 357] cost: 1.0010179281234741\n",
      "[step: 358] cost: 0.9929360747337341\n",
      "[step: 359] cost: 0.9973583817481995\n",
      "[step: 360] cost: 0.9943181872367859\n",
      "[step: 361] cost: 0.9875711798667908\n",
      "[step: 362] cost: 0.9909722805023193\n",
      "[step: 363] cost: 0.9862592816352844\n",
      "[step: 364] cost: 0.9830425977706909\n",
      "[step: 365] cost: 0.9845549464225769\n",
      "[step: 366] cost: 0.9788848757743835\n",
      "[step: 367] cost: 0.9789718985557556\n",
      "[step: 368] cost: 0.9770963788032532\n",
      "[step: 369] cost: 0.9733959436416626\n",
      "[step: 370] cost: 0.9738433957099915\n",
      "[step: 371] cost: 0.9699933528900146\n",
      "[step: 372] cost: 0.968967616558075\n",
      "[step: 373] cost: 0.9674287438392639\n",
      "[step: 374] cost: 0.9643396139144897\n",
      "[step: 375] cost: 0.9639195799827576\n",
      "[step: 376] cost: 0.9609453082084656\n",
      "[step: 377] cost: 0.9594313502311707\n",
      "[step: 378] cost: 0.9579213261604309\n",
      "[step: 379] cost: 0.9552106261253357\n",
      "[step: 380] cost: 0.9542017579078674\n",
      "[step: 381] cost: 0.9517735242843628\n",
      "[step: 382] cost: 0.9499459266662598\n",
      "[step: 383] cost: 0.9484421610832214\n",
      "[step: 384] cost: 0.9459888339042664\n",
      "[step: 385] cost: 0.9445688724517822\n",
      "[step: 386] cost: 0.9425145387649536\n",
      "[step: 387] cost: 0.9404452443122864\n",
      "[step: 388] cost: 0.9389082193374634\n",
      "[step: 389] cost: 0.9366682171821594\n",
      "[step: 390] cost: 0.934888482093811\n",
      "[step: 391] cost: 0.9330819249153137\n",
      "[step: 392] cost: 0.930916965007782\n",
      "[step: 393] cost: 0.9292048811912537\n",
      "[step: 394] cost: 0.9272168874740601\n",
      "[step: 395] cost: 0.925175130367279\n",
      "[step: 396] cost: 0.9234073162078857\n",
      "[step: 397] cost: 0.9213491678237915\n",
      "[step: 398] cost: 0.9193817973136902\n",
      "[step: 399] cost: 0.9175360202789307\n",
      "[step: 400] cost: 0.9154653549194336\n",
      "[step: 401] cost: 0.913520336151123\n",
      "[step: 402] cost: 0.9116123914718628\n",
      "[step: 403] cost: 0.9095471501350403\n",
      "[step: 404] cost: 0.907592236995697\n",
      "[step: 405] cost: 0.9056438207626343\n",
      "[step: 406] cost: 0.9035832285881042\n",
      "[step: 407] cost: 0.9016038179397583\n",
      "[step: 408] cost: 0.8996298313140869\n",
      "[step: 409] cost: 0.8975698947906494\n",
      "[step: 410] cost: 0.8955612778663635\n",
      "[step: 411] cost: 0.8935683369636536\n",
      "[step: 412] cost: 0.8915076851844788\n",
      "[step: 413] cost: 0.8894691467285156\n",
      "[step: 414] cost: 0.8874571323394775\n",
      "[step: 415] cost: 0.8853969573974609\n",
      "[step: 416] cost: 0.8833320140838623\n",
      "[step: 417] cost: 0.8812963962554932\n",
      "[step: 418] cost: 0.8792372941970825\n",
      "[step: 419] cost: 0.8771544098854065\n",
      "[step: 420] cost: 0.8750902414321899\n",
      "[step: 421] cost: 0.8730267882347107\n",
      "[step: 422] cost: 0.8709375858306885\n",
      "[step: 423] cost: 0.8688463568687439\n",
      "[step: 424] cost: 0.8667667508125305\n",
      "[step: 425] cost: 0.8646768927574158\n",
      "[step: 426] cost: 0.8625708818435669\n",
      "[step: 427] cost: 0.8604674935340881\n",
      "[step: 428] cost: 0.8583686351776123\n",
      "[step: 429] cost: 0.8562599420547485\n",
      "[step: 430] cost: 0.8541405200958252\n",
      "[step: 431] cost: 0.8520219922065735\n",
      "[step: 432] cost: 0.8499053716659546\n",
      "[step: 433] cost: 0.8477828502655029\n",
      "[step: 434] cost: 0.8456518054008484\n",
      "[step: 435] cost: 0.8435184359550476\n",
      "[step: 436] cost: 0.8413862586021423\n",
      "[step: 437] cost: 0.8392519950866699\n",
      "[step: 438] cost: 0.8371115326881409\n",
      "[step: 439] cost: 0.8349666595458984\n",
      "[step: 440] cost: 0.8328206539154053\n",
      "[step: 441] cost: 0.8306743502616882\n",
      "[step: 442] cost: 0.8285261392593384\n",
      "[step: 443] cost: 0.8263742327690125\n",
      "[step: 444] cost: 0.8242190480232239\n",
      "[step: 445] cost: 0.8220619559288025\n",
      "[step: 446] cost: 0.8199041485786438\n",
      "[step: 447] cost: 0.8177458047866821\n",
      "[step: 448] cost: 0.8155858516693115\n",
      "[step: 449] cost: 0.8134239315986633\n",
      "[step: 450] cost: 0.8112601637840271\n",
      "[step: 451] cost: 0.8090949654579163\n",
      "[step: 452] cost: 0.8069288730621338\n",
      "[step: 453] cost: 0.8047621250152588\n",
      "[step: 454] cost: 0.8025951981544495\n",
      "[step: 455] cost: 0.8004276752471924\n",
      "[step: 456] cost: 0.7982597947120667\n",
      "[step: 457] cost: 0.7960914969444275\n",
      "[step: 458] cost: 0.793923020362854\n",
      "[step: 459] cost: 0.791754424571991\n",
      "[step: 460] cost: 0.7895858287811279\n",
      "[step: 461] cost: 0.7874178886413574\n",
      "[step: 462] cost: 0.7852509021759033\n",
      "[step: 463] cost: 0.783085823059082\n",
      "[step: 464] cost: 0.7809242606163025\n",
      "[step: 465] cost: 0.7787702679634094\n",
      "[step: 466] cost: 0.7766314148902893\n",
      "[step: 467] cost: 0.7745274901390076\n",
      "[step: 468] cost: 0.7725000381469727\n",
      "[step: 469] cost: 0.7706541419029236\n",
      "[step: 470] cost: 0.7692090272903442\n",
      "[step: 471] cost: 0.768642783164978\n",
      "[step: 472] cost: 0.7693459987640381\n",
      "[step: 473] cost: 0.7708333730697632\n",
      "[step: 474] cost: 0.7684614658355713\n",
      "[step: 475] cost: 0.7612466216087341\n",
      "[step: 476] cost: 0.7555450797080994\n",
      "[step: 477] cost: 0.7563691735267639\n",
      "[step: 478] cost: 0.7573290467262268\n",
      "[step: 479] cost: 0.7523154616355896\n",
      "[step: 480] cost: 0.7477049231529236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 481] cost: 0.7480314373970032\n",
      "[step: 482] cost: 0.7472567558288574\n",
      "[step: 483] cost: 0.7428311705589294\n",
      "[step: 484] cost: 0.740224301815033\n",
      "[step: 485] cost: 0.7402449250221252\n",
      "[step: 486] cost: 0.7380043268203735\n",
      "[step: 487] cost: 0.7343332767486572\n",
      "[step: 488] cost: 0.7331516742706299\n",
      "[step: 489] cost: 0.7322339415550232\n",
      "[step: 490] cost: 0.7291625142097473\n",
      "[step: 491] cost: 0.7267515659332275\n",
      "[step: 492] cost: 0.7258411049842834\n",
      "[step: 493] cost: 0.7238483428955078\n",
      "[step: 494] cost: 0.7210846543312073\n",
      "[step: 495] cost: 0.7194739580154419\n",
      "[step: 496] cost: 0.7181147933006287\n",
      "[step: 497] cost: 0.7157658338546753\n",
      "[step: 498] cost: 0.7135242223739624\n",
      "[step: 499] cost: 0.7120792865753174\n",
      "[step: 500] cost: 0.7103295922279358\n",
      "[step: 501] cost: 0.7080117464065552\n",
      "[step: 502] cost: 0.7061048150062561\n",
      "[step: 503] cost: 0.7045646905899048\n",
      "[step: 504] cost: 0.7026166319847107\n",
      "[step: 505] cost: 0.7004655003547668\n",
      "[step: 506] cost: 0.6986788511276245\n",
      "[step: 507] cost: 0.6970106959342957\n",
      "[step: 508] cost: 0.6950449347496033\n",
      "[step: 509] cost: 0.6930100321769714\n",
      "[step: 510] cost: 0.6912267208099365\n",
      "[step: 511] cost: 0.689493715763092\n",
      "[step: 512] cost: 0.6875582933425903\n",
      "[step: 513] cost: 0.6855849027633667\n",
      "[step: 514] cost: 0.6837737560272217\n",
      "[step: 515] cost: 0.6820077896118164\n",
      "[step: 516] cost: 0.6801213622093201\n",
      "[step: 517] cost: 0.6781829595565796\n",
      "[step: 518] cost: 0.6763356328010559\n",
      "[step: 519] cost: 0.6745492219924927\n",
      "[step: 520] cost: 0.6727052330970764\n",
      "[step: 521] cost: 0.6708003878593445\n",
      "[step: 522] cost: 0.6689242124557495\n",
      "[step: 523] cost: 0.6671079993247986\n",
      "[step: 524] cost: 0.6652913093566895\n",
      "[step: 525] cost: 0.6634277105331421\n",
      "[step: 526] cost: 0.6615462303161621\n",
      "[step: 527] cost: 0.659694254398346\n",
      "[step: 528] cost: 0.6578718423843384\n",
      "[step: 529] cost: 0.6560428738594055\n",
      "[step: 530] cost: 0.6541869044303894\n",
      "학습 정확도: 0.78959274\n",
      "테스트 정확도: 0.33157894\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "ohe = OneHotEncoder()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "import_data = np.genfromtxt('../data/cct_swr_calculation_rnn.csv', delimiter=',', dtype='float')\n",
    "\n",
    "x_data = import_data[:, :25]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "x_data = x_data[:, :25]\n",
    "\n",
    "y_data = []\n",
    "test_y = []\n",
    "\n",
    "for i in range(len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][25])\n",
    "    y_data.append(temp)\n",
    "\n",
    "raw_y = y_data\n",
    "    \n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "seq_length = 4\n",
    "data_dim = 25\n",
    "hidden_dim = 50\n",
    "output_dim = 5\n",
    "learning_rate = 0.001\n",
    "iterations = 531\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(len(x_data) - seq_length):\n",
    "    _x = x_data[i:i + seq_length]\n",
    "    _y = y_data[i+seq_length]\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)\n",
    "\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "trainX, testX = np.array(dataX[0:train_size]), np.array(dataX[train_size:len(dataX)])\n",
    "trainY, testY = np.array(dataY[0:train_size]), np.array(dataY[train_size:len(dataY)])\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, output_dim])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([hidden_dim, output_dim]))\n",
    "b = tf.Variable(tf.random_normal([output_dim]))\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(hidden_dim)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "writer = tf.summary.FileWriter(\"./logs/rnn_logs\", sess.graph)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "for i in range(iterations):\n",
    "    _, step_cost = sess.run([optimizer, cost], feed_dict={X:trainX, Y:trainY})\n",
    "    print(\"[step: {}] cost: {}\".format(i, step_cost))\n",
    "    summary, acc = sess.run([merged, accuracy], feed_dict={X:testX, Y:testY})\n",
    "    writer.add_summary(summary, i)\n",
    "\n",
    "print('학습 정확도:', sess.run(accuracy, feed_dict={X:trainX, Y:trainY}))\n",
    "print('테스트 정확도:', sess.run(accuracy, feed_dict={X:testX, Y:testY}))\n",
    "\n",
    "# for i in range(len(trainX)):\n",
    "#     a = sess.run(model, feed_dict={X:[trainX[i]]})\n",
    "#     b = sess.run(Y, feed_dict={X:[trainX[i]]})\n",
    "#     print(sess.run(tf.argmax(a, 1)), \", \", sess.run(tf.argmax(b, 1)))\n",
    "\n",
    "# cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)\n",
    "# outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "# Y_pred = tf.contrib.layers.fully_connected(outputs[:, -1], output_dim, activation_fn=tf.nn.softmax)\n",
    "\n",
    "# loss = tf.reduce_sum(tf.square(Y_pred - Y))\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# train = optimizer.minimize(loss)\n",
    "\n",
    "# targets = tf.placeholder(tf.float32, [None, 5])\n",
    "# predictions = tf.placeholder(tf.float32, [None, 5])\n",
    "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "    \n",
    "#     for i in range(iterations):\n",
    "#         _, step_loss = sess.run([train, loss], feed_dict={X:trainX, Y:trainY})\n",
    "#         print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "        \n",
    "#     test_predict = sess.run(Y_pred, feed_dict={X:testX})\n",
    "#     rmse_val = sess.run(rmse, feed_dict={targets:testY, predictions:test_predict})\n",
    "#     print(\"RMSE:{}\".format(rmse_val))\n",
    "    \n",
    "#     print(sess.run(tf.argmax(test_predict, 1)))\n",
    "#     print(len(dataX), len(trainX), len(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-760073b0b4bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;36m21.78\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RNN' is not defined"
     ]
    }
   ],
   "source": [
    "RNN\n",
    "30\n",
    "29.45\n",
    "\n",
    "50\n",
    "33.56\n",
    "\n",
    "100\n",
    "34.93\n",
    "\n",
    "150\n",
    "33.56\n",
    "\n",
    "200\n",
    "34.24\n",
    "\n",
    "250\n",
    "34.93\n",
    "\n",
    "300\n",
    "37.67\n",
    "\n",
    "350\n",
    "39.04\n",
    "\n",
    "400\n",
    "36.3\n",
    "\n",
    "531\n",
    "41.09\n",
    "\n",
    "LSTM\n",
    "219\n",
    "34.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
