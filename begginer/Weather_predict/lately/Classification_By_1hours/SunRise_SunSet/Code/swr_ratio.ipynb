{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-19 5:52:00 5:52:00\n",
      "2018-04-19 19:52:00 19:52:00\n",
      "2018-04-19 am saved.\n",
      "2018-04-19 pm saved.\n",
      "2018-04-21 5:49:00 5:49:00\n",
      "2018-04-21 19:49:00 19:49:00\n",
      "2018-04-21 am saved.\n",
      "2018-04-21 pm saved.\n",
      "2018-04-26 5:43:00 5:43:00\n",
      "2018-04-26 19:43:00 19:43:00\n",
      "2018-04-26 am saved.\n",
      "2018-04-26 pm saved.\n",
      "2018-04-27 5:42:00 5:42:00\n",
      "2018-04-27 19:42:00 19:42:00\n",
      "2018-04-27 am saved.\n",
      "2018-04-27 pm saved.\n",
      "2018-04-28 5:41:00 5:41:00\n",
      "2018-04-28 19:41:00 19:41:00\n",
      "2018-04-28 am saved.\n",
      "2018-04-28 pm saved.\n",
      "2018-04-29 5:40:00 5:40:00\n",
      "2018-04-29 19:40:00 19:40:00\n",
      "2018-04-29 am saved.\n",
      "2018-04-29 pm saved.\n",
      "2018-04-30 5:38:00 5:38:00\n",
      "2018-04-30 19:38:00 19:38:00\n",
      "2018-04-30 am saved.\n",
      "2018-04-30 pm saved.\n",
      "2018-05-04 5:34:00 5:34:00\n",
      "2018-05-04 19:34:00 19:34:00\n",
      "2018-05-04 am saved.\n",
      "2018-05-04 pm saved.\n",
      "2018-05-05 5:33:00 5:33:00\n",
      "2018-05-05 19:33:00 19:33:00\n",
      "2018-05-05 am saved.\n",
      "2018-05-05 pm saved.\n",
      "2018-05-08 5:30:00 5:30:00\n",
      "2018-05-08 19:30:00 19:30:00\n",
      "2018-05-08 am saved.\n",
      "2018-05-08 pm saved.\n",
      "2018-05-10 5:28:00 5:28:00\n",
      "2018-05-10 19:28:00 19:28:00\n",
      "2018-05-10 am saved.\n",
      "2018-05-10 pm saved.\n",
      "2018-05-14 5:24:00 5:24:00\n",
      "2018-05-14 19:24:00 19:24:00\n",
      "2018-05-14 am saved.\n",
      "2018-05-14 pm saved.\n",
      "2018-05-19 5:20:00 5:20:00\n",
      "2018-05-19 19:20:00 19:20:00\n",
      "2018-05-19 am saved.\n",
      "2018-05-19 pm saved.\n",
      "2018-05-21 5:19:00 5:19:00\n",
      "2018-05-21 19:19:00 19:19:00\n",
      "2018-05-21 am saved.\n",
      "2018-05-21 pm saved.\n",
      "2018-05-24 5:17:00 5:17:00\n",
      "2018-05-24 19:17:00 19:17:00\n",
      "2018-05-24 am saved.\n",
      "2018-05-24 pm saved.\n",
      "2018-05-25 5:17:00 5:17:00\n",
      "2018-05-25 19:17:00 19:17:00\n",
      "2018-05-25 am saved.\n",
      "2018-05-25 pm saved.\n",
      "2018-05-26 5:16:00 5:16:00\n",
      "2018-05-26 19:16:00 19:16:00\n",
      "2018-05-26 am saved.\n",
      "2018-05-26 pm saved.\n",
      "2018-05-27 5:16:00 5:16:00\n",
      "2018-05-27 19:16:00 19:16:00\n",
      "2018-05-27 am saved.\n",
      "2018-05-27 pm saved.\n",
      "2018-05-28 5:15:00 5:15:00\n",
      "2018-05-28 19:15:00 19:15:00\n",
      "2018-05-28 am saved.\n",
      "2018-05-28 pm saved.\n",
      "2018-05-29 5:15:00 5:15:00\n",
      "2018-05-29 19:15:00 19:15:00\n",
      "2018-05-29 am saved.\n",
      "2018-05-29 pm saved.\n",
      "2018-05-30 5:14:00 5:14:00\n",
      "2018-05-30 19:14:00 19:14:00\n",
      "2018-05-30 am saved.\n",
      "2018-05-30 pm saved.\n",
      "2018-05-31 5:14:00 5:14:00\n",
      "2018-05-31 19:14:00 19:14:00\n",
      "2018-05-31 am saved.\n",
      "2018-05-31 pm saved.\n",
      "2018-06-01 5:13:00 5:13:00\n",
      "2018-06-01 19:13:00 19:13:00\n",
      "2018-06-01 am saved.\n",
      "2018-06-01 pm saved.\n",
      "2018-06-02 5:13:00 5:13:00\n",
      "2018-06-02 19:13:00 19:13:00\n",
      "2018-06-02 am saved.\n",
      "2018-06-02 pm saved.\n",
      "2018-06-03 5:13:00 5:13:00\n",
      "2018-06-03 19:13:00 19:13:00\n",
      "2018-06-03 am saved.\n",
      "2018-06-03 pm saved.\n",
      "2018-06-05 5:12:00 5:12:00\n",
      "2018-06-05 19:12:00 19:12:00\n",
      "2018-06-05 am saved.\n",
      "2018-06-05 pm saved.\n",
      "2018-06-06 5:12:00 5:12:00\n",
      "2018-06-06 19:12:00 19:12:00\n",
      "2018-06-06 am saved.\n",
      "2018-06-06 pm saved.\n",
      "2018-06-07 5:12:00 5:12:00\n",
      "2018-06-07 19:12:00 19:12:00\n",
      "2018-06-07 am saved.\n",
      "2018-06-07 pm saved.\n",
      "2018-06-08 5:12:00 5:12:00\n",
      "2018-06-08 19:12:00 19:12:00\n",
      "2018-06-08 am saved.\n",
      "2018-06-08 pm saved.\n",
      "2018-06-09 5:11:00 5:11:00\n",
      "2018-06-09 19:11:00 19:11:00\n",
      "2018-06-09 am saved.\n",
      "2018-06-09 pm saved.\n",
      "2018-06-11 5:11:00 5:11:00\n",
      "2018-06-11 19:11:00 19:11:00\n",
      "2018-06-11 am saved.\n",
      "2018-06-11 pm saved.\n",
      "2018-06-13 5:11:00 5:11:00\n",
      "2018-06-13 19:11:00 19:11:00\n",
      "2018-06-13 am saved.\n",
      "2018-06-13 pm saved.\n",
      "2018-06-16 5:11:00 5:11:00\n",
      "2018-06-16 19:11:00 19:11:00\n",
      "2018-06-16 am saved.\n",
      "2018-06-16 pm saved.\n",
      "2018-06-17 5:11:00 5:11:00\n",
      "2018-06-17 19:11:00 19:11:00\n",
      "2018-06-17 am saved.\n",
      "2018-06-17 pm saved.\n",
      "2018-06-18 5:11:00 5:11:00\n",
      "2018-06-18 19:11:00 19:11:00\n",
      "2018-06-18 am saved.\n",
      "2018-06-18 pm saved.\n",
      "2018-06-24 5:13:00 5:13:00\n",
      "2018-06-24 19:13:00 19:13:00\n",
      "2018-06-24 am saved.\n",
      "2018-06-24 pm saved.\n",
      "2018-06-25 5:13:00 5:13:00\n",
      "2018-06-25 19:13:00 19:13:00\n",
      "2018-06-25 am saved.\n",
      "2018-06-25 pm saved.\n"
     ]
    }
   ],
   "source": [
    "# 분별 날짜 파일에 있는 날짜 기준으로 DB에서 데이터 받아와서 저장하기\n",
    "\n",
    "import MySQLdb\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# MySQL DB 연결\n",
    "db = MySQLdb.connect('210.102.142.13',\"root\", \"witlab8*\", \"cas_db\")\n",
    "c = db.cursor()\n",
    "\n",
    "# 분별 날짜\n",
    "# date = np.genfromtxt('../data/date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "date = np.genfromtxt('../data/test_date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "\n",
    "# csv 파일로 내보내기\n",
    "# w = open('../data/db_connect_data_am.csv', 'w', encoding='utf-8')\n",
    "w = open('../data/db_connect_test_data_am.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "# csv 파일로 내보내기\n",
    "# w2 = open('../data/db_connect_data_pm.csv', 'w', encoding='utf-8')\n",
    "w2 = open('../data/db_connect_test_data_pm.csv', 'w', encoding='utf-8')\n",
    "wr2 = csv.writer(w2)\n",
    "\n",
    "# 각 날짜별 데이터들 DB에서 가져오고 csv 파일로 저장\n",
    "# swr, mwr, lwr data 받아옴\n",
    "for j in range(len(date)):\n",
    "    sql = \"select time(date),cas_swr, cas_mwr, cas_lwr from natural_tracker left outer join cas_wave_ratio using(date) where date(date) = '\"+ str(date[j][0]) + \"' order by time(date)\"\n",
    "    c.execute(sql)\n",
    "    rows = c.fetchall()\n",
    "    \n",
    "     # 일출 후 6시간과 일몰 후 6시간 데이터 사용, 일출 혹은 일몰 당시 데이터가 없을 경우 가장 가까운 다른 데이터로 변환\n",
    "    sunrise = datetime.datetime.strptime(date[j][1], '%H:%M:%S')\n",
    "    sunset = datetime.datetime.strptime(date[j][2], '%H:%M:%S')\n",
    "    \n",
    "    standard = datetime.datetime.strptime('1900-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    sunrise = sunrise - standard\n",
    "    sunset = sunset - standard\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if(rows[i][0] >= sunrise):\n",
    "            start = i\n",
    "            print(date[j][0], rows[start][0], sunrise)\n",
    "            break;\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if(rows[i][0] >= sunset):\n",
    "            end = i\n",
    "            print(date[j][0], rows[end][0], sunset)\n",
    "            break;\n",
    "\n",
    "    # start에 저장된 index부터 772개 데이터 가져와서 저장\n",
    "    for l in range(start, start+60):\n",
    "        wr.writerow([rows[l][1], rows[l][2], rows[l][3]])\n",
    "    print(date[j][0] + \" am saved.\")\n",
    "    \n",
    "    for l in range(start+60, start+120):\n",
    "        wr2.writerow([rows[l][1], rows[l][2], rows[l][3]])\n",
    "    print(date[j][0] + \" pm saved.\")\n",
    "        \n",
    "w.close()\n",
    "w2.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = np.genfromtxt('../data/date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "date = np.genfromtxt('../data/test_date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "\n",
    "# import_data = np.loadtxt('../data/db_connect_data_am.csv', delimiter=',')\n",
    "# import_data = np.loadtxt('../data/db_connect_test_data_am.csv', delimiter=',')\n",
    "# import_data = np.loadtxt('../data/db_connect_data_pm.csv', delimiter=',')\n",
    "import_data = np.loadtxt('../data/db_connect_test_data_pm.csv', delimiter=',')\n",
    "\n",
    "one = import_data[:,0] # swr\n",
    "two = import_data[:,1] # mwr\n",
    "thr = import_data[:,2] # lwr\n",
    "\n",
    "swr = []\n",
    "mwr = []\n",
    "lwr = []\n",
    "\n",
    "for cnt in range(len(date)): # 전체 데이터 날짜 수 (행)\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    temp3 = []\n",
    "    for i in range(60): # 한 날짜의 데이터들 한 행에 저장 (열)\n",
    "        temp.append(one[i+60*cnt])\n",
    "        temp2.append(two[i+60*cnt])\n",
    "        temp3.append(thr[i+60*cnt])\n",
    "    swr.append(temp)\n",
    "    mwr.append(temp2)\n",
    "    lwr.append(temp3)\n",
    "\n",
    "# w = open('../data/swr_ratio_calculation_am.csv', 'w', encoding='utf-8')\n",
    "# w = open('../data/swr_ratio_test_calculation_am.csv', 'w', encoding='utf-8')\n",
    "# w = open('../data/swr_ratio_calculation_pm.csv', 'w', encoding='utf-8')\n",
    "w = open('../data/swr_ratio_test_calculation_pm.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range(len(date)):\n",
    "    all_hap = 0\n",
    "    swr_hap = 0\n",
    "    ratio = 0\n",
    "    grade = 0\n",
    "    \n",
    "    for j in range(len(swr[i])):\n",
    "        swr_hap += swr[i][j]\n",
    "        all_hap += swr[i][j] + mwr[i][j] + lwr[i][j]\n",
    "    \n",
    "    ratio = round(swr_hap / all_hap * 100, 2)\n",
    "    \n",
    "    if(ratio >= 18.00):\n",
    "        grade += 1\n",
    "    if(ratio >= 20.00):\n",
    "        grade += 1\n",
    "    if(ratio >= 22.00):\n",
    "        grade += 1\n",
    "    if(ratio >= 24.00):\n",
    "        grade += 1\n",
    "    \n",
    "    wr.writerow([ratio, grade])\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data = np.genfromtxt('../data/swr_ratio_calculation_am.csv', delimiter=',', dtype='float')\n",
    "import_data2 = np.genfromtxt('../data/swr_ratio_test_calculation_am.csv', delimiter=',', dtype='float')\n",
    "w = open('../data/swr_ratio_classification_input_am.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range(len(import_data)):\n",
    "    wr.writerow(import_data[i][:])\n",
    "for i in range(len(import_data2)):\n",
    "    wr.writerow(import_data2[i][:])\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28.150242\n",
      "100 1.3364223\n",
      "200 1.2058318\n",
      "300 1.1678567\n",
      "400 1.129017\n",
      "500 1.0917857\n",
      "600 1.0575277\n",
      "700 1.0268209\n",
      "800 0.9997282\n",
      "900 0.97601604\n",
      "1000 0.9553109\n",
      "1100 0.93719906\n",
      "1200 0.9212826\n",
      "1300 0.9072049\n",
      "1400 0.8946608\n",
      "1500 0.8833945\n",
      "1600 0.87319624\n",
      "1700 0.86389476\n",
      "1800 0.85535145\n",
      "1900 0.847454\n",
      "2000 0.8401117\n",
      "2100 0.8332504\n",
      "2200 0.82680976\n",
      "2300 0.82073975\n",
      "2400 0.8149991\n",
      "2500 0.8095527\n",
      "2600 0.80437154\n",
      "2700 0.79942995\n",
      "2800 0.7947061\n",
      "2900 0.79018086\n",
      "3000 0.78583753\n",
      "3100 0.7816611\n",
      "3200 0.7776383\n",
      "3300 0.7737573\n",
      "3400 0.77000743\n",
      "3500 0.76637924\n",
      "3600 0.76286405\n",
      "3700 0.7594542\n",
      "3800 0.75614274\n",
      "3900 0.75292355\n",
      "4000 0.749791\n",
      "4100 0.74674\n",
      "4200 0.74376607\n",
      "4300 0.74086505\n",
      "4400 0.73803335\n",
      "4500 0.73526764\n",
      "4600 0.73256505\n",
      "4700 0.7299226\n",
      "4800 0.7273381\n",
      "4900 0.7248093\n",
      "5000 0.7223341\n",
      "5100 0.7199107\n",
      "5200 0.7175374\n",
      "5300 0.71521264\n",
      "5400 0.7129352\n",
      "5500 0.71070355\n",
      "5600 0.7085166\n",
      "5700 0.70637316\n",
      "5800 0.7042723\n",
      "5900 0.702213\n",
      "6000 0.70019436\n",
      "6100 0.6982156\n",
      "6200 0.6962758\n",
      "6300 0.69437426\n",
      "6400 0.69251037\n",
      "6500 0.6906833\n",
      "6600 0.6888925\n",
      "6700 0.6871373\n",
      "6800 0.6854172\n",
      "6900 0.68373156\n",
      "7000 0.68208\n",
      "7100 0.6804617\n",
      "7200 0.6788765\n",
      "7300 0.67732364\n",
      "7400 0.67580277\n",
      "7500 0.67431337\n",
      "7600 0.6728551\n",
      "7700 0.6714273\n",
      "7800 0.6700297\n",
      "7900 0.66866636\n",
      "8000 0.6673381\n",
      "8100 0.66603935\n",
      "8200 0.6647783\n",
      "8300 0.6635443\n",
      "8400 0.6623438\n",
      "8500 0.661179\n",
      "8600 0.6600405\n",
      "8700 0.65894914\n",
      "8800 0.65783954\n",
      "8900 0.65678596\n",
      "9000 0.65575373\n",
      "9100 0.6547505\n",
      "9200 0.6537726\n",
      "9300 0.6528232\n",
      "9400 0.6518948\n",
      "9500 0.6509938\n",
      "9600 0.6501137\n",
      "9700 0.6492594\n",
      "9800 0.6484356\n",
      "9900 0.64761513\n",
      "10000 0.64681983\n",
      "10100 0.64605546\n",
      "10200 0.6453175\n",
      "10300 0.64456666\n",
      "10400 0.64388216\n",
      "10500 0.6431584\n",
      "10600 0.6424831\n",
      "10700 0.6418254\n",
      "10800 0.6411876\n",
      "10900 0.6405706\n",
      "11000 0.6399625\n",
      "11100 0.6393736\n",
      "11200 0.6388053\n",
      "11300 0.6382358\n",
      "11400 0.63768756\n",
      "11500 0.6371547\n",
      "11600 0.6366351\n",
      "11700 0.6361301\n",
      "11800 0.63563156\n",
      "11900 0.6351474\n",
      "12000 0.6346769\n",
      "12100 0.6342468\n",
      "12200 0.63376874\n",
      "12300 0.63332075\n",
      "12400 0.63288945\n",
      "12500 0.63246727\n",
      "12600 0.6320511\n",
      "12700 0.63164485\n",
      "12800 0.63124657\n",
      "12900 0.6308564\n",
      "13000 0.6304875\n",
      "13100 0.63011616\n",
      "13200 0.62973267\n",
      "13300 0.62937313\n",
      "13400 0.62901807\n",
      "13500 0.62867033\n",
      "13600 0.62833035\n",
      "13700 0.6280102\n",
      "13800 0.6276673\n",
      "13900 0.627345\n",
      "14000 0.6270264\n",
      "14100 0.62671536\n",
      "14200 0.6264087\n",
      "14300 0.62610865\n",
      "14400 0.62581205\n",
      "14500 0.62552124\n",
      "14600 0.6252364\n",
      "14700 0.6249537\n",
      "14800 0.624679\n",
      "14900 0.62440825\n",
      "15000 0.6241632\n",
      "15100 0.6238794\n",
      "15200 0.62362206\n",
      "15300 0.62337387\n",
      "15400 0.62312293\n",
      "15500 0.6228803\n",
      "15600 0.62263364\n",
      "15700 0.6223969\n",
      "15800 0.62216437\n",
      "15900 0.6219363\n",
      "16000 0.6217107\n",
      "16100 0.62149745\n",
      "16200 0.6212755\n",
      "16300 0.6210545\n",
      "16400 0.6208433\n",
      "16500 0.62066925\n",
      "16600 0.620431\n",
      "16700 0.62039924\n",
      "16800 0.6200298\n",
      "16900 0.61983633\n",
      "17000 0.6196521\n",
      "17100 0.61956674\n",
      "17200 0.6192615\n",
      "17300 0.6190895\n",
      "17400 0.6189596\n",
      "17500 0.61876136\n",
      "17600 0.6185378\n",
      "17700 0.618364\n",
      "17800 0.618199\n",
      "17900 0.61802286\n",
      "18000 0.617857\n",
      "18100 0.61769664\n",
      "18200 0.6175318\n",
      "18300 0.6173722\n",
      "18400 0.61721665\n",
      "18500 0.6170638\n",
      "18600 0.6169083\n",
      "18700 0.6167562\n",
      "18800 0.61660737\n",
      "18900 0.6164618\n",
      "19000 0.6163254\n",
      "19100 0.6161789\n",
      "19200 0.6160359\n",
      "19300 0.61589694\n",
      "19400 0.6157609\n",
      "19500 0.615633\n",
      "19600 0.61550117\n",
      "19700 0.6153684\n",
      "19800 0.6152534\n",
      "19900 0.61513203\n",
      "20000 0.6150265\n",
      "-----------------------------\n",
      "train_data =  85 test_data =  37\n",
      "train accuracy =  9.411764705882353\n",
      "test accuracy =  10.81081081081081\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 모델 생성 위한 import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# 초기값 선정 xavier 알고리즘\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    \n",
    "    if uniform:\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "# 단파장 비율 학습 및 테스트 (편차 분포)\n",
    "\n",
    "import_data = np.genfromtxt('../data/swr_ratio_classification_input_am.csv', delimiter=',', dtype='float')\n",
    "\n",
    "x_data = []\n",
    "for i in range(len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][0])\n",
    "    x_data.append(temp)\n",
    "    \n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# x_data = scaler.fit_transform(x_data)\n",
    "test_x = x_data[85:]\n",
    "x_data = x_data[:85]\n",
    "\n",
    "y_data = []\n",
    "test_y = []\n",
    "\n",
    "for i in range(85):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][1])\n",
    "    y_data.append(temp)\n",
    "\n",
    "raw_y = y_data\n",
    "    \n",
    "for i in range(85, len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][1])\n",
    "    test_y.append(temp)\n",
    "\n",
    "\n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 1])\n",
    "Y = tf.placeholder(\"float\", [None, 5])\n",
    "\n",
    "nb_classes = 5\n",
    "\n",
    "# W = tf.Variable(tf.random_normal([1, nb_classes]), name='weight')\n",
    "# b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# Xavier Initializer 추가 코드\n",
    "W = tf.get_variable(\"W\", shape=[1, nb_classes], initializer=xavier_init(1, nb_classes))\n",
    "b = tf.Variable(tf.zeros([nb_classes]))\n",
    "\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    train_accuracy = 0\n",
    "    test_accuracy = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(20001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "\n",
    "    print('-----------------------------')\n",
    "\n",
    "    print('train_data = ', len(x_data), 'test_data = ', len(test_x))\n",
    "\n",
    "    for i in range(len(x_data)):\n",
    "        a = sess.run(H, feed_dict={X:[x_data[i]]})\n",
    "        if(sess.run(tf.argmax(a, 1)) == (raw_y[i][0] - 1)):\n",
    "            train_accuracy += 1\n",
    "    print(\"train accuracy = \", float(train_accuracy / len(x_data) * 100))\n",
    "    \n",
    "    for i in range(len(test_x)):\n",
    "        a = sess.run(H, feed_dict={X:[test_x[i]]})\n",
    "        if(sess.run(tf.argmax(a, 1)) == (test_y[i][0] - 1)):\n",
    "            test_accuracy += 1\n",
    "    print(\"test accuracy = \", float(test_accuracy / len(test_x) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "20000\n",
    "9\n",
    "10\n",
    "\n",
    "5000\n",
    "10\n",
    "10\n",
    "\n",
    "3000\n",
    "10\n",
    "10\n",
    "\n",
    "1000\n",
    "11\n",
    "10\n",
    "\n",
    "500\n",
    "11\n",
    "10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
