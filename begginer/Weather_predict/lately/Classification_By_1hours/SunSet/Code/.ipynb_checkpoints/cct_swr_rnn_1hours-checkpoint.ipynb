{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-19 5:52:00 5:52:00\n",
      "2018-04-19 19:52:00 19:52:00\n",
      "2018-04-19 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-21 5:49:00 5:49:00\n",
      "2018-04-21 19:49:00 19:49:00\n",
      "2018-04-21 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-26 5:43:00 5:43:00\n",
      "2018-04-26 19:43:00 19:43:00\n",
      "2018-04-26 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-27 5:42:00 5:42:00\n",
      "2018-04-27 19:42:00 19:42:00\n",
      "2018-04-27 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-28 5:41:00 5:41:00\n",
      "2018-04-28 19:41:00 19:41:00\n",
      "2018-04-28 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-29 5:40:00 5:40:00\n",
      "2018-04-29 19:40:00 19:40:00\n",
      "2018-04-29 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-30 5:38:00 5:38:00\n",
      "2018-04-30 19:38:00 19:38:00\n",
      "2018-04-30 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-04 5:34:00 5:34:00\n",
      "2018-05-04 19:34:00 19:34:00\n",
      "2018-05-04 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-05 5:33:00 5:33:00\n",
      "2018-05-05 19:33:00 19:33:00\n",
      "2018-05-05 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-08 5:30:00 5:30:00\n",
      "2018-05-08 19:30:00 19:30:00\n",
      "2018-05-08 828 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-10 5:28:00 5:28:00\n",
      "2018-05-10 19:28:00 19:28:00\n",
      "2018-05-10 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-14 5:24:00 5:24:00\n",
      "2018-05-14 19:24:00 19:24:00\n",
      "2018-05-14 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-19 5:20:00 5:20:00\n",
      "2018-05-19 19:20:00 19:20:00\n",
      "2018-05-19 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-21 5:19:00 5:19:00\n",
      "2018-05-21 19:19:00 19:19:00\n",
      "2018-05-21 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-24 5:17:00 5:17:00\n",
      "2018-05-24 19:17:00 19:17:00\n",
      "2018-05-24 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-25 5:17:00 5:17:00\n",
      "2018-05-25 19:17:00 19:17:00\n",
      "2018-05-25 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-26 5:16:00 5:16:00\n",
      "2018-05-26 19:16:00 19:16:00\n",
      "2018-05-26 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-27 5:16:00 5:16:00\n",
      "2018-05-27 19:16:00 19:16:00\n",
      "2018-05-27 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-28 5:15:00 5:15:00\n",
      "2018-05-28 19:15:00 19:15:00\n",
      "2018-05-28 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-29 5:15:00 5:15:00\n",
      "2018-05-29 19:15:00 19:15:00\n",
      "2018-05-29 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-30 5:14:00 5:14:00\n",
      "2018-05-30 19:14:00 19:14:00\n",
      "2018-05-30 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-31 5:14:00 5:14:00\n",
      "2018-05-31 19:14:00 19:14:00\n",
      "2018-05-31 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-01 5:13:00 5:13:00\n",
      "2018-06-01 19:13:00 19:13:00\n",
      "2018-06-01 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-02 5:13:00 5:13:00\n",
      "2018-06-02 19:13:00 19:13:00\n",
      "2018-06-02 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-03 5:13:00 5:13:00\n",
      "2018-06-03 19:13:00 19:13:00\n",
      "2018-06-03 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-05 5:12:00 5:12:00\n",
      "2018-06-05 19:12:00 19:12:00\n",
      "2018-06-05 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-06 5:12:00 5:12:00\n",
      "2018-06-06 19:12:00 19:12:00\n",
      "2018-06-06 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-07 5:12:00 5:12:00\n",
      "2018-06-07 19:12:00 19:12:00\n",
      "2018-06-07 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-08 5:12:00 5:12:00\n",
      "2018-06-08 19:12:00 19:12:00\n",
      "2018-06-08 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-09 5:11:00 5:11:00\n",
      "2018-06-09 19:11:00 19:11:00\n",
      "2018-06-09 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-11 5:11:00 5:11:00\n",
      "2018-06-11 19:11:00 19:11:00\n",
      "2018-06-11 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-13 5:11:00 5:11:00\n",
      "2018-06-13 19:11:00 19:11:00\n",
      "2018-06-13 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-16 5:11:00 5:11:00\n",
      "2018-06-16 19:11:00 19:11:00\n",
      "2018-06-16 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-17 5:11:00 5:11:00\n",
      "2018-06-17 19:11:00 19:11:00\n",
      "2018-06-17 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-18 5:11:00 5:11:00\n",
      "2018-06-18 19:11:00 19:11:00\n",
      "2018-06-18 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-24 5:13:00 5:13:00\n",
      "2018-06-24 19:13:00 19:13:00\n",
      "2018-06-24 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-25 5:13:00 5:13:00\n",
      "2018-06-25 19:13:00 19:13:00\n",
      "2018-06-25 828 data saved.\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 분별 날짜 파일에 있는 날짜 기준으로 DB에서 데이터 받아와서 저장하기\n",
    "\n",
    "import MySQLdb\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# MySQL DB 연결\n",
    "db = MySQLdb.connect('210.102.142.13',\"root\", \"witlab8*\", \"cas_db\")\n",
    "c = db.cursor()\n",
    "\n",
    "# 분별 날짜\n",
    "# date = np.genfromtxt('../data/date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "date = np.genfromtxt('../data/test_date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "\n",
    "# csv 파일로 내보내기\n",
    "# w = open('../data/db_connect_data_rnn.csv', 'w', encoding='utf-8')\n",
    "w = open('../data/db_connect_test_data_rnn.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "data_length = []\n",
    "\n",
    "# 각 날짜별 데이터들 DB에서 가져오고 csv 파일로 저장\n",
    "# 데이터는 cct, swr, uvb, uvi 순\n",
    "for j in range(len(date)):\n",
    "    sql = \"select time(date), date(date), cct, cas_swr from natural_tracker left outer join cas_wave_ratio using(date) where date(date) = '\"+ str(date[j][0]) + \"' order by time(date)\"\n",
    "    c.execute(sql)\n",
    "    rows = c.fetchall()\n",
    "    \n",
    "    # 일출 후 6시간과 일몰 후 6시간 데이터 사용, 일출 혹은 일몰 당시 데이터가 없을 경우 가장 가까운 다른 데이터로 변환\n",
    "    sunrise = datetime.datetime.strptime(date[j][1], '%H:%M:%S')\n",
    "    sunset = datetime.datetime.strptime(date[j][2], '%H:%M:%S')\n",
    "    \n",
    "    standard = datetime.datetime.strptime('1900-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    sunrise = sunrise - standard\n",
    "    sunset = sunset - standard\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        if(rows[i][0] >= sunrise):\n",
    "            start = i\n",
    "            print(date[j][0], rows[start][0], sunrise)\n",
    "            break;\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if(rows[i][0] >= sunset):\n",
    "            end = i\n",
    "            print(date[j][0], rows[end][0], sunset)\n",
    "            break;\n",
    "    \n",
    "    last = int((end - start) / 4)\n",
    "    last = last * 4\n",
    "    \n",
    "#     # start에 저장된 index부터 772개 데이터 가져와서 저장\n",
    "    for l in range(start, start + last):\n",
    "        wr.writerow([rows[l][2], rows[l][3]])\n",
    "    print(date[j][0] + \" \" + str(last) + \" data saved.\")\n",
    "    for l in range(4):\n",
    "        data_length.append(int(last/4))\n",
    "    print('----------------------------------------------')\n",
    "        \n",
    "w.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = np.genfromtxt('../data/date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "date = np.genfromtxt('../data/test_date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "\n",
    "# 데이터 받아오고 편차 계산히기\n",
    "# import_data = np.loadtxt('../data/db_connect_data_rnn.csv', delimiter=',')\n",
    "import_data = np.loadtxt('../data/db_connect_test_data_rnn.csv', delimiter=',')\n",
    "\n",
    "one = import_data[:,0] # cct\n",
    "two = import_data[:,1] # cas_swr\n",
    "\n",
    "data_index = 0\n",
    "\n",
    "cct = []\n",
    "swr = []\n",
    "\n",
    "delta_cct = []\n",
    "delta_swr = []\n",
    "\n",
    "cct_hap = []\n",
    "swr_hap = []\n",
    "\n",
    "for i in range(len(data_length)):\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    for j in range(data_length[i]):\n",
    "        temp.append(one[j + data_index])\n",
    "        temp2.append(two[j + data_index])\n",
    "    cct.append(temp)\n",
    "    swr.append(temp2)\n",
    "    data_index += data_length[i]\n",
    "\n",
    "for i in range(len(data_length)):\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    for j in range(data_length[i] - 1):\n",
    "        temp.append(cct[i][j+1] - cct[i][j])\n",
    "        temp2.append(swr[i][j+1] - swr[i][j])\n",
    "    delta_cct.append(temp)\n",
    "    delta_swr.append(temp2)\n",
    "    \n",
    "for i in range(len(data_length)):\n",
    "    temp1 = 0\n",
    "    temp2 = 0\n",
    "    for j in range(data_length[i]):\n",
    "        temp1 += cct[i][j]\n",
    "        temp2 += swr[i][j]\n",
    "    cct_hap.append(temp1)\n",
    "    swr_hap.append(temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = open('../data/cct_swr_calculation_rnn.csv', 'w', encoding='utf-8')\n",
    "w = open('../data/cct_swr_calculation_test_rnn.csv', 'w', encoding='utf-8')\n",
    "\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range(len(delta_cct)):\n",
    "    up_dot_25 = 0\n",
    "    up_dot_50 = 0\n",
    "    up_dot_100 = 0\n",
    "    up_dot_150 = 0\n",
    "    up_dot_200 = 0\n",
    "    up_dot_250 = 0\n",
    "    up_dot_300 = 0\n",
    "    up_dot_350 = 0\n",
    "    up_dot_400 = 0\n",
    "    up_dot_450 = 0\n",
    "    up_dot_500 = 0\n",
    "\n",
    "    # 위 변수들을 비율로 계산\n",
    "    percent_1 = 0\n",
    "    percent_2 = 0\n",
    "    percent_3 = 0\n",
    "    percent_4 = 0\n",
    "    percent_5 = 0\n",
    "    percent_6 = 0\n",
    "    percent_7 = 0\n",
    "    percent_8 = 0\n",
    "    percent_9 = 0\n",
    "    percent_10 = 0\n",
    "    percent_11 = 0\n",
    "\n",
    "    # 편차의 합, 평균, 등급 저장\n",
    "    hap = 0\n",
    "    avg = 0\n",
    "    grade = 0\n",
    "\n",
    "    # 편차 절댓값을 기준으로 갯수 저장\n",
    "    for j in range(len(delta_cct[i])):\n",
    "        if(abs(delta_cct[i][j]) >= 25):\n",
    "            up_dot_25 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 50):\n",
    "            up_dot_50 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 100):\n",
    "            up_dot_100 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 150):\n",
    "            up_dot_150 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 200):\n",
    "            up_dot_200 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 250):\n",
    "            up_dot_250 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 300):\n",
    "            up_dot_300 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 350):\n",
    "            up_dot_350 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 400):\n",
    "            up_dot_400 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 450):\n",
    "            up_dot_450 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 500):\n",
    "            up_dot_500 += 1\n",
    "        \n",
    "        # 편차 합 및 평균 저장\n",
    "        hap += abs(delta_cct[i][j])\n",
    "        avg = hap / len(delta_cct[i])\n",
    "\n",
    "        # 편차 갯수들이 차지하는 비율 소수점 둘째짜리까지 계산\n",
    "        percent_1 = round(up_dot_25 / len(cct[i]) * 100, 2)\n",
    "        percent_2 = round(up_dot_50 / len(cct[i]) * 100, 2)\n",
    "        percent_3 = round(up_dot_100 / len(cct[i]) * 100, 2)\n",
    "        percent_4 = round(up_dot_150 / len(cct[i]) * 100, 2)\n",
    "        percent_5 = round(up_dot_200 / len(cct[i]) * 100, 2)\n",
    "        percent_6 = round(up_dot_250 / len(cct[i]) * 100, 2)\n",
    "        percent_7 = round(up_dot_300 / len(cct[i]) * 100, 2)\n",
    "        percent_8 = round(up_dot_350 / len(cct[i]) * 100, 2)\n",
    "        percent_9 = round(up_dot_400 / len(cct[i]) * 100, 2)\n",
    "        percent_10 = round(up_dot_450 / len(cct[i]) * 100, 2)\n",
    "        percent_11 = round(up_dot_500 / len(cct[i]) * 100, 2)\n",
    "\n",
    "    # 등급 선정 기준\n",
    "    if(percent_1 > 30.0):\n",
    "        grade += 1\n",
    "    \n",
    "    if(percent_2 > 20.0):\n",
    "        grade += 1\n",
    "    \n",
    "    if(cct_hap[i] < 950000.0 or cct_hap[i] > 1050000.0):\n",
    "        grade += 1\n",
    "        \n",
    "    if(hap > 15000.0):\n",
    "        grade += 1\n",
    "        \n",
    "        # 편차의 절대값이 0.1 ~ 5이상인 경우의 갯수 저장\n",
    "    up_dot_1 = 0\n",
    "    up_dot_2 = 0\n",
    "    up_dot_3 = 0\n",
    "    up_dot_4 = 0\n",
    "    up_dot_5 = 0\n",
    "    up_dot_6 = 0\n",
    "    up_dot_7 = 0\n",
    "    up_dot_8 = 0\n",
    "    up_dot_9 = 0\n",
    "    up_dot_10 = 0\n",
    "    up_dot_20 = 0\n",
    "    up_dot_30 = 0\n",
    "    up_dot_40 = 0\n",
    "    up_dot_50_2 = 0\n",
    "\n",
    "    # 위의 갯수가 하루 전체 데이터에서 차지하는 비율 저장\n",
    "    percent_1 = 0\n",
    "    percent_2 = 0\n",
    "    percent_3 = 0\n",
    "    percent_4 = 0\n",
    "    percent_5 = 0\n",
    "    percent_6 = 0\n",
    "    percent_7 = 0\n",
    "    percent_8 = 0\n",
    "    percent_9 = 0\n",
    "    percent_10 = 0\n",
    "    percent_20 = 0\n",
    "    percent_30 = 0\n",
    "    percent_40 = 0\n",
    "    percent_50_2 = 0\n",
    "\n",
    "    # 편차의 합, 평균, 등급 저장\n",
    "    hap_2 = 0\n",
    "    avg_2 = 0\n",
    "#     grade = 0\n",
    "\n",
    "    for j in range(len(delta_swr[i])):\n",
    "        if(abs(delta_swr[i][j]) >= 0.1):\n",
    "            up_dot_1 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.2):\n",
    "            up_dot_2 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.3):\n",
    "            up_dot_3 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.4):\n",
    "            up_dot_4 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.5):\n",
    "            up_dot_5 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.6):\n",
    "            up_dot_6 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.7):\n",
    "            up_dot_7 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.8):\n",
    "            up_dot_8 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.9):\n",
    "            up_dot_9 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 1):\n",
    "            up_dot_10 += 1\n",
    "        if(abs(delta_swr[i][j] >= 2)):\n",
    "            up_dot_20 += 1\n",
    "        if(abs(delta_swr[i][j] >= 3)):\n",
    "            up_dot_30 += 1\n",
    "        if(abs(delta_swr[i][j] >= 4)):\n",
    "            up_dot_40 += 1\n",
    "        if(abs(delta_swr[i][j] >= 5)):\n",
    "            up_dot_50_2 += 1\n",
    "\n",
    "        hap_2 += abs(delta_swr[i][j])\n",
    "        avg_2 = hap / len(delta_swr[i])\n",
    "\n",
    "        percent_1 = round(up_dot_1 / len(swr[i]) * 100, 2);\n",
    "        percent_2 = round(up_dot_2 / len(swr[i]) * 100, 2);\n",
    "        percent_3 = round(up_dot_3 / len(swr[i]) * 100, 2);\n",
    "        percent_4 = round(up_dot_4 / len(swr[i]) * 100, 2);\n",
    "        percent_5 = round(up_dot_5 / len(swr[i]) * 100, 2);\n",
    "        percent_6 = round(up_dot_6 / len(swr[i]) * 100, 2);\n",
    "        percent_7 = round(up_dot_7 / len(swr[i]) * 100, 2);\n",
    "        percent_8 = round(up_dot_8 / len(swr[i]) * 100, 2);\n",
    "        percent_9 = round(up_dot_9 / len(swr[i]) * 100, 2);\n",
    "        percent_10 = round(up_dot_10 / len(swr[i]) * 100, 2);\n",
    "        percent_20 = round(up_dot_20 / len(swr[i]) * 100, 2);\n",
    "        percent_30 = round(up_dot_30 / len(swr[i]) * 100, 2);\n",
    "        percent_40 = round(up_dot_40 / len(swr[i]) * 100, 2);\n",
    "        percent_50 = round(up_dot_50 / len(swr[i]) * 100, 2);\n",
    "\n",
    "        # 등급 기준 1\n",
    "#     if(swr_hap[i] <= 15500.0 or swr_hap[i] >= 16500.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     # 등급 기준 2\n",
    "#     # 편차의 절대값이 0.1 이상인 경우가 전체 데이터의 25% + 1, 30%를 넘을 경우 +1, 40%를 넘을 경우 +2, 50%를 넘길 경우 +3\n",
    "#     if(percent_1 >= 25.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     if(percent_1 >= 40.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     # 등급 기준 3\n",
    "#     # 편차의 절대값이 1 이상인 경우가 전체 데이터의 5%를 넘을 경우 +1, 10%를 넘을 경우 +2\n",
    "#     if(percent_10 >= 10.0):\n",
    "#         grade += 1\n",
    "        \n",
    "    wr.writerow([up_dot_25, up_dot_50, up_dot_100, up_dot_150, up_dot_200, up_dot_250, up_dot_300, up_dot_350, up_dot_400, up_dot_450, up_dot_500, up_dot_1, up_dot_2, up_dot_3, up_dot_4, up_dot_5, up_dot_6, up_dot_7, up_dot_8, up_dot_9, up_dot_10, up_dot_20, up_dot_30, up_dot_40, up_dot_50_2, grade])\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0] cost: 1.9927129745483398\n",
      "[step: 1] cost: 1.9058407545089722\n",
      "[step: 2] cost: 1.8317058086395264\n",
      "[step: 3] cost: 1.7720954418182373\n",
      "[step: 4] cost: 1.7275753021240234\n",
      "[step: 5] cost: 1.6964199542999268\n",
      "[step: 6] cost: 1.6752475500106812\n",
      "[step: 7] cost: 1.6605862379074097\n",
      "[step: 8] cost: 1.6498132944107056\n",
      "[step: 9] cost: 1.641206979751587\n",
      "[step: 10] cost: 1.633674144744873\n",
      "[step: 11] cost: 1.626544713973999\n",
      "[step: 12] cost: 1.6194467544555664\n",
      "[step: 13] cost: 1.6122620105743408\n",
      "[step: 14] cost: 1.6050727367401123\n",
      "[step: 15] cost: 1.598044753074646\n",
      "[step: 16] cost: 1.591292381286621\n",
      "[step: 17] cost: 1.5847941637039185\n",
      "[step: 18] cost: 1.5784252882003784\n",
      "[step: 19] cost: 1.5720655918121338\n",
      "[step: 20] cost: 1.5656826496124268\n",
      "[step: 21] cost: 1.5593376159667969\n",
      "[step: 22] cost: 1.553143858909607\n",
      "[step: 23] cost: 1.5472068786621094\n",
      "[step: 24] cost: 1.5415807962417603\n",
      "[step: 25] cost: 1.5362484455108643\n",
      "[step: 26] cost: 1.5311335325241089\n",
      "[step: 27] cost: 1.5261383056640625\n",
      "[step: 28] cost: 1.5211838483810425\n",
      "[step: 29] cost: 1.5162439346313477\n",
      "[step: 30] cost: 1.5113561153411865\n",
      "[step: 31] cost: 1.5066148042678833\n",
      "[step: 32] cost: 1.5021488666534424\n",
      "[step: 33] cost: 1.4980902671813965\n",
      "[step: 34] cost: 1.4945447444915771\n",
      "[step: 35] cost: 1.4915688037872314\n",
      "[step: 36] cost: 1.4891576766967773\n",
      "[step: 37] cost: 1.487248182296753\n",
      "[step: 38] cost: 1.485730528831482\n",
      "[step: 39] cost: 1.4844692945480347\n",
      "[step: 40] cost: 1.4833252429962158\n",
      "[step: 41] cost: 1.482176423072815\n",
      "[step: 42] cost: 1.4809328317642212\n",
      "[step: 43] cost: 1.4795466661453247\n",
      "[step: 44] cost: 1.4780125617980957\n",
      "[step: 45] cost: 1.476362705230713\n",
      "[step: 46] cost: 1.4746557474136353\n",
      "[step: 47] cost: 1.472961664199829\n",
      "[step: 48] cost: 1.471348524093628\n",
      "[step: 49] cost: 1.4698694944381714\n",
      "[step: 50] cost: 1.4685559272766113\n",
      "[step: 51] cost: 1.4674161672592163\n",
      "[step: 52] cost: 1.4664369821548462\n",
      "[step: 53] cost: 1.4655892848968506\n",
      "[step: 54] cost: 1.464835524559021\n",
      "[step: 55] cost: 1.4641361236572266\n",
      "[step: 56] cost: 1.4634562730789185\n",
      "[step: 57] cost: 1.4627691507339478\n",
      "[step: 58] cost: 1.4620577096939087\n",
      "[step: 59] cost: 1.4613161087036133\n",
      "[step: 60] cost: 1.460547924041748\n",
      "[step: 61] cost: 1.4597629308700562\n",
      "[step: 62] cost: 1.4589766263961792\n",
      "[step: 63] cost: 1.4582043886184692\n",
      "[step: 64] cost: 1.4574607610702515\n",
      "[step: 65] cost: 1.4567553997039795\n",
      "[step: 66] cost: 1.4560937881469727\n",
      "[step: 67] cost: 1.455474615097046\n",
      "[step: 68] cost: 1.4548933506011963\n",
      "[step: 69] cost: 1.4543408155441284\n",
      "[step: 70] cost: 1.4538073539733887\n",
      "[step: 71] cost: 1.453283429145813\n",
      "[step: 72] cost: 1.4527620077133179\n",
      "[step: 73] cost: 1.45223867893219\n",
      "[step: 74] cost: 1.4517128467559814\n",
      "[step: 75] cost: 1.4511864185333252\n",
      "[step: 76] cost: 1.4506635665893555\n",
      "[step: 77] cost: 1.4501497745513916\n",
      "[step: 78] cost: 1.4496489763259888\n",
      "[step: 79] cost: 1.4491647481918335\n",
      "[step: 80] cost: 1.44869863986969\n",
      "[step: 81] cost: 1.4482495784759521\n",
      "[step: 82] cost: 1.447816014289856\n",
      "[step: 83] cost: 1.4473950862884521\n",
      "[step: 84] cost: 1.4469836950302124\n",
      "[step: 85] cost: 1.446579098701477\n",
      "[step: 86] cost: 1.4461792707443237\n",
      "[step: 87] cost: 1.4457836151123047\n",
      "[step: 88] cost: 1.4453915357589722\n",
      "[step: 89] cost: 1.445003867149353\n",
      "[step: 90] cost: 1.4446213245391846\n",
      "[step: 91] cost: 1.4442452192306519\n",
      "[step: 92] cost: 1.443875789642334\n",
      "[step: 93] cost: 1.4435139894485474\n",
      "[step: 94] cost: 1.4431593418121338\n",
      "[step: 95] cost: 1.442811369895935\n",
      "[step: 96] cost: 1.4424690008163452\n",
      "[step: 97] cost: 1.4421314001083374\n",
      "[step: 98] cost: 1.4417977333068848\n",
      "[step: 99] cost: 1.4414669275283813\n",
      "[step: 100] cost: 1.4411388635635376\n",
      "[step: 101] cost: 1.4408131837844849\n",
      "[step: 102] cost: 1.4404902458190918\n",
      "[step: 103] cost: 1.4401699304580688\n",
      "[step: 104] cost: 1.4398527145385742\n",
      "[step: 105] cost: 1.439538836479187\n",
      "[step: 106] cost: 1.4392282962799072\n",
      "[step: 107] cost: 1.4389209747314453\n",
      "[step: 108] cost: 1.4386167526245117\n",
      "[step: 109] cost: 1.4383149147033691\n",
      "[step: 110] cost: 1.4380158185958862\n",
      "[step: 111] cost: 1.4377188682556152\n",
      "[step: 112] cost: 1.4374234676361084\n",
      "[step: 113] cost: 1.4371299743652344\n",
      "[step: 114] cost: 1.4368380308151245\n",
      "[step: 115] cost: 1.4365479946136475\n",
      "[step: 116] cost: 1.4362596273422241\n",
      "[step: 117] cost: 1.4359731674194336\n",
      "[step: 118] cost: 1.4356887340545654\n",
      "[step: 119] cost: 1.4354060888290405\n",
      "[step: 120] cost: 1.4351252317428589\n",
      "[step: 121] cost: 1.434846043586731\n",
      "[step: 122] cost: 1.4345682859420776\n",
      "[step: 123] cost: 1.4342923164367676\n",
      "[step: 124] cost: 1.4340176582336426\n",
      "[step: 125] cost: 1.4337444305419922\n",
      "[step: 126] cost: 1.4334725141525269\n",
      "[step: 127] cost: 1.433201789855957\n",
      "[step: 128] cost: 1.4329324960708618\n",
      "[step: 129] cost: 1.4326645135879517\n",
      "[step: 130] cost: 1.4323979616165161\n",
      "[step: 131] cost: 1.4321328401565552\n",
      "[step: 132] cost: 1.4318689107894897\n",
      "[step: 133] cost: 1.4316062927246094\n",
      "[step: 134] cost: 1.4313451051712036\n",
      "[step: 135] cost: 1.4310849905014038\n",
      "[step: 136] cost: 1.43082594871521\n",
      "[step: 137] cost: 1.4305682182312012\n",
      "[step: 138] cost: 1.4303117990493774\n",
      "[step: 139] cost: 1.430056095123291\n",
      "[step: 140] cost: 1.4298018217086792\n",
      "[step: 141] cost: 1.4295485019683838\n",
      "[step: 142] cost: 1.4292964935302734\n",
      "[step: 143] cost: 1.4290457963943481\n",
      "[step: 144] cost: 1.4287959337234497\n",
      "[step: 145] cost: 1.4285473823547363\n",
      "[step: 146] cost: 1.428299903869629\n",
      "[step: 147] cost: 1.4280531406402588\n",
      "[step: 148] cost: 1.4278078079223633\n",
      "[step: 149] cost: 1.4275634288787842\n",
      "[step: 150] cost: 1.427320122718811\n",
      "[step: 151] cost: 1.4270778894424438\n",
      "[step: 152] cost: 1.4268368482589722\n",
      "[step: 153] cost: 1.4265966415405273\n",
      "[step: 154] cost: 1.426357626914978\n",
      "[step: 155] cost: 1.4261196851730347\n",
      "[step: 156] cost: 1.4258825778961182\n",
      "[step: 157] cost: 1.4256467819213867\n",
      "[step: 158] cost: 1.4254119396209717\n",
      "[step: 159] cost: 1.4251779317855835\n",
      "[step: 160] cost: 1.4249451160430908\n",
      "[step: 161] cost: 1.4247132539749146\n",
      "[step: 162] cost: 1.4244823455810547\n",
      "[step: 163] cost: 1.4242525100708008\n",
      "[step: 164] cost: 1.4240238666534424\n",
      "[step: 165] cost: 1.4237959384918213\n",
      "[step: 166] cost: 1.4235690832138062\n",
      "[step: 167] cost: 1.423343300819397\n",
      "[step: 168] cost: 1.423118233680725\n",
      "[step: 169] cost: 1.4228943586349487\n",
      "[step: 170] cost: 1.4226715564727783\n",
      "[step: 171] cost: 1.4224495887756348\n",
      "[step: 172] cost: 1.4222286939620972\n",
      "[step: 173] cost: 1.4220086336135864\n",
      "[step: 174] cost: 1.4217897653579712\n",
      "[step: 175] cost: 1.4215714931488037\n",
      "[step: 176] cost: 1.4213545322418213\n",
      "[step: 177] cost: 1.421138048171997\n",
      "[step: 178] cost: 1.420922875404358\n",
      "[step: 179] cost: 1.4207086563110352\n",
      "[step: 180] cost: 1.4204952716827393\n",
      "[step: 181] cost: 1.4202827215194702\n",
      "[step: 182] cost: 1.4200711250305176\n",
      "[step: 183] cost: 1.419860601425171\n",
      "[step: 184] cost: 1.419650912284851\n",
      "[step: 185] cost: 1.419441819190979\n",
      "[step: 186] cost: 1.4192339181900024\n",
      "[step: 187] cost: 1.4190269708633423\n",
      "[step: 188] cost: 1.418820858001709\n",
      "[step: 189] cost: 1.4186155796051025\n",
      "[step: 190] cost: 1.4184112548828125\n",
      "[step: 191] cost: 1.4182076454162598\n",
      "[step: 192] cost: 1.4180048704147339\n",
      "[step: 193] cost: 1.4178029298782349\n",
      "[step: 194] cost: 1.4176020622253418\n",
      "[step: 195] cost: 1.417401909828186\n",
      "[step: 196] cost: 1.4172025918960571\n",
      "[step: 197] cost: 1.417004108428955\n",
      "[step: 198] cost: 1.4168065786361694\n",
      "[step: 199] cost: 1.416609525680542\n",
      "[step: 200] cost: 1.41641366481781\n",
      "[step: 201] cost: 1.4162181615829468\n",
      "[step: 202] cost: 1.416023850440979\n",
      "[step: 203] cost: 1.415830135345459\n",
      "[step: 204] cost: 1.4156372547149658\n",
      "[step: 205] cost: 1.4154452085494995\n",
      "[step: 206] cost: 1.4152536392211914\n",
      "[step: 207] cost: 1.4150632619857788\n",
      "[step: 208] cost: 1.4148732423782349\n",
      "[step: 209] cost: 1.4146841764450073\n",
      "[step: 210] cost: 1.414495825767517\n",
      "[step: 211] cost: 1.4143083095550537\n",
      "[step: 212] cost: 1.414121150970459\n",
      "[step: 213] cost: 1.4139351844787598\n",
      "[step: 214] cost: 1.4137494564056396\n",
      "[step: 215] cost: 1.4135645627975464\n",
      "[step: 216] cost: 1.413380742073059\n",
      "[step: 217] cost: 1.4131971597671509\n",
      "[step: 218] cost: 1.4130144119262695\n",
      "[step: 219] cost: 1.412832260131836\n",
      "[step: 220] cost: 1.4126508235931396\n",
      "[step: 221] cost: 1.4124701023101807\n",
      "[step: 222] cost: 1.412290096282959\n",
      "[step: 223] cost: 1.4121105670928955\n",
      "[step: 224] cost: 1.4119317531585693\n",
      "[step: 225] cost: 1.4117534160614014\n",
      "[step: 226] cost: 1.4115756750106812\n",
      "[step: 227] cost: 1.4113988876342773\n",
      "[step: 228] cost: 1.4112223386764526\n",
      "[step: 229] cost: 1.4110466241836548\n",
      "[step: 230] cost: 1.4108716249465942\n",
      "[step: 231] cost: 1.4106969833374023\n",
      "[step: 232] cost: 1.4105229377746582\n",
      "[step: 233] cost: 1.4103494882583618\n",
      "[step: 234] cost: 1.4101767539978027\n",
      "[step: 235] cost: 1.4100042581558228\n",
      "[step: 236] cost: 1.40983247756958\n",
      "[step: 237] cost: 1.4096612930297852\n",
      "[step: 238] cost: 1.4094905853271484\n",
      "[step: 239] cost: 1.4093204736709595\n",
      "[step: 240] cost: 1.4091508388519287\n",
      "[step: 241] cost: 1.4089819192886353\n",
      "[step: 242] cost: 1.408813238143921\n",
      "[step: 243] cost: 1.4086450338363647\n",
      "[step: 244] cost: 1.408477544784546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 245] cost: 1.4083105325698853\n",
      "[step: 246] cost: 1.4081441164016724\n",
      "[step: 247] cost: 1.4079780578613281\n",
      "[step: 248] cost: 1.4078123569488525\n",
      "[step: 249] cost: 1.4076472520828247\n",
      "[step: 250] cost: 1.407482624053955\n",
      "[step: 251] cost: 1.4073184728622437\n",
      "[step: 252] cost: 1.4071547985076904\n",
      "[step: 253] cost: 1.4069916009902954\n",
      "[step: 254] cost: 1.406828761100769\n",
      "[step: 255] cost: 1.4066663980484009\n",
      "[step: 256] cost: 1.406504511833191\n",
      "[step: 257] cost: 1.4063431024551392\n",
      "[step: 258] cost: 1.406182050704956\n",
      "[step: 259] cost: 1.4060214757919312\n",
      "[step: 260] cost: 1.4058611392974854\n",
      "[step: 261] cost: 1.4057016372680664\n",
      "[step: 262] cost: 1.4055421352386475\n",
      "[step: 263] cost: 1.4053831100463867\n",
      "[step: 264] cost: 1.4052246809005737\n",
      "[step: 265] cost: 1.4050664901733398\n",
      "[step: 266] cost: 1.4049088954925537\n",
      "[step: 267] cost: 1.4047514200210571\n",
      "[step: 268] cost: 1.4045946598052979\n",
      "[step: 269] cost: 1.4044378995895386\n",
      "[step: 270] cost: 1.4042819738388062\n",
      "[step: 271] cost: 1.4041260480880737\n",
      "[step: 272] cost: 1.403970718383789\n",
      "[step: 273] cost: 1.4038156270980835\n",
      "[step: 274] cost: 1.4036608934402466\n",
      "[step: 275] cost: 1.4035066366195679\n",
      "[step: 276] cost: 1.4033526182174683\n",
      "[step: 277] cost: 1.4031990766525269\n",
      "[step: 278] cost: 1.4030457735061646\n",
      "[step: 279] cost: 1.402892827987671\n",
      "[step: 280] cost: 1.402740240097046\n",
      "[step: 281] cost: 1.4025880098342896\n",
      "[step: 282] cost: 1.4024362564086914\n",
      "[step: 283] cost: 1.4022846221923828\n",
      "[step: 284] cost: 1.4021334648132324\n",
      "[step: 285] cost: 1.4019825458526611\n",
      "[step: 286] cost: 1.401832103729248\n",
      "[step: 287] cost: 1.401681900024414\n",
      "[step: 288] cost: 1.4015319347381592\n",
      "[step: 289] cost: 1.401382327079773\n",
      "[step: 290] cost: 1.4012330770492554\n",
      "[step: 291] cost: 1.401084065437317\n",
      "[step: 292] cost: 1.400935411453247\n",
      "[step: 293] cost: 1.400787115097046\n",
      "[step: 294] cost: 1.4006389379501343\n",
      "[step: 295] cost: 1.40049147605896\n",
      "[step: 296] cost: 1.400343894958496\n",
      "[step: 297] cost: 1.4001967906951904\n",
      "[step: 298] cost: 1.4000500440597534\n",
      "[step: 299] cost: 1.3999032974243164\n",
      "[step: 300] cost: 1.3997570276260376\n",
      "[step: 301] cost: 1.3996111154556274\n",
      "[step: 302] cost: 1.3994654417037964\n",
      "[step: 303] cost: 1.3993200063705444\n",
      "[step: 304] cost: 1.3991748094558716\n",
      "[step: 305] cost: 1.3990299701690674\n",
      "[step: 306] cost: 1.3988852500915527\n",
      "[step: 307] cost: 1.3987412452697754\n",
      "[step: 308] cost: 1.3985971212387085\n",
      "[step: 309] cost: 1.3984533548355103\n",
      "[step: 310] cost: 1.3983098268508911\n",
      "[step: 311] cost: 1.3981666564941406\n",
      "[step: 312] cost: 1.3980234861373901\n",
      "[step: 313] cost: 1.3978809118270874\n",
      "[step: 314] cost: 1.3977383375167847\n",
      "[step: 315] cost: 1.3975963592529297\n",
      "[step: 316] cost: 1.3974542617797852\n",
      "[step: 317] cost: 1.3973126411437988\n",
      "[step: 318] cost: 1.3971712589263916\n",
      "[step: 319] cost: 1.3970301151275635\n",
      "[step: 320] cost: 1.396889090538025\n",
      "[step: 321] cost: 1.396748423576355\n",
      "[step: 322] cost: 1.3966078758239746\n",
      "[step: 323] cost: 1.3964678049087524\n",
      "[step: 324] cost: 1.3963277339935303\n",
      "[step: 325] cost: 1.3961881399154663\n",
      "[step: 326] cost: 1.3960485458374023\n",
      "[step: 327] cost: 1.395909309387207\n",
      "[step: 328] cost: 1.3957703113555908\n",
      "[step: 329] cost: 1.3956315517425537\n",
      "[step: 330] cost: 1.3954930305480957\n",
      "[step: 331] cost: 1.3953546285629272\n",
      "[step: 332] cost: 1.3952165842056274\n",
      "[step: 333] cost: 1.3950785398483276\n",
      "[step: 334] cost: 1.3949410915374756\n",
      "[step: 335] cost: 1.394803524017334\n",
      "[step: 336] cost: 1.394666314125061\n",
      "[step: 337] cost: 1.3945294618606567\n",
      "[step: 338] cost: 1.394392728805542\n",
      "[step: 339] cost: 1.3942561149597168\n",
      "[step: 340] cost: 1.3941198587417603\n",
      "[step: 341] cost: 1.3939836025238037\n",
      "[step: 342] cost: 1.3938477039337158\n",
      "[step: 343] cost: 1.3937119245529175\n",
      "[step: 344] cost: 1.3935766220092773\n",
      "[step: 345] cost: 1.3934412002563477\n",
      "[step: 346] cost: 1.3933062553405762\n",
      "[step: 347] cost: 1.3931711912155151\n",
      "[step: 348] cost: 1.3930366039276123\n",
      "[step: 349] cost: 1.3929022550582886\n",
      "[step: 350] cost: 1.3927679061889648\n",
      "[step: 351] cost: 1.3926339149475098\n",
      "[step: 352] cost: 1.3925000429153442\n",
      "[step: 353] cost: 1.3923662900924683\n",
      "[step: 354] cost: 1.3922327756881714\n",
      "[step: 355] cost: 1.3920994997024536\n",
      "[step: 356] cost: 1.391966462135315\n",
      "[step: 357] cost: 1.3918335437774658\n",
      "[step: 358] cost: 1.3917008638381958\n",
      "[step: 359] cost: 1.3915683031082153\n",
      "[step: 360] cost: 1.3914361000061035\n",
      "[step: 361] cost: 1.3913040161132812\n",
      "[step: 362] cost: 1.391171932220459\n",
      "[step: 363] cost: 1.3910402059555054\n",
      "[step: 364] cost: 1.3909088373184204\n",
      "[step: 365] cost: 1.3907772302627563\n",
      "[step: 366] cost: 1.3906461000442505\n",
      "[step: 367] cost: 1.3905150890350342\n",
      "[step: 368] cost: 1.3903840780258179\n",
      "[step: 369] cost: 1.3902535438537598\n",
      "[step: 370] cost: 1.3901230096817017\n",
      "[step: 371] cost: 1.3899927139282227\n",
      "[step: 372] cost: 1.3898626565933228\n",
      "[step: 373] cost: 1.3897325992584229\n",
      "[step: 374] cost: 1.3896028995513916\n",
      "[step: 375] cost: 1.3894730806350708\n",
      "[step: 376] cost: 1.3893437385559082\n",
      "[step: 377] cost: 1.3892143964767456\n",
      "[step: 378] cost: 1.3890854120254517\n",
      "[step: 379] cost: 1.3889563083648682\n",
      "[step: 380] cost: 1.3888275623321533\n",
      "[step: 381] cost: 1.388698935508728\n",
      "[step: 382] cost: 1.3885704278945923\n",
      "[step: 383] cost: 1.388442039489746\n",
      "[step: 384] cost: 1.388314127922058\n",
      "[step: 385] cost: 1.388185977935791\n",
      "[step: 386] cost: 1.3880583047866821\n",
      "[step: 387] cost: 1.3879305124282837\n",
      "[step: 388] cost: 1.387803077697754\n",
      "[step: 389] cost: 1.3876757621765137\n",
      "[step: 390] cost: 1.387548565864563\n",
      "[step: 391] cost: 1.3874216079711914\n",
      "[step: 392] cost: 1.3872947692871094\n",
      "[step: 393] cost: 1.3871679306030273\n",
      "[step: 394] cost: 1.3870413303375244\n",
      "[step: 395] cost: 1.3869149684906006\n",
      "[step: 396] cost: 1.3867887258529663\n",
      "[step: 397] cost: 1.3866626024246216\n",
      "[step: 398] cost: 1.386536717414856\n",
      "[step: 399] cost: 1.3864108324050903\n",
      "[step: 400] cost: 1.3862851858139038\n",
      "[step: 401] cost: 1.3861596584320068\n",
      "[step: 402] cost: 1.3860342502593994\n",
      "[step: 403] cost: 1.3859089612960815\n",
      "[step: 404] cost: 1.3857837915420532\n",
      "[step: 405] cost: 1.3856589794158936\n",
      "[step: 406] cost: 1.3855341672897339\n",
      "[step: 407] cost: 1.3854094743728638\n",
      "[step: 408] cost: 1.3852850198745728\n",
      "[step: 409] cost: 1.3851606845855713\n",
      "[step: 410] cost: 1.3850363492965698\n",
      "[step: 411] cost: 1.3849122524261475\n",
      "[step: 412] cost: 1.3847882747650146\n",
      "[step: 413] cost: 1.3846644163131714\n",
      "[step: 414] cost: 1.3845405578613281\n",
      "[step: 415] cost: 1.3844170570373535\n",
      "[step: 416] cost: 1.384293794631958\n",
      "[step: 417] cost: 1.3841702938079834\n",
      "[step: 418] cost: 1.3840471506118774\n",
      "[step: 419] cost: 1.383924126625061\n",
      "[step: 420] cost: 1.3838012218475342\n",
      "[step: 421] cost: 1.3836784362792969\n",
      "[step: 422] cost: 1.3835556507110596\n",
      "[step: 423] cost: 1.383433222770691\n",
      "[step: 424] cost: 1.3833110332489014\n",
      "[step: 425] cost: 1.3831886053085327\n",
      "[step: 426] cost: 1.3830664157867432\n",
      "[step: 427] cost: 1.3829443454742432\n",
      "[step: 428] cost: 1.3828225135803223\n",
      "[step: 429] cost: 1.3827006816864014\n",
      "[step: 430] cost: 1.3825790882110596\n",
      "[step: 431] cost: 1.3824576139450073\n",
      "[step: 432] cost: 1.382336139678955\n",
      "[step: 433] cost: 1.3822147846221924\n",
      "[step: 434] cost: 1.3820936679840088\n",
      "[step: 435] cost: 1.3819726705551147\n",
      "[step: 436] cost: 1.3818516731262207\n",
      "[step: 437] cost: 1.3817310333251953\n",
      "[step: 438] cost: 1.3816101551055908\n",
      "[step: 439] cost: 1.381489634513855\n",
      "[step: 440] cost: 1.3813692331314087\n",
      "[step: 441] cost: 1.3812488317489624\n",
      "[step: 442] cost: 1.3811284303665161\n",
      "[step: 443] cost: 1.381008505821228\n",
      "[step: 444] cost: 1.3808884620666504\n",
      "[step: 445] cost: 1.3807685375213623\n",
      "[step: 446] cost: 1.3806487321853638\n",
      "[step: 447] cost: 1.3805291652679443\n",
      "[step: 448] cost: 1.3804094791412354\n",
      "[step: 449] cost: 1.3802902698516846\n",
      "[step: 450] cost: 1.3801707029342651\n",
      "[step: 451] cost: 1.380051612854004\n",
      "[step: 452] cost: 1.3799324035644531\n",
      "[step: 453] cost: 1.3798134326934814\n",
      "[step: 454] cost: 1.3796945810317993\n",
      "[step: 455] cost: 1.3795756101608276\n",
      "[step: 456] cost: 1.3794569969177246\n",
      "[step: 457] cost: 1.3793383836746216\n",
      "[step: 458] cost: 1.3792197704315186\n",
      "[step: 459] cost: 1.3791016340255737\n",
      "[step: 460] cost: 1.3789833784103394\n",
      "[step: 461] cost: 1.378865122795105\n",
      "[step: 462] cost: 1.3787471055984497\n",
      "[step: 463] cost: 1.378629207611084\n",
      "[step: 464] cost: 1.3785111904144287\n",
      "[step: 465] cost: 1.3783934116363525\n",
      "[step: 466] cost: 1.378275752067566\n",
      "[step: 467] cost: 1.3781583309173584\n",
      "[step: 468] cost: 1.3780406713485718\n",
      "[step: 469] cost: 1.3779233694076538\n",
      "[step: 470] cost: 1.3778060674667358\n",
      "[step: 471] cost: 1.377689003944397\n",
      "[step: 472] cost: 1.3775718212127686\n",
      "[step: 473] cost: 1.3774549961090088\n",
      "[step: 474] cost: 1.3773380517959595\n",
      "[step: 475] cost: 1.3772212266921997\n",
      "[step: 476] cost: 1.377104640007019\n",
      "[step: 477] cost: 1.3769878149032593\n",
      "[step: 478] cost: 1.3768715858459473\n",
      "[step: 479] cost: 1.3767549991607666\n",
      "[step: 480] cost: 1.376638650894165\n",
      "[step: 481] cost: 1.376522421836853\n",
      "[step: 482] cost: 1.3764063119888306\n",
      "[step: 483] cost: 1.3762903213500977\n",
      "[step: 484] cost: 1.3761743307113647\n",
      "[step: 485] cost: 1.3760584592819214\n",
      "[step: 486] cost: 1.375942587852478\n",
      "[step: 487] cost: 1.3758269548416138\n",
      "[step: 488] cost: 1.375711441040039\n",
      "[step: 489] cost: 1.3755959272384644\n",
      "[step: 490] cost: 1.3754804134368896\n",
      "[step: 491] cost: 1.375365138053894\n",
      "[step: 492] cost: 1.3752497434616089\n",
      "[step: 493] cost: 1.3751347064971924\n",
      "[step: 494] cost: 1.3750196695327759\n",
      "[step: 495] cost: 1.3749046325683594\n",
      "[step: 496] cost: 1.374789834022522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 497] cost: 1.3746747970581055\n",
      "[step: 498] cost: 1.374559998512268\n",
      "[step: 499] cost: 1.3744455575942993\n",
      "[step: 500] cost: 1.3743308782577515\n",
      "[step: 501] cost: 1.3742163181304932\n",
      "[step: 502] cost: 1.374101996421814\n",
      "[step: 503] cost: 1.3739876747131348\n",
      "[step: 504] cost: 1.3738734722137451\n",
      "[step: 505] cost: 1.373759150505066\n",
      "[step: 506] cost: 1.3736451864242554\n",
      "[step: 507] cost: 1.3735311031341553\n",
      "[step: 508] cost: 1.3734172582626343\n",
      "[step: 509] cost: 1.3733032941818237\n",
      "[step: 510] cost: 1.3731894493103027\n",
      "[step: 511] cost: 1.3730759620666504\n",
      "[step: 512] cost: 1.3729621171951294\n",
      "[step: 513] cost: 1.3728487491607666\n",
      "[step: 514] cost: 1.3727350234985352\n",
      "[step: 515] cost: 1.3726216554641724\n",
      "[step: 516] cost: 1.3725084066390991\n",
      "[step: 517] cost: 1.3723951578140259\n",
      "[step: 518] cost: 1.3722819089889526\n",
      "[step: 519] cost: 1.372168779373169\n",
      "[step: 520] cost: 1.3720557689666748\n",
      "[step: 521] cost: 1.3719429969787598\n",
      "[step: 522] cost: 1.3718299865722656\n",
      "[step: 523] cost: 1.3717172145843506\n",
      "[step: 524] cost: 1.371604323387146\n",
      "[step: 525] cost: 1.3714916706085205\n",
      "[step: 526] cost: 1.371379017829895\n",
      "[step: 527] cost: 1.3712663650512695\n",
      "[step: 528] cost: 1.3711539506912231\n",
      "[step: 529] cost: 1.3710415363311768\n",
      "[step: 530] cost: 1.3709293603897095\n",
      "학습 정확도: 0.42352942\n",
      "테스트 정확도: 0.3537415\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "ohe = OneHotEncoder()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "import_data = np.genfromtxt('../data/cct_swr_calculation_rnn.csv', delimiter=',', dtype='float')\n",
    "\n",
    "x_data = import_data[:, :25]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "x_data = x_data[:, :25]\n",
    "\n",
    "y_data = []\n",
    "test_y = []\n",
    "\n",
    "for i in range(len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][25])\n",
    "    y_data.append(temp)\n",
    "\n",
    "raw_y = y_data\n",
    "    \n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "seq_length = 1\n",
    "data_dim = 25\n",
    "hidden_dim = 50\n",
    "output_dim = 5\n",
    "learning_rate = 0.001\n",
    "iterations = 531\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(len(x_data) - seq_length):\n",
    "    _x = x_data[i:i + seq_length]\n",
    "    _y = y_data[i+seq_length]\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)\n",
    "\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "trainX, testX = np.array(dataX[0:train_size]), np.array(dataX[train_size:len(dataX)])\n",
    "trainY, testY = np.array(dataY[0:train_size]), np.array(dataY[train_size:len(dataY)])\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, output_dim])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([hidden_dim, output_dim]))\n",
    "b = tf.Variable(tf.random_normal([output_dim]))\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(hidden_dim)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "writer = tf.summary.FileWriter(\"./logs/rnn_logs\", sess.graph)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "for i in range(iterations):\n",
    "    _, step_cost = sess.run([optimizer, cost], feed_dict={X:trainX, Y:trainY})\n",
    "    print(\"[step: {}] cost: {}\".format(i, step_cost))\n",
    "    summary, acc = sess.run([merged, accuracy], feed_dict={X:testX, Y:testY})\n",
    "    writer.add_summary(summary, i)\n",
    "\n",
    "print('학습 정확도:', sess.run(accuracy, feed_dict={X:trainX, Y:trainY}))\n",
    "print('테스트 정확도:', sess.run(accuracy, feed_dict={X:testX, Y:testY}))\n",
    "\n",
    "# for i in range(len(trainX)):\n",
    "#     a = sess.run(model, feed_dict={X:[trainX[i]]})\n",
    "#     b = sess.run(Y, feed_dict={X:[trainX[i]]})\n",
    "#     print(sess.run(tf.argmax(a, 1)), \", \", sess.run(tf.argmax(b, 1)))\n",
    "\n",
    "# cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)\n",
    "# outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "# Y_pred = tf.contrib.layers.fully_connected(outputs[:, -1], output_dim, activation_fn=tf.nn.softmax)\n",
    "\n",
    "# loss = tf.reduce_sum(tf.square(Y_pred - Y))\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# train = optimizer.minimize(loss)\n",
    "\n",
    "# targets = tf.placeholder(tf.float32, [None, 5])\n",
    "# predictions = tf.placeholder(tf.float32, [None, 5])\n",
    "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "    \n",
    "#     for i in range(iterations):\n",
    "#         _, step_loss = sess.run([train, loss], feed_dict={X:trainX, Y:trainY})\n",
    "#         print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "        \n",
    "#     test_predict = sess.run(Y_pred, feed_dict={X:testX})\n",
    "#     rmse_val = sess.run(rmse, feed_dict={targets:testY, predictions:test_predict})\n",
    "#     print(\"RMSE:{}\".format(rmse_val))\n",
    "    \n",
    "#     print(sess.run(tf.argmax(test_predict, 1)))\n",
    "#     print(len(dataX), len(trainX), len(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-760073b0b4bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;36m21.78\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RNN' is not defined"
     ]
    }
   ],
   "source": [
    "RNN\n",
    "30\n",
    "29.45\n",
    "\n",
    "50\n",
    "33.56\n",
    "\n",
    "100\n",
    "34.93\n",
    "\n",
    "150\n",
    "33.56\n",
    "\n",
    "200\n",
    "34.24\n",
    "\n",
    "250\n",
    "34.93\n",
    "\n",
    "300\n",
    "37.67\n",
    "\n",
    "350\n",
    "39.04\n",
    "\n",
    "400\n",
    "36.3\n",
    "\n",
    "531\n",
    "41.09\n",
    "\n",
    "LSTM\n",
    "219\n",
    "34.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
