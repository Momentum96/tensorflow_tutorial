{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.2960602\n",
      "100 1.2277786\n",
      "200 1.1997769\n",
      "300 1.1747309\n",
      "400 1.1514864\n",
      "500 1.1298746\n",
      "600 1.109834\n",
      "700 1.0912719\n",
      "800 1.074065\n",
      "900 1.0580753\n",
      "1000 1.0431656\n",
      "1100 1.0292066\n",
      "1200 1.0160819\n",
      "1300 1.0036875\n",
      "1400 0.9919336\n",
      "1500 0.98074216\n",
      "1600 0.97004646\n",
      "1700 0.95978934\n",
      "1800 0.9499223\n",
      "1900 0.94040394\n",
      "2000 0.9311994\n",
      "2100 0.9222786\n",
      "2200 0.9136168\n",
      "2300 0.90519226\n",
      "2400 0.8969873\n",
      "2500 0.88898647\n",
      "2600 0.8811769\n",
      "2700 0.87354755\n",
      "2800 0.86608905\n",
      "2900 0.85879296\n",
      "3000 0.85165244\n",
      "3100 0.8446611\n",
      "3200 0.83781326\n",
      "3300 0.8311042\n",
      "3400 0.82452923\n",
      "3500 0.8180843\n",
      "3600 0.8117654\n",
      "3700 0.80556875\n",
      "3800 0.799491\n",
      "3900 0.7935291\n",
      "4000 0.78767943\n",
      "4100 0.7819394\n",
      "4200 0.7763056\n",
      "4300 0.77077574\n",
      "4400 0.7653469\n",
      "4500 0.7600163\n",
      "4600 0.7547815\n",
      "4700 0.74964\n",
      "4800 0.74458945\n",
      "4900 0.7396274\n",
      "5000 0.7347517\n",
      "5100 0.7299601\n",
      "5200 0.7252503\n",
      "5300 0.7206206\n",
      "5400 0.71606857\n",
      "5500 0.71159256\n",
      "5600 0.7071906\n",
      "5700 0.7028607\n",
      "5800 0.6986012\n",
      "5900 0.6944104\n",
      "6000 0.6902865\n",
      "6100 0.68622786\n",
      "6200 0.68223286\n",
      "6300 0.67829996\n",
      "6400 0.6744278\n",
      "-----------------------------\n",
      "train_data =  86 test_data =  37\n",
      "[2] [1.0]\n",
      "[2] [2.0]\n",
      "[4] [3.0]\n",
      "[2] [0.0]\n",
      "[3] [3.0]\n",
      "[2] [0.0]\n",
      "[2] [1.0]\n",
      "[4] [4.0]\n",
      "[3] [2.0]\n",
      "[2] [2.0]\n",
      "[3] [2.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[3] [3.0]\n",
      "[4] [3.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[2] [2.0]\n",
      "[3] [3.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[3] [3.0]\n",
      "[4] [4.0]\n",
      "[3] [3.0]\n",
      "[3] [3.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "accuracy =  78.37837837837837\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 모델 생성 위한 import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# 초기값 선정 xavier 알고리즘\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    \n",
    "    if uniform:\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "# 색온도 학습 및 테스트 (편차 분포)\n",
    "\n",
    "import_data = np.genfromtxt('./../swr_area_test.csv', delimiter=',', dtype='float')\n",
    "\n",
    "x_data = import_data[:, :2]\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "test_x = x_data[86:, :2]\n",
    "x_data = x_data[:86, :2]\n",
    "\n",
    "y_data = []\n",
    "test_y = []\n",
    "\n",
    "for i in range(86):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][2])\n",
    "    y_data.append(temp)\n",
    "\n",
    "raw_y = y_data\n",
    "    \n",
    "for i in range(86, len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][2])\n",
    "    test_y.append(temp)\n",
    "    \n",
    "# raw_y = y_data\n",
    "\n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 2])\n",
    "Y = tf.placeholder(\"float\", [None, 5])\n",
    "\n",
    "nb_classes = 5\n",
    "\n",
    "#기존 코드\n",
    "# W = tf.Variable(tf.random_normal([11, nb_classes]), name='weight')\n",
    "# b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# Xavier Initializer 추가 코드\n",
    "W = tf.get_variable(\"W\", shape=[2, nb_classes], initializer=xavier_init(2, nb_classes))\n",
    "b = tf.Variable(tf.zeros([nb_classes]))\n",
    "\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "#  dropout 추가 코드\n",
    "# dropout_rate = tf.placeholder(\"float\")\n",
    "\n",
    "# W1 = tf.get_variable(\"W1\", shape=[11, 30], initializer=xavier_init(11, 30))\n",
    "# W2 = tf.get_variable(\"W2\", shape=[30, 30], initializer=xavier_init(30, 30))\n",
    "# W3 = tf.get_variable(\"W3\", shape=[30, nb_classes], initializer=xavier_init(30, nb_classes))\n",
    "\n",
    "# B1 = tf.Variable(tf.random_normal([30]))\n",
    "# B2 = tf.Variable(tf.random_normal([30]))\n",
    "# B3 = tf.Variable(tf.random_normal([5]))\n",
    "\n",
    "# _L1 = tf.nn.relu(tf.add(tf.matmul(X, W1), B1))\n",
    "# L1 = tf.nn.dropout(_L1, dropout_rate)\n",
    "# _L2 = tf.nn.relu(tf.add(tf.matmul(_L1, W2), B2))\n",
    "# L2 = tf.nn.dropout(_L2, dropout_rate)\n",
    "\n",
    "# H = tf.add(tf.matmul(_L2, W3), B3)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    accuracy = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(6401):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "\n",
    "    print('-----------------------------')\n",
    "\n",
    "    print('train_data = ', len(x_data), 'test_data = ', len(test_x))\n",
    "\n",
    "    for i in range(len(test_x)):\n",
    "        a = sess.run(H, feed_dict={X:[test_x[i]]})\n",
    "        print(sess.run(tf.argmax(a, 1)), test_y[i])\n",
    "        if(sess.run(tf.argmax(a, 1)) ==test_y[i]):\n",
    "            accuracy += 1\n",
    "    print(\"accuracy = \", float(accuracy / len(test_x) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
