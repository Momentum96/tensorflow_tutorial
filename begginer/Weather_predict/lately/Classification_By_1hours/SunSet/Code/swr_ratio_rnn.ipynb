{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-19 5:52:00 5:52:00\n",
      "2018-04-19 19:52:00 19:52:00\n",
      "2018-04-19 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-21 5:49:00 5:49:00\n",
      "2018-04-21 19:49:00 19:49:00\n",
      "2018-04-21 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-26 5:43:00 5:43:00\n",
      "2018-04-26 19:43:00 19:43:00\n",
      "2018-04-26 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-27 5:42:00 5:42:00\n",
      "2018-04-27 19:42:00 19:42:00\n",
      "2018-04-27 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-28 5:41:00 5:41:00\n",
      "2018-04-28 19:41:00 19:41:00\n",
      "2018-04-28 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-29 5:40:00 5:40:00\n",
      "2018-04-29 19:40:00 19:40:00\n",
      "2018-04-29 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-04-30 5:38:00 5:38:00\n",
      "2018-04-30 19:38:00 19:38:00\n",
      "2018-04-30 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-04 5:34:00 5:34:00\n",
      "2018-05-04 19:34:00 19:34:00\n",
      "2018-05-04 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-05 5:33:00 5:33:00\n",
      "2018-05-05 19:33:00 19:33:00\n",
      "2018-05-05 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-08 5:30:00 5:30:00\n",
      "2018-05-08 19:30:00 19:30:00\n",
      "2018-05-08 828 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-10 5:28:00 5:28:00\n",
      "2018-05-10 19:28:00 19:28:00\n",
      "2018-05-10 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-14 5:24:00 5:24:00\n",
      "2018-05-14 19:24:00 19:24:00\n",
      "2018-05-14 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-19 5:20:00 5:20:00\n",
      "2018-05-19 19:20:00 19:20:00\n",
      "2018-05-19 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-21 5:19:00 5:19:00\n",
      "2018-05-21 19:19:00 19:19:00\n",
      "2018-05-21 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-24 5:17:00 5:17:00\n",
      "2018-05-24 19:17:00 19:17:00\n",
      "2018-05-24 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-25 5:17:00 5:17:00\n",
      "2018-05-25 19:17:00 19:17:00\n",
      "2018-05-25 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-26 5:16:00 5:16:00\n",
      "2018-05-26 19:16:00 19:16:00\n",
      "2018-05-26 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-27 5:16:00 5:16:00\n",
      "2018-05-27 19:16:00 19:16:00\n",
      "2018-05-27 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-28 5:15:00 5:15:00\n",
      "2018-05-28 19:15:00 19:15:00\n",
      "2018-05-28 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-29 5:15:00 5:15:00\n",
      "2018-05-29 19:15:00 19:15:00\n",
      "2018-05-29 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-30 5:14:00 5:14:00\n",
      "2018-05-30 19:14:00 19:14:00\n",
      "2018-05-30 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-05-31 5:14:00 5:14:00\n",
      "2018-05-31 19:14:00 19:14:00\n",
      "2018-05-31 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-01 5:13:00 5:13:00\n",
      "2018-06-01 19:13:00 19:13:00\n",
      "2018-06-01 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-02 5:13:00 5:13:00\n",
      "2018-06-02 19:13:00 19:13:00\n",
      "2018-06-02 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-03 5:13:00 5:13:00\n",
      "2018-06-03 19:13:00 19:13:00\n",
      "2018-06-03 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-05 5:12:00 5:12:00\n",
      "2018-06-05 19:12:00 19:12:00\n",
      "2018-06-05 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-06 5:12:00 5:12:00\n",
      "2018-06-06 19:12:00 19:12:00\n",
      "2018-06-06 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-07 5:12:00 5:12:00\n",
      "2018-06-07 19:12:00 19:12:00\n",
      "2018-06-07 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-08 5:12:00 5:12:00\n",
      "2018-06-08 19:12:00 19:12:00\n",
      "2018-06-08 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-09 5:11:00 5:11:00\n",
      "2018-06-09 19:11:00 19:11:00\n",
      "2018-06-09 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-11 5:11:00 5:11:00\n",
      "2018-06-11 19:11:00 19:11:00\n",
      "2018-06-11 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-13 5:11:00 5:11:00\n",
      "2018-06-13 19:11:00 19:11:00\n",
      "2018-06-13 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-16 5:11:00 5:11:00\n",
      "2018-06-16 19:11:00 19:11:00\n",
      "2018-06-16 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-17 5:11:00 5:11:00\n",
      "2018-06-17 19:11:00 19:11:00\n",
      "2018-06-17 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-18 5:11:00 5:11:00\n",
      "2018-06-18 19:11:00 19:11:00\n",
      "2018-06-18 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-24 5:13:00 5:13:00\n",
      "2018-06-24 19:13:00 19:13:00\n",
      "2018-06-24 832 data saved.\n",
      "----------------------------------------------\n",
      "2018-06-25 5:13:00 5:13:00\n",
      "2018-06-25 19:13:00 19:13:00\n",
      "2018-06-25 828 data saved.\n",
      "----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 분별 날짜 파일에 있는 날짜 기준으로 DB에서 데이터 받아와서 저장하기\n",
    "\n",
    "import MySQLdb\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# MySQL DB 연결\n",
    "db = MySQLdb.connect('210.102.142.13',\"root\", \"witlab8*\", \"cas_db\")\n",
    "c = db.cursor()\n",
    "\n",
    "# 분별 날짜\n",
    "# date = np.genfromtxt('../data/date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "date = np.genfromtxt('../data/test_date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "\n",
    "# csv 파일로 내보내기\n",
    "# w = open('../data/db_connect_data_rnn.csv', 'w', encoding='utf-8')\n",
    "w = open('../data/db_connect_test_data_rnn.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "data_length = []\n",
    "\n",
    "# 각 날짜별 데이터들 DB에서 가져오고 csv 파일로 저장\n",
    "# 데이터는 cct, swr, uvb, uvi 순\n",
    "for j in range(len(date)):\n",
    "    sql = \"select time(date),cas_swr, cas_mwr, cas_lwr from natural_tracker left outer join cas_wave_ratio using(date) where date(date) = '\"+ str(date[j][0]) + \"' order by time(date)\"\n",
    "    c.execute(sql)\n",
    "    rows = c.fetchall()\n",
    "    \n",
    "    # 일출 후 6시간과 일몰 후 6시간 데이터 사용, 일출 혹은 일몰 당시 데이터가 없을 경우 가장 가까운 다른 데이터로 변환\n",
    "    sunrise = datetime.datetime.strptime(date[j][1], '%H:%M:%S')\n",
    "    sunset = datetime.datetime.strptime(date[j][2], '%H:%M:%S')\n",
    "    \n",
    "    standard = datetime.datetime.strptime('1900-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    sunrise = sunrise - standard\n",
    "    sunset = sunset - standard\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "\n",
    "    for i in range(len(rows)):\n",
    "        if(rows[i][0] >= sunrise):\n",
    "            start = i\n",
    "            print(date[j][0], rows[start][0], sunrise)\n",
    "            break;\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if(rows[i][0] >= sunset):\n",
    "            end = i\n",
    "            print(date[j][0], rows[end][0], sunset)\n",
    "            break;\n",
    "    \n",
    "    last = int((end - start) / 4)\n",
    "    last = last * 4\n",
    "    \n",
    "#     # start에 저장된 index부터 772개 데이터 가져와서 저장\n",
    "    for l in range(start, start + last):\n",
    "        wr.writerow([rows[l][1], rows[l][2], rows[l][3]])\n",
    "    print(date[j][0] + \" \" + str(last) + \" data saved.\")\n",
    "    for l in range(4):\n",
    "        data_length.append(int(last/4))\n",
    "    print('----------------------------------------------')\n",
    "        \n",
    "w.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date = np.genfromtxt('../data/date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "date = np.genfromtxt('../data/test_date_sunrise_sunset.csv', delimiter=',', dtype='str')\n",
    "\n",
    "# 데이터 받아오고 편차 계산히기\n",
    "# import_data = np.loadtxt('../data/db_connect_data_rnn.csv', delimiter=',')\n",
    "import_data = np.loadtxt('../data/db_connect_test_data_rnn.csv', delimiter=',')\n",
    "\n",
    "one = import_data[:,0] # swr\n",
    "two = import_data[:,1] # mwr\n",
    "thr = import_data[:,2] # lwr\n",
    "\n",
    "swr = []\n",
    "mwr = []\n",
    "lwr = []\n",
    "\n",
    "data_index = 0\n",
    "\n",
    "for i in range(len(data_length)):\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    temp3 = []\n",
    "    for j in range(data_length[i]):\n",
    "        temp.append(one[j + data_index])\n",
    "        temp2.append(two[j + data_index])\n",
    "        temp3.append(thr[j + data_index])\n",
    "    swr.append(temp)\n",
    "    mwr.append(temp2)\n",
    "    lwr.append(temp3)\n",
    "    data_index += data_length[i]\n",
    "    \n",
    "# w = open('../data/swr_ratio_classification_rnn.csv', 'w', encoding='utf-8')\n",
    "w = open('../data/swr_ratio_test_classification_rnn.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range(len(data_length)):\n",
    "    all_hap = 0\n",
    "    swr_hap = 0\n",
    "    ratio = 0\n",
    "    grade = 0\n",
    "    \n",
    "    for j in range(len(swr[i])):\n",
    "        swr_hap += swr[i][j]\n",
    "        all_hap += swr[i][j] + mwr[i][j] + lwr[i][j]\n",
    "        \n",
    "    ratio = round(swr_hap / all_hap * 100, 2)\n",
    "    \n",
    "    if(ratio >= 18.00):\n",
    "        grade += 1\n",
    "    if(ratio >= 20.00):\n",
    "        grade += 1\n",
    "    if(ratio >= 22.00):\n",
    "        grade += 1\n",
    "    if(ratio >= 24.00):\n",
    "        grade += 1\n",
    "    \n",
    "    wr.writerow([ratio, grade])\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(340, 2, 1)\n",
      "[step: 0] cost: 2.3537700176239014\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 1] cost: 2.3387763500213623\n",
      "[step: 2] cost: 2.3240318298339844\n",
      "[step: 3] cost: 2.309537172317505\n",
      "[step: 4] cost: 2.295293092727661\n",
      "[step: 5] cost: 2.281299114227295\n",
      "[step: 6] cost: 2.267554998397827\n",
      "[step: 7] cost: 2.2540595531463623\n",
      "[step: 8] cost: 2.2408111095428467\n",
      "[step: 9] cost: 2.2278079986572266\n",
      "[step: 10] cost: 2.215047597885132\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 11] cost: 2.2025279998779297\n",
      "[step: 12] cost: 2.1902449131011963\n",
      "[step: 13] cost: 2.178196907043457\n",
      "[step: 14] cost: 2.16637921333313\n",
      "[step: 15] cost: 2.1547892093658447\n",
      "[step: 16] cost: 2.143423557281494\n",
      "[step: 17] cost: 2.1322786808013916\n",
      "[step: 18] cost: 2.121350049972534\n",
      "[step: 19] cost: 2.110635995864868\n",
      "[step: 20] cost: 2.100132942199707\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 21] cost: 2.0898377895355225\n",
      "[step: 22] cost: 2.0797486305236816\n",
      "[step: 23] cost: 2.069861888885498\n",
      "[step: 24] cost: 2.0601768493652344\n",
      "[step: 25] cost: 2.0506911277770996\n",
      "[step: 26] cost: 2.0414037704467773\n",
      "[step: 27] cost: 2.032313346862793\n",
      "[step: 28] cost: 2.0234193801879883\n",
      "[step: 29] cost: 2.0147202014923096\n",
      "[step: 30] cost: 2.0062155723571777\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 31] cost: 1.997904658317566\n",
      "[step: 32] cost: 1.989786148071289\n",
      "[step: 33] cost: 1.981858730316162\n",
      "[step: 34] cost: 1.9741207361221313\n",
      "[step: 35] cost: 1.9665700197219849\n",
      "[step: 36] cost: 1.9592037200927734\n",
      "[step: 37] cost: 1.9520177841186523\n",
      "[step: 38] cost: 1.945008635520935\n",
      "[step: 39] cost: 1.9381704330444336\n",
      "[step: 40] cost: 1.9314979314804077\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 41] cost: 1.924984335899353\n",
      "[step: 42] cost: 1.918622374534607\n",
      "[step: 43] cost: 1.9124035835266113\n",
      "[step: 44] cost: 1.9063198566436768\n",
      "[step: 45] cost: 1.9003615379333496\n",
      "[step: 46] cost: 1.8945201635360718\n",
      "[step: 47] cost: 1.888784646987915\n",
      "[step: 48] cost: 1.8831461668014526\n",
      "[step: 49] cost: 1.8775949478149414\n",
      "[step: 50] cost: 1.8721210956573486\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 51] cost: 1.8667162656784058\n",
      "[step: 52] cost: 1.8613718748092651\n",
      "[step: 53] cost: 1.8560807704925537\n",
      "[step: 54] cost: 1.8508367538452148\n",
      "[step: 55] cost: 1.8456350564956665\n",
      "[step: 56] cost: 1.8404731750488281\n",
      "[step: 57] cost: 1.8353502750396729\n",
      "[step: 58] cost: 1.8302671909332275\n",
      "[step: 59] cost: 1.8252278566360474\n",
      "[step: 60] cost: 1.8202365636825562\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 61] cost: 1.815300464630127\n",
      "[step: 62] cost: 1.8104276657104492\n",
      "[step: 63] cost: 1.8056243658065796\n",
      "[step: 64] cost: 1.8008983135223389\n",
      "[step: 65] cost: 1.796252965927124\n",
      "[step: 66] cost: 1.7916901111602783\n",
      "[step: 67] cost: 1.7872077226638794\n",
      "[step: 68] cost: 1.7828011512756348\n",
      "[step: 69] cost: 1.7784615755081177\n",
      "[step: 70] cost: 1.774179458618164\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 71] cost: 1.7699429988861084\n",
      "[step: 72] cost: 1.7657417058944702\n",
      "[step: 73] cost: 1.7615630626678467\n",
      "[step: 74] cost: 1.7573981285095215\n",
      "[step: 75] cost: 1.7532376050949097\n",
      "[step: 76] cost: 1.7490742206573486\n",
      "[step: 77] cost: 1.7449018955230713\n",
      "[step: 78] cost: 1.7407156229019165\n",
      "[step: 79] cost: 1.7365121841430664\n",
      "[step: 80] cost: 1.7322890758514404\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 81] cost: 1.7280439138412476\n",
      "[step: 82] cost: 1.7237757444381714\n",
      "[step: 83] cost: 1.7194844484329224\n",
      "[step: 84] cost: 1.7151691913604736\n",
      "[step: 85] cost: 1.7108314037322998\n",
      "[step: 86] cost: 1.7064712047576904\n",
      "[step: 87] cost: 1.7020899057388306\n",
      "[step: 88] cost: 1.6976886987686157\n",
      "[step: 89] cost: 1.693270206451416\n",
      "[step: 90] cost: 1.6888352632522583\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 91] cost: 1.6843866109848022\n",
      "[step: 92] cost: 1.6799269914627075\n",
      "[step: 93] cost: 1.6754584312438965\n",
      "[step: 94] cost: 1.6709843873977661\n",
      "[step: 95] cost: 1.6665077209472656\n",
      "[step: 96] cost: 1.6620312929153442\n",
      "[step: 97] cost: 1.6575591564178467\n",
      "[step: 98] cost: 1.6530942916870117\n",
      "[step: 99] cost: 1.6486408710479736\n",
      "[step: 100] cost: 1.6442023515701294\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 101] cost: 1.6397833824157715\n",
      "[step: 102] cost: 1.6353877782821655\n",
      "[step: 103] cost: 1.631020188331604\n",
      "[step: 104] cost: 1.6266851425170898\n",
      "[step: 105] cost: 1.622387170791626\n",
      "[step: 106] cost: 1.6181315183639526\n",
      "[step: 107] cost: 1.6139227151870728\n",
      "[step: 108] cost: 1.6097663640975952\n",
      "[step: 109] cost: 1.605668067932129\n",
      "[step: 110] cost: 1.6016321182250977\n",
      "학습 정확도: 0.17058824\n",
      "테스트 정확도: 0.05479452\n",
      "[step: 111] cost: 1.5976654291152954\n",
      "[step: 112] cost: 1.5937731266021729\n",
      "[step: 113] cost: 1.5899605751037598\n",
      "[step: 114] cost: 1.5862340927124023\n",
      "[step: 115] cost: 1.5825985670089722\n",
      "[step: 116] cost: 1.5790599584579468\n",
      "[step: 117] cost: 1.575623631477356\n",
      "[step: 118] cost: 1.5722947120666504\n",
      "[step: 119] cost: 1.5690783262252808\n",
      "[step: 120] cost: 1.565978765487671\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 121] cost: 1.5630004405975342\n",
      "[step: 122] cost: 1.5601470470428467\n",
      "[step: 123] cost: 1.5574216842651367\n",
      "[step: 124] cost: 1.5548272132873535\n",
      "[step: 125] cost: 1.5523656606674194\n",
      "[step: 126] cost: 1.5500389337539673\n",
      "[step: 127] cost: 1.5478476285934448\n",
      "[step: 128] cost: 1.5457922220230103\n",
      "[step: 129] cost: 1.5438728332519531\n",
      "[step: 130] cost: 1.5420880317687988\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 131] cost: 1.540436863899231\n",
      "[step: 132] cost: 1.5389174222946167\n",
      "[step: 133] cost: 1.5375269651412964\n",
      "[step: 134] cost: 1.5362627506256104\n",
      "[step: 135] cost: 1.5351207256317139\n",
      "[step: 136] cost: 1.5340967178344727\n",
      "[step: 137] cost: 1.5331857204437256\n",
      "[step: 138] cost: 1.5323820114135742\n",
      "[step: 139] cost: 1.5316792726516724\n",
      "[step: 140] cost: 1.5310701131820679\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 141] cost: 1.53054678440094\n",
      "[step: 142] cost: 1.5301005840301514\n",
      "[step: 143] cost: 1.5297220945358276\n",
      "[step: 144] cost: 1.5294015407562256\n",
      "[step: 145] cost: 1.5291287899017334\n",
      "[step: 146] cost: 1.5288944244384766\n",
      "[step: 147] cost: 1.528687834739685\n",
      "[step: 148] cost: 1.5285005569458008\n",
      "[step: 149] cost: 1.5283235311508179\n",
      "[step: 150] cost: 1.5281506776809692\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 151] cost: 1.5279754400253296\n",
      "[step: 152] cost: 1.5277940034866333\n",
      "[step: 153] cost: 1.5276029109954834\n",
      "[step: 154] cost: 1.5274006128311157\n",
      "[step: 155] cost: 1.5271868705749512\n",
      "[step: 156] cost: 1.5269619226455688\n",
      "[step: 157] cost: 1.526727318763733\n",
      "[step: 158] cost: 1.5264846086502075\n",
      "[step: 159] cost: 1.5262362957000732\n",
      "[step: 160] cost: 1.525984287261963\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 161] cost: 1.5257312059402466\n",
      "[step: 162] cost: 1.525478720664978\n",
      "[step: 163] cost: 1.52522873878479\n",
      "[step: 164] cost: 1.5249829292297363\n",
      "[step: 165] cost: 1.5247423648834229\n",
      "[step: 166] cost: 1.524507999420166\n",
      "[step: 167] cost: 1.5242801904678345\n",
      "[step: 168] cost: 1.524059534072876\n",
      "[step: 169] cost: 1.5238456726074219\n",
      "[step: 170] cost: 1.5236387252807617\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 171] cost: 1.5234380960464478\n",
      "[step: 172] cost: 1.5232436656951904\n",
      "[step: 173] cost: 1.5230547189712524\n",
      "[step: 174] cost: 1.5228708982467651\n",
      "[step: 175] cost: 1.5226916074752808\n",
      "[step: 176] cost: 1.5225162506103516\n",
      "[step: 177] cost: 1.5223442316055298\n",
      "[step: 178] cost: 1.5221751928329468\n",
      "[step: 179] cost: 1.5220085382461548\n",
      "[step: 180] cost: 1.5218439102172852\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 181] cost: 1.5216814279556274\n",
      "[step: 182] cost: 1.5215201377868652\n",
      "[step: 183] cost: 1.5213605165481567\n",
      "[step: 184] cost: 1.5212019681930542\n",
      "[step: 185] cost: 1.5210446119308472\n",
      "[step: 186] cost: 1.520888328552246\n",
      "[step: 187] cost: 1.520733118057251\n",
      "[step: 188] cost: 1.520579218864441\n",
      "[step: 189] cost: 1.5204261541366577\n",
      "[step: 190] cost: 1.5202744007110596\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 191] cost: 1.5201241970062256\n",
      "[step: 192] cost: 1.5199750661849976\n",
      "[step: 193] cost: 1.5198272466659546\n",
      "[step: 194] cost: 1.5196813344955444\n",
      "[step: 195] cost: 1.5195366144180298\n",
      "[step: 196] cost: 1.5193936824798584\n",
      "[step: 197] cost: 1.5192524194717407\n",
      "[step: 198] cost: 1.519113302230835\n",
      "[step: 199] cost: 1.5189756155014038\n",
      "[step: 200] cost: 1.518839955329895\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 201] cost: 1.5187058448791504\n",
      "[step: 202] cost: 1.5185737609863281\n",
      "[step: 203] cost: 1.518442988395691\n",
      "[step: 204] cost: 1.5183143615722656\n",
      "[step: 205] cost: 1.518187403678894\n",
      "[step: 206] cost: 1.518061876296997\n",
      "[step: 207] cost: 1.5179380178451538\n",
      "[step: 208] cost: 1.5178155899047852\n",
      "[step: 209] cost: 1.5176945924758911\n",
      "[step: 210] cost: 1.5175750255584717\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 211] cost: 1.5174567699432373\n",
      "[step: 212] cost: 1.5173395872116089\n",
      "[step: 213] cost: 1.5172237157821655\n",
      "[step: 214] cost: 1.517108678817749\n",
      "[step: 215] cost: 1.5169951915740967\n",
      "[step: 216] cost: 1.516882300376892\n",
      "[step: 217] cost: 1.5167707204818726\n",
      "[step: 218] cost: 1.5166594982147217\n",
      "[step: 219] cost: 1.5165493488311768\n",
      "[step: 220] cost: 1.5164400339126587\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 221] cost: 1.5163317918777466\n",
      "[step: 222] cost: 1.5162240266799927\n",
      "[step: 223] cost: 1.5161168575286865\n",
      "[step: 224] cost: 1.5160106420516968\n",
      "[step: 225] cost: 1.5159050226211548\n",
      "[step: 226] cost: 1.5157999992370605\n",
      "[step: 227] cost: 1.5156959295272827\n",
      "[step: 228] cost: 1.515592098236084\n",
      "[step: 229] cost: 1.5154889822006226\n",
      "[step: 230] cost: 1.5153865814208984\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 231] cost: 1.5152846574783325\n",
      "[step: 232] cost: 1.515183448791504\n",
      "[step: 233] cost: 1.5150824785232544\n",
      "[step: 234] cost: 1.5149821043014526\n",
      "[step: 235] cost: 1.514882206916809\n",
      "[step: 236] cost: 1.5147829055786133\n",
      "[step: 237] cost: 1.5146838426589966\n",
      "[step: 238] cost: 1.5145857334136963\n",
      "[step: 239] cost: 1.514487624168396\n",
      "[step: 240] cost: 1.514389991760254\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 241] cost: 1.51429283618927\n",
      "[step: 242] cost: 1.5141960382461548\n",
      "[step: 243] cost: 1.5140997171401978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 244] cost: 1.5140037536621094\n",
      "[step: 245] cost: 1.5139079093933105\n",
      "[step: 246] cost: 1.513812780380249\n",
      "[step: 247] cost: 1.5137178897857666\n",
      "[step: 248] cost: 1.5136229991912842\n",
      "[step: 249] cost: 1.51352858543396\n",
      "[step: 250] cost: 1.5134345293045044\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 251] cost: 1.5133410692214966\n",
      "[step: 252] cost: 1.5132474899291992\n",
      "[step: 253] cost: 1.5131545066833496\n",
      "[step: 254] cost: 1.513061761856079\n",
      "[step: 255] cost: 1.5129692554473877\n",
      "[step: 256] cost: 1.5128769874572754\n",
      "[step: 257] cost: 1.5127848386764526\n",
      "[step: 258] cost: 1.512693166732788\n",
      "[step: 259] cost: 1.5126017332077026\n",
      "[step: 260] cost: 1.5125107765197754\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 261] cost: 1.5124197006225586\n",
      "[step: 262] cost: 1.5123291015625\n",
      "[step: 263] cost: 1.512238621711731\n",
      "[step: 264] cost: 1.512148380279541\n",
      "[step: 265] cost: 1.5120586156845093\n",
      "[step: 266] cost: 1.511968970298767\n",
      "[step: 267] cost: 1.5118794441223145\n",
      "[step: 268] cost: 1.51179039478302\n",
      "[step: 269] cost: 1.5117013454437256\n",
      "[step: 270] cost: 1.5116126537322998\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 271] cost: 1.511523962020874\n",
      "[step: 272] cost: 1.511435866355896\n",
      "[step: 273] cost: 1.5113476514816284\n",
      "[step: 274] cost: 1.5112600326538086\n",
      "[step: 275] cost: 1.5111722946166992\n",
      "[step: 276] cost: 1.5110849142074585\n",
      "[step: 277] cost: 1.5109977722167969\n",
      "[step: 278] cost: 1.5109107494354248\n",
      "[step: 279] cost: 1.5108240842819214\n",
      "[step: 280] cost: 1.5107375383377075\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 281] cost: 1.5106509923934937\n",
      "[step: 282] cost: 1.5105650424957275\n",
      "[step: 283] cost: 1.5104789733886719\n",
      "[step: 284] cost: 1.5103932619094849\n",
      "[step: 285] cost: 1.510307788848877\n",
      "[step: 286] cost: 1.510222315788269\n",
      "[step: 287] cost: 1.5101372003555298\n",
      "[step: 288] cost: 1.5100523233413696\n",
      "[step: 289] cost: 1.509967565536499\n",
      "[step: 290] cost: 1.5098830461502075\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 291] cost: 1.5097986459732056\n",
      "[step: 292] cost: 1.5097144842147827\n",
      "[step: 293] cost: 1.5096304416656494\n",
      "[step: 294] cost: 1.5095467567443848\n",
      "[step: 295] cost: 1.5094633102416992\n",
      "[step: 296] cost: 1.5093796253204346\n",
      "[step: 297] cost: 1.5092964172363281\n",
      "[step: 298] cost: 1.5092132091522217\n",
      "[step: 299] cost: 1.5091304779052734\n",
      "[step: 300] cost: 1.5090477466583252\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 301] cost: 1.5089653730392456\n",
      "[step: 302] cost: 1.5088831186294556\n",
      "[step: 303] cost: 1.5088011026382446\n",
      "[step: 304] cost: 1.5087188482284546\n",
      "[step: 305] cost: 1.5086371898651123\n",
      "[step: 306] cost: 1.50855553150177\n",
      "[step: 307] cost: 1.5084739923477173\n",
      "[step: 308] cost: 1.5083926916122437\n",
      "[step: 309] cost: 1.5083117485046387\n",
      "[step: 310] cost: 1.5082305669784546\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 311] cost: 1.5081499814987183\n",
      "[step: 312] cost: 1.508069396018982\n",
      "[step: 313] cost: 1.5079888105392456\n",
      "[step: 314] cost: 1.5079087018966675\n",
      "[step: 315] cost: 1.507828712463379\n",
      "[step: 316] cost: 1.5077487230300903\n",
      "[step: 317] cost: 1.5076690912246704\n",
      "[step: 318] cost: 1.507589340209961\n",
      "[step: 319] cost: 1.5075098276138306\n",
      "[step: 320] cost: 1.5074304342269897\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 321] cost: 1.507351279258728\n",
      "[step: 322] cost: 1.5072723627090454\n",
      "[step: 323] cost: 1.507193684577942\n",
      "[step: 324] cost: 1.5071148872375488\n",
      "[step: 325] cost: 1.5070364475250244\n",
      "[step: 326] cost: 1.5069580078125\n",
      "[step: 327] cost: 1.5068796873092651\n",
      "[step: 328] cost: 1.5068016052246094\n",
      "[step: 329] cost: 1.5067237615585327\n",
      "[step: 330] cost: 1.5066460371017456\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 331] cost: 1.506568431854248\n",
      "[step: 332] cost: 1.50649094581604\n",
      "[step: 333] cost: 1.5064136981964111\n",
      "[step: 334] cost: 1.5063363313674927\n",
      "[step: 335] cost: 1.5062593221664429\n",
      "[step: 336] cost: 1.5061825513839722\n",
      "[step: 337] cost: 1.506105661392212\n",
      "[step: 338] cost: 1.5060290098190308\n",
      "[step: 339] cost: 1.5059525966644287\n",
      "[step: 340] cost: 1.505876064300537\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 341] cost: 1.5057998895645142\n",
      "[step: 342] cost: 1.5057237148284912\n",
      "[step: 343] cost: 1.5056475400924683\n",
      "[step: 344] cost: 1.505571961402893\n",
      "[step: 345] cost: 1.5054961442947388\n",
      "[step: 346] cost: 1.5054206848144531\n",
      "[step: 347] cost: 1.505345106124878\n",
      "[step: 348] cost: 1.5052696466445923\n",
      "[step: 349] cost: 1.5051946640014648\n",
      "[step: 350] cost: 1.5051195621490479\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 351] cost: 1.5050445795059204\n",
      "[step: 352] cost: 1.504969596862793\n",
      "[step: 353] cost: 1.5048949718475342\n",
      "[step: 354] cost: 1.504820466041565\n",
      "[step: 355] cost: 1.5047457218170166\n",
      "[step: 356] cost: 1.504671335220337\n",
      "[step: 357] cost: 1.5045970678329468\n",
      "[step: 358] cost: 1.5045229196548462\n",
      "[step: 359] cost: 1.5044490098953247\n",
      "[step: 360] cost: 1.5043749809265137\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 361] cost: 1.5043010711669922\n",
      "[step: 362] cost: 1.5042275190353394\n",
      "[step: 363] cost: 1.5041536092758179\n",
      "[step: 364] cost: 1.5040801763534546\n",
      "[step: 365] cost: 1.5040068626403809\n",
      "[step: 366] cost: 1.5039335489273071\n",
      "[step: 367] cost: 1.503860354423523\n",
      "[step: 368] cost: 1.5037872791290283\n",
      "[step: 369] cost: 1.5037143230438232\n",
      "[step: 370] cost: 1.5036413669586182\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 371] cost: 1.5035685300827026\n",
      "[step: 372] cost: 1.5034959316253662\n",
      "[step: 373] cost: 1.5034233331680298\n",
      "[step: 374] cost: 1.5033506155014038\n",
      "[step: 375] cost: 1.503278136253357\n",
      "[step: 376] cost: 1.5032058954238892\n",
      "[step: 377] cost: 1.5031336545944214\n",
      "[step: 378] cost: 1.5030614137649536\n",
      "[step: 379] cost: 1.5029892921447754\n",
      "[step: 380] cost: 1.5029174089431763\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 381] cost: 1.5028455257415771\n",
      "[step: 382] cost: 1.502773642539978\n",
      "[step: 383] cost: 1.502701759338379\n",
      "[step: 384] cost: 1.5026302337646484\n",
      "[step: 385] cost: 1.5025585889816284\n",
      "[step: 386] cost: 1.5024869441986084\n",
      "[step: 387] cost: 1.502415657043457\n",
      "[step: 388] cost: 1.5023442506790161\n",
      "[step: 389] cost: 1.5022729635238647\n",
      "[step: 390] cost: 1.502201795578003\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 391] cost: 1.5021307468414307\n",
      "[step: 392] cost: 1.5020595788955688\n",
      "[step: 393] cost: 1.501988410949707\n",
      "[step: 394] cost: 1.5019176006317139\n",
      "[step: 395] cost: 1.5018465518951416\n",
      "[step: 396] cost: 1.501775860786438\n",
      "[step: 397] cost: 1.5017051696777344\n",
      "[step: 398] cost: 1.5016343593597412\n",
      "[step: 399] cost: 1.5015637874603271\n",
      "[step: 400] cost: 1.501493215560913\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 401] cost: 1.5014227628707886\n",
      "[step: 402] cost: 1.501352310180664\n",
      "[step: 403] cost: 1.501281976699829\n",
      "[step: 404] cost: 1.5012115240097046\n",
      "[step: 405] cost: 1.5011413097381592\n",
      "[step: 406] cost: 1.5010712146759033\n",
      "[step: 407] cost: 1.501001000404358\n",
      "[step: 408] cost: 1.500930905342102\n",
      "[step: 409] cost: 1.5008608102798462\n",
      "[step: 410] cost: 1.5007907152175903\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 411] cost: 1.5007208585739136\n",
      "[step: 412] cost: 1.5006511211395264\n",
      "[step: 413] cost: 1.50058114528656\n",
      "[step: 414] cost: 1.5005112886428833\n",
      "[step: 415] cost: 1.500441551208496\n",
      "[step: 416] cost: 1.5003716945648193\n",
      "[step: 417] cost: 1.5003020763397217\n",
      "[step: 418] cost: 1.5002323389053345\n",
      "[step: 419] cost: 1.5001628398895264\n",
      "[step: 420] cost: 1.5000932216644287\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 421] cost: 1.5000234842300415\n",
      "[step: 422] cost: 1.499954104423523\n",
      "[step: 423] cost: 1.4998846054077148\n",
      "[step: 424] cost: 1.4998152256011963\n",
      "[step: 425] cost: 1.4997458457946777\n",
      "[step: 426] cost: 1.4996764659881592\n",
      "[step: 427] cost: 1.4996070861816406\n",
      "[step: 428] cost: 1.4995378255844116\n",
      "[step: 429] cost: 1.4994685649871826\n",
      "[step: 430] cost: 1.499399185180664\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 431] cost: 1.4993300437927246\n",
      "[step: 432] cost: 1.4992609024047852\n",
      "[step: 433] cost: 1.4991916418075562\n",
      "[step: 434] cost: 1.4991226196289062\n",
      "[step: 435] cost: 1.4990533590316772\n",
      "[step: 436] cost: 1.4989843368530273\n",
      "[step: 437] cost: 1.4989153146743774\n",
      "[step: 438] cost: 1.498846173286438\n",
      "[step: 439] cost: 1.498777151107788\n",
      "[step: 440] cost: 1.4987080097198486\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 441] cost: 1.4986389875411987\n",
      "[step: 442] cost: 1.4985700845718384\n",
      "[step: 443] cost: 1.4985010623931885\n",
      "[step: 444] cost: 1.498431921005249\n",
      "[step: 445] cost: 1.4983632564544678\n",
      "[step: 446] cost: 1.4982941150665283\n",
      "[step: 447] cost: 1.4982250928878784\n",
      "[step: 448] cost: 1.4981563091278076\n",
      "[step: 449] cost: 1.4980874061584473\n",
      "[step: 450] cost: 1.4980183839797974\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 451] cost: 1.497949481010437\n",
      "[step: 452] cost: 1.4978805780410767\n",
      "[step: 453] cost: 1.4978115558624268\n",
      "[step: 454] cost: 1.497742772102356\n",
      "[step: 455] cost: 1.4976738691329956\n",
      "[step: 456] cost: 1.4976049661636353\n",
      "[step: 457] cost: 1.4975359439849854\n",
      "[step: 458] cost: 1.4974671602249146\n",
      "[step: 459] cost: 1.4973981380462646\n",
      "[step: 460] cost: 1.4973292350769043\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 461] cost: 1.4972604513168335\n",
      "[step: 462] cost: 1.4971914291381836\n",
      "[step: 463] cost: 1.4971224069595337\n",
      "[step: 464] cost: 1.497053623199463\n",
      "[step: 465] cost: 1.496984601020813\n",
      "[step: 466] cost: 1.4969156980514526\n",
      "[step: 467] cost: 1.4968466758728027\n",
      "[step: 468] cost: 1.4967776536941528\n",
      "[step: 469] cost: 1.4967087507247925\n",
      "[step: 470] cost: 1.496639609336853\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 471] cost: 1.4965708255767822\n",
      "[step: 472] cost: 1.4965016841888428\n",
      "[step: 473] cost: 1.4964327812194824\n",
      "[step: 474] cost: 1.496363639831543\n",
      "[step: 475] cost: 1.4962944984436035\n",
      "[step: 476] cost: 1.496225357055664\n",
      "[step: 477] cost: 1.4961563348770142\n",
      "[step: 478] cost: 1.4960873126983643\n",
      "[step: 479] cost: 1.4960181713104248\n",
      "[step: 480] cost: 1.4959487915039062\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 481] cost: 1.4958796501159668\n",
      "[step: 482] cost: 1.4958103895187378\n",
      "[step: 483] cost: 1.4957411289215088\n",
      "[step: 484] cost: 1.4956718683242798\n",
      "[step: 485] cost: 1.4956023693084717\n",
      "[step: 486] cost: 1.4955332279205322\n",
      "[step: 487] cost: 1.4954639673233032\n",
      "[step: 488] cost: 1.4953944683074951\n",
      "[step: 489] cost: 1.4953248500823975\n",
      "[step: 490] cost: 1.495255470275879\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 491] cost: 1.4951860904693604\n",
      "[step: 492] cost: 1.4951165914535522\n",
      "[step: 493] cost: 1.495046854019165\n",
      "[step: 494] cost: 1.494977355003357\n",
      "[step: 495] cost: 1.4949077367782593\n",
      "[step: 496] cost: 1.494837999343872\n",
      "[step: 497] cost: 1.4947682619094849\n",
      "[step: 498] cost: 1.494698405265808\n",
      "[step: 499] cost: 1.494628667831421\n",
      "[step: 500] cost: 1.4945589303970337\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 501] cost: 1.494489073753357\n",
      "[step: 502] cost: 1.494418978691101\n",
      "[step: 503] cost: 1.4943490028381348\n",
      "[step: 504] cost: 1.494278907775879\n",
      "[step: 505] cost: 1.4942090511322021\n",
      "[step: 506] cost: 1.4941388368606567\n",
      "[step: 507] cost: 1.4940685033798218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 508] cost: 1.4939982891082764\n",
      "[step: 509] cost: 1.493928074836731\n",
      "[step: 510] cost: 1.493857741355896\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 511] cost: 1.4937872886657715\n",
      "[step: 512] cost: 1.493716835975647\n",
      "[step: 513] cost: 1.4936463832855225\n",
      "[step: 514] cost: 1.4935758113861084\n",
      "[step: 515] cost: 1.4935050010681152\n",
      "[step: 516] cost: 1.4934345483779907\n",
      "[step: 517] cost: 1.4933637380599976\n",
      "[step: 518] cost: 1.4932928085327148\n",
      "[step: 519] cost: 1.4932219982147217\n",
      "[step: 520] cost: 1.493151068687439\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 521] cost: 1.4930799007415771\n",
      "[step: 522] cost: 1.4930089712142944\n",
      "[step: 523] cost: 1.4929378032684326\n",
      "[step: 524] cost: 1.4928667545318604\n",
      "[step: 525] cost: 1.4927953481674194\n",
      "[step: 526] cost: 1.4927239418029785\n",
      "[step: 527] cost: 1.4926525354385376\n",
      "[step: 528] cost: 1.4925810098648071\n",
      "[step: 529] cost: 1.4925094842910767\n",
      "[step: 530] cost: 1.4924376010894775\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 531] cost: 1.4923659563064575\n",
      "[step: 532] cost: 1.4922940731048584\n",
      "[step: 533] cost: 1.4922223091125488\n",
      "[step: 534] cost: 1.4921503067016602\n",
      "[step: 535] cost: 1.492078185081482\n",
      "[step: 536] cost: 1.4920060634613037\n",
      "[step: 537] cost: 1.4919337034225464\n",
      "[step: 538] cost: 1.4918614625930786\n",
      "[step: 539] cost: 1.4917889833450317\n",
      "[step: 540] cost: 1.4917165040969849\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 541] cost: 1.4916437864303589\n",
      "[step: 542] cost: 1.491571068763733\n",
      "[step: 543] cost: 1.4914982318878174\n",
      "[step: 544] cost: 1.4914253950119019\n",
      "[step: 545] cost: 1.4913524389266968\n",
      "[step: 546] cost: 1.4912793636322021\n",
      "[step: 547] cost: 1.4912059307098389\n",
      "[step: 548] cost: 1.4911327362060547\n",
      "[step: 549] cost: 1.4910593032836914\n",
      "[step: 550] cost: 1.4909858703613281\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 551] cost: 1.4909120798110962\n",
      "[step: 552] cost: 1.4908384084701538\n",
      "[step: 553] cost: 1.4907646179199219\n",
      "[step: 554] cost: 1.4906905889511108\n",
      "[step: 555] cost: 1.4906164407730103\n",
      "[step: 556] cost: 1.4905422925949097\n",
      "[step: 557] cost: 1.4904677867889404\n",
      "[step: 558] cost: 1.4903934001922607\n",
      "[step: 559] cost: 1.490318775177002\n",
      "[step: 560] cost: 1.4902441501617432\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 561] cost: 1.4901692867279053\n",
      "[step: 562] cost: 1.4900943040847778\n",
      "[step: 563] cost: 1.4900192022323608\n",
      "[step: 564] cost: 1.4899438619613647\n",
      "[step: 565] cost: 1.4898687601089478\n",
      "[step: 566] cost: 1.4897931814193726\n",
      "[step: 567] cost: 1.4897174835205078\n",
      "[step: 568] cost: 1.4896414279937744\n",
      "[step: 569] cost: 1.4895657300949097\n",
      "[step: 570] cost: 1.4894894361495972\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 571] cost: 1.4894131422042847\n",
      "[step: 572] cost: 1.4893368482589722\n",
      "[step: 573] cost: 1.489260196685791\n",
      "[step: 574] cost: 1.4891835451126099\n",
      "[step: 575] cost: 1.48910653591156\n",
      "[step: 576] cost: 1.4890295267105103\n",
      "[step: 577] cost: 1.4889521598815918\n",
      "[step: 578] cost: 1.4888746738433838\n",
      "[step: 579] cost: 1.4887969493865967\n",
      "[step: 580] cost: 1.4887192249298096\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 581] cost: 1.4886411428451538\n",
      "[step: 582] cost: 1.4885625839233398\n",
      "[step: 583] cost: 1.4884841442108154\n",
      "[step: 584] cost: 1.4884052276611328\n",
      "[step: 585] cost: 1.488326072692871\n",
      "[step: 586] cost: 1.4882466793060303\n",
      "[step: 587] cost: 1.4881668090820312\n",
      "[step: 588] cost: 1.4880867004394531\n",
      "[step: 589] cost: 1.4880061149597168\n",
      "[step: 590] cost: 1.4879251718521118\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 591] cost: 1.4878435134887695\n",
      "[step: 592] cost: 1.4877612590789795\n",
      "[step: 593] cost: 1.4876784086227417\n",
      "[step: 594] cost: 1.487594723701477\n",
      "[step: 595] cost: 1.4875099658966064\n",
      "[step: 596] cost: 1.4874240159988403\n",
      "[step: 597] cost: 1.4873371124267578\n",
      "[step: 598] cost: 1.4872483015060425\n",
      "[step: 599] cost: 1.487157940864563\n",
      "[step: 600] cost: 1.4870654344558716\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 601] cost: 1.4869706630706787\n",
      "[step: 602] cost: 1.4868730306625366\n",
      "[step: 603] cost: 1.4867722988128662\n",
      "[step: 604] cost: 1.4866677522659302\n",
      "[step: 605] cost: 1.4865591526031494\n",
      "[step: 606] cost: 1.486445665359497\n",
      "[step: 607] cost: 1.4863264560699463\n",
      "[step: 608] cost: 1.4862006902694702\n",
      "[step: 609] cost: 1.486067771911621\n",
      "[step: 610] cost: 1.4859262704849243\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 611] cost: 1.485775351524353\n",
      "[step: 612] cost: 1.4856137037277222\n",
      "[step: 613] cost: 1.4854402542114258\n",
      "[step: 614] cost: 1.4852536916732788\n",
      "[step: 615] cost: 1.4850528240203857\n",
      "[step: 616] cost: 1.4848369359970093\n",
      "[step: 617] cost: 1.4846055507659912\n",
      "[step: 618] cost: 1.4843581914901733\n",
      "[step: 619] cost: 1.4840959310531616\n",
      "[step: 620] cost: 1.4838204383850098\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 621] cost: 1.4835351705551147\n",
      "[step: 622] cost: 1.4832453727722168\n",
      "[step: 623] cost: 1.482959270477295\n",
      "[step: 624] cost: 1.4826867580413818\n",
      "[step: 625] cost: 1.4824392795562744\n",
      "[step: 626] cost: 1.482224702835083\n",
      "[step: 627] cost: 1.4820367097854614\n",
      "[step: 628] cost: 1.481850266456604\n",
      "[step: 629] cost: 1.4816398620605469\n",
      "[step: 630] cost: 1.4813988208770752\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 631] cost: 1.481137752532959\n",
      "[step: 632] cost: 1.4808744192123413\n",
      "[step: 633] cost: 1.4806233644485474\n",
      "[step: 634] cost: 1.4803907871246338\n",
      "[step: 635] cost: 1.4801753759384155\n",
      "[step: 636] cost: 1.479970097541809\n",
      "[step: 637] cost: 1.479765772819519\n",
      "[step: 638] cost: 1.4795550107955933\n",
      "[step: 639] cost: 1.4793343544006348\n",
      "[step: 640] cost: 1.4791051149368286\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 641] cost: 1.4788718223571777\n",
      "[step: 642] cost: 1.4786412715911865\n",
      "[step: 643] cost: 1.4784181118011475\n",
      "[step: 644] cost: 1.4782048463821411\n",
      "[step: 645] cost: 1.4780001640319824\n",
      "[step: 646] cost: 1.4778001308441162\n",
      "[step: 647] cost: 1.4776015281677246\n",
      "[step: 648] cost: 1.4774028062820435\n",
      "[step: 649] cost: 1.477204442024231\n",
      "[step: 650] cost: 1.4770092964172363\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 651] cost: 1.476819634437561\n",
      "[step: 652] cost: 1.4766361713409424\n",
      "[step: 653] cost: 1.476457953453064\n",
      "[step: 654] cost: 1.4762825965881348\n",
      "[step: 655] cost: 1.4761085510253906\n",
      "[step: 656] cost: 1.4759351015090942\n",
      "[step: 657] cost: 1.4757623672485352\n",
      "[step: 658] cost: 1.4755922555923462\n",
      "[step: 659] cost: 1.4754258394241333\n",
      "[step: 660] cost: 1.475263237953186\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 661] cost: 1.4751046895980835\n",
      "[step: 662] cost: 1.4749484062194824\n",
      "[step: 663] cost: 1.4747934341430664\n",
      "[step: 664] cost: 1.4746390581130981\n",
      "[step: 665] cost: 1.4744858741760254\n",
      "[step: 666] cost: 1.474334478378296\n",
      "[step: 667] cost: 1.474185585975647\n",
      "[step: 668] cost: 1.47403883934021\n",
      "[step: 669] cost: 1.473893642425537\n",
      "[step: 670] cost: 1.4737492799758911\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 671] cost: 1.4736056327819824\n",
      "[step: 672] cost: 1.4734625816345215\n",
      "[step: 673] cost: 1.4733202457427979\n",
      "[step: 674] cost: 1.4731793403625488\n",
      "[step: 675] cost: 1.4730395078659058\n",
      "[step: 676] cost: 1.472900629043579\n",
      "[step: 677] cost: 1.4727623462677002\n",
      "[step: 678] cost: 1.4726241827011108\n",
      "[step: 679] cost: 1.4724863767623901\n",
      "[step: 680] cost: 1.4723490476608276\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 681] cost: 1.4722124338150024\n",
      "[step: 682] cost: 1.472076654434204\n",
      "[step: 683] cost: 1.4719411134719849\n",
      "[step: 684] cost: 1.4718055725097656\n",
      "[step: 685] cost: 1.4716702699661255\n",
      "[step: 686] cost: 1.471535325050354\n",
      "[step: 687] cost: 1.4714001417160034\n",
      "[step: 688] cost: 1.471265435218811\n",
      "[step: 689] cost: 1.4711309671401978\n",
      "[step: 690] cost: 1.470996618270874\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.4041096\n",
      "[step: 691] cost: 1.4708623886108398\n",
      "[step: 692] cost: 1.4707281589508057\n",
      "[step: 693] cost: 1.4705944061279297\n",
      "[step: 694] cost: 1.4704607725143433\n",
      "[step: 695] cost: 1.470327615737915\n",
      "[step: 696] cost: 1.4701950550079346\n",
      "[step: 697] cost: 1.4700628519058228\n",
      "[step: 698] cost: 1.4699312448501587\n",
      "[step: 699] cost: 1.4698004722595215\n",
      "[step: 700] cost: 1.4696707725524902\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.4041096\n",
      "[step: 701] cost: 1.4695425033569336\n",
      "[step: 702] cost: 1.4694154262542725\n",
      "[step: 703] cost: 1.4692896604537964\n",
      "[step: 704] cost: 1.4691650867462158\n",
      "[step: 705] cost: 1.4690419435501099\n",
      "[step: 706] cost: 1.4689198732376099\n",
      "[step: 707] cost: 1.468798041343689\n",
      "[step: 708] cost: 1.4686763286590576\n",
      "[step: 709] cost: 1.4685542583465576\n",
      "[step: 710] cost: 1.4684315919876099\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.4041096\n",
      "[step: 711] cost: 1.468308448791504\n",
      "[step: 712] cost: 1.468185305595398\n",
      "[step: 713] cost: 1.4680620431900024\n",
      "[step: 714] cost: 1.4679391384124756\n",
      "[step: 715] cost: 1.4678168296813965\n",
      "[step: 716] cost: 1.4676953554153442\n",
      "[step: 717] cost: 1.4675744771957397\n",
      "[step: 718] cost: 1.4674543142318726\n",
      "[step: 719] cost: 1.4673347473144531\n",
      "[step: 720] cost: 1.4672152996063232\n",
      "학습 정확도: 0.35588235\n",
      "테스트 정확도: 0.4041096\n",
      "[step: 721] cost: 1.467095971107483\n",
      "[step: 722] cost: 1.4669767618179321\n",
      "[step: 723] cost: 1.4668574333190918\n",
      "[step: 724] cost: 1.4667381048202515\n",
      "[step: 725] cost: 1.4666186571121216\n",
      "[step: 726] cost: 1.4664990901947021\n",
      "[step: 727] cost: 1.4663797616958618\n",
      "[step: 728] cost: 1.4662604331970215\n",
      "[step: 729] cost: 1.4661412239074707\n",
      "[step: 730] cost: 1.46602201461792\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.4041096\n",
      "[step: 731] cost: 1.4659028053283691\n",
      "[step: 732] cost: 1.4657834768295288\n",
      "[step: 733] cost: 1.4656641483306885\n",
      "[step: 734] cost: 1.4655441045761108\n",
      "[step: 735] cost: 1.465423822402954\n",
      "[step: 736] cost: 1.46530282497406\n",
      "[step: 737] cost: 1.4651808738708496\n",
      "[step: 738] cost: 1.4650583267211914\n",
      "[step: 739] cost: 1.4649348258972168\n",
      "[step: 740] cost: 1.4648103713989258\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.4041096\n",
      "[step: 741] cost: 1.4646846055984497\n",
      "[step: 742] cost: 1.4645576477050781\n",
      "[step: 743] cost: 1.4644289016723633\n",
      "[step: 744] cost: 1.4642983675003052\n",
      "[step: 745] cost: 1.4641656875610352\n",
      "[step: 746] cost: 1.4640308618545532\n",
      "[step: 747] cost: 1.4638936519622803\n",
      "[step: 748] cost: 1.4637540578842163\n",
      "[step: 749] cost: 1.4636125564575195\n",
      "[step: 750] cost: 1.463469386100769\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.39726028\n",
      "[step: 751] cost: 1.4633257389068604\n",
      "[step: 752] cost: 1.4631826877593994\n",
      "[step: 753] cost: 1.4630423784255981\n",
      "[step: 754] cost: 1.4629071950912476\n",
      "[step: 755] cost: 1.4627792835235596\n",
      "[step: 756] cost: 1.4626579284667969\n",
      "[step: 757] cost: 1.462538719177246\n",
      "[step: 758] cost: 1.4624171257019043\n",
      "[step: 759] cost: 1.4622917175292969\n",
      "[step: 760] cost: 1.4621646404266357\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.39726028\n",
      "[step: 761] cost: 1.462038278579712\n",
      "[step: 762] cost: 1.461914300918579\n",
      "[step: 763] cost: 1.4617942571640015\n",
      "[step: 764] cost: 1.4616777896881104\n",
      "[step: 765] cost: 1.461561918258667\n",
      "[step: 766] cost: 1.4614430665969849\n",
      "[step: 767] cost: 1.461320400238037\n",
      "[step: 768] cost: 1.4611953496932983\n",
      "[step: 769] cost: 1.4610706567764282\n",
      "[step: 770] cost: 1.460947871208191\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.39726028\n",
      "[step: 771] cost: 1.4608265161514282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 772] cost: 1.4607056379318237\n",
      "[step: 773] cost: 1.460584044456482\n",
      "[step: 774] cost: 1.4604599475860596\n",
      "[step: 775] cost: 1.4603344202041626\n",
      "[step: 776] cost: 1.4602097272872925\n",
      "[step: 777] cost: 1.4600865840911865\n",
      "[step: 778] cost: 1.459964394569397\n",
      "[step: 779] cost: 1.459842562675476\n",
      "[step: 780] cost: 1.4597201347351074\n",
      "학습 정확도: 0.35\n",
      "테스트 정확도: 0.39726028\n",
      "[step: 781] cost: 1.4595974683761597\n",
      "[step: 782] cost: 1.4594743251800537\n",
      "[step: 783] cost: 1.4593517780303955\n",
      "[step: 784] cost: 1.4592303037643433\n",
      "[step: 785] cost: 1.4591091871261597\n",
      "[step: 786] cost: 1.4589877128601074\n",
      "[step: 787] cost: 1.4588656425476074\n",
      "[step: 788] cost: 1.4587429761886597\n",
      "[step: 789] cost: 1.4586201906204224\n",
      "[step: 790] cost: 1.4584977626800537\n",
      "학습 정확도: 0.34705883\n",
      "테스트 정확도: 0.39726028\n",
      "[step: 791] cost: 1.4583752155303955\n",
      "[step: 792] cost: 1.4582525491714478\n",
      "[step: 793] cost: 1.4581295251846313\n",
      "[step: 794] cost: 1.4580059051513672\n",
      "[step: 795] cost: 1.457882285118103\n",
      "[step: 796] cost: 1.4577586650848389\n",
      "[step: 797] cost: 1.4576352834701538\n",
      "[step: 798] cost: 1.4575116634368896\n",
      "[step: 799] cost: 1.4573874473571777\n",
      "[step: 800] cost: 1.4572632312774658\n",
      "학습 정확도: 0.34705883\n",
      "테스트 정확도: 0.39726028\n",
      "[step: 801] cost: 1.4571387767791748\n",
      "[step: 802] cost: 1.4570144414901733\n",
      "[step: 803] cost: 1.4568901062011719\n",
      "[step: 804] cost: 1.4567655324935913\n",
      "[step: 805] cost: 1.456640601158142\n",
      "[step: 806] cost: 1.4565155506134033\n",
      "[step: 807] cost: 1.456390380859375\n",
      "[step: 808] cost: 1.4562649726867676\n",
      "[step: 809] cost: 1.4561395645141602\n",
      "[step: 810] cost: 1.4560136795043945\n",
      "학습 정확도: 0.34117648\n",
      "테스트 정확도: 0.4178082\n",
      "[step: 811] cost: 1.4558875560760498\n",
      "[step: 812] cost: 1.455761432647705\n",
      "[step: 813] cost: 1.4556348323822021\n",
      "[step: 814] cost: 1.4555081129074097\n",
      "[step: 815] cost: 1.4553812742233276\n",
      "[step: 816] cost: 1.4552539587020874\n",
      "[step: 817] cost: 1.4551265239715576\n",
      "[step: 818] cost: 1.4549987316131592\n",
      "[step: 819] cost: 1.4548708200454712\n",
      "[step: 820] cost: 1.4547427892684937\n",
      "학습 정확도: 0.35\n",
      "테스트 정확도: 0.43150684\n",
      "[step: 821] cost: 1.454614281654358\n",
      "[step: 822] cost: 1.4544854164123535\n",
      "[step: 823] cost: 1.45435631275177\n",
      "[step: 824] cost: 1.4542269706726074\n",
      "[step: 825] cost: 1.4540971517562866\n",
      "[step: 826] cost: 1.4539669752120972\n",
      "[step: 827] cost: 1.4538366794586182\n",
      "[step: 828] cost: 1.453705906867981\n",
      "[step: 829] cost: 1.4535748958587646\n",
      "[step: 830] cost: 1.4534434080123901\n",
      "학습 정확도: 0.35\n",
      "테스트 정확도: 0.43150684\n",
      "[step: 831] cost: 1.453311562538147\n",
      "[step: 832] cost: 1.4531793594360352\n",
      "[step: 833] cost: 1.4530466794967651\n",
      "[step: 834] cost: 1.4529136419296265\n",
      "[step: 835] cost: 1.4527802467346191\n",
      "[step: 836] cost: 1.4526463747024536\n",
      "[step: 837] cost: 1.4525119066238403\n",
      "[step: 838] cost: 1.4523770809173584\n",
      "[step: 839] cost: 1.4522420167922974\n",
      "[step: 840] cost: 1.4521061182022095\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.43150684\n",
      "[step: 841] cost: 1.451970100402832\n",
      "[step: 842] cost: 1.4518334865570068\n",
      "[step: 843] cost: 1.4516961574554443\n",
      "[step: 844] cost: 1.4515584707260132\n",
      "[step: 845] cost: 1.4514201879501343\n",
      "[step: 846] cost: 1.4512814283370972\n",
      "[step: 847] cost: 1.4511418342590332\n",
      "[step: 848] cost: 1.4510020017623901\n",
      "[step: 849] cost: 1.4508615732192993\n",
      "[step: 850] cost: 1.4507205486297607\n",
      "학습 정확도: 0.3529412\n",
      "테스트 정확도: 0.43150684\n",
      "[step: 851] cost: 1.4505789279937744\n",
      "[step: 852] cost: 1.4504367113113403\n",
      "[step: 853] cost: 1.450293779373169\n",
      "[step: 854] cost: 1.450150489807129\n",
      "[step: 855] cost: 1.4500064849853516\n",
      "[step: 856] cost: 1.449862003326416\n",
      "[step: 857] cost: 1.4497166872024536\n",
      "[step: 858] cost: 1.4495710134506226\n",
      "[step: 859] cost: 1.4494245052337646\n",
      "[step: 860] cost: 1.4492777585983276\n",
      "학습 정확도: 0.35882354\n",
      "테스트 정확도: 0.42465752\n",
      "[step: 861] cost: 1.4491301774978638\n",
      "[step: 862] cost: 1.4489822387695312\n",
      "[step: 863] cost: 1.4488338232040405\n",
      "[step: 864] cost: 1.448684573173523\n",
      "[step: 865] cost: 1.4485350847244263\n",
      "[step: 866] cost: 1.448385238647461\n",
      "[step: 867] cost: 1.4482346773147583\n",
      "[step: 868] cost: 1.4480839967727661\n",
      "[step: 869] cost: 1.4479329586029053\n",
      "[step: 870] cost: 1.4477821588516235\n",
      "학습 정확도: 0.35882354\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 871] cost: 1.447633981704712\n",
      "[step: 872] cost: 1.4474903345108032\n",
      "[step: 873] cost: 1.4473339319229126\n",
      "[step: 874] cost: 1.44717276096344\n",
      "[step: 875] cost: 1.4470311403274536\n",
      "[step: 876] cost: 1.446869134902954\n",
      "[step: 877] cost: 1.446719765663147\n",
      "[step: 878] cost: 1.4465659856796265\n",
      "[step: 879] cost: 1.446409821510315\n",
      "[step: 880] cost: 1.446260690689087\n",
      "학습 정확도: 0.3617647\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 881] cost: 1.4461019039154053\n",
      "[step: 882] cost: 1.4459540843963623\n",
      "[step: 883] cost: 1.4457954168319702\n",
      "[step: 884] cost: 1.4456455707550049\n",
      "[step: 885] cost: 1.4454894065856934\n",
      "[step: 886] cost: 1.4453364610671997\n",
      "[step: 887] cost: 1.4451829195022583\n",
      "[step: 888] cost: 1.445027470588684\n",
      "[step: 889] cost: 1.444875717163086\n",
      "[step: 890] cost: 1.444718837738037\n",
      "학습 정확도: 0.36764705\n",
      "테스트 정확도: 0.41095892\n",
      "[step: 891] cost: 1.4445669651031494\n",
      "[step: 892] cost: 1.4444106817245483\n",
      "[step: 893] cost: 1.4442572593688965\n",
      "[step: 894] cost: 1.4441025257110596\n",
      "[step: 895] cost: 1.4439469575881958\n",
      "[step: 896] cost: 1.4437934160232544\n",
      "[step: 897] cost: 1.4436370134353638\n",
      "[step: 898] cost: 1.4434828758239746\n",
      "[step: 899] cost: 1.4433274269104004\n",
      "[step: 900] cost: 1.4431716203689575\n",
      "학습 정확도: 0.3617647\n",
      "테스트 정확도: 0.4178082\n",
      "[step: 901] cost: 1.4430171251296997\n",
      "[step: 902] cost: 1.4428608417510986\n",
      "[step: 903] cost: 1.4427058696746826\n",
      "[step: 904] cost: 1.4425501823425293\n",
      "[step: 905] cost: 1.4423940181732178\n",
      "[step: 906] cost: 1.4422391653060913\n",
      "[step: 907] cost: 1.4420828819274902\n",
      "[step: 908] cost: 1.441927194595337\n",
      "[step: 909] cost: 1.4417718648910522\n",
      "[step: 910] cost: 1.4416158199310303\n",
      "학습 정확도: 0.3617647\n",
      "테스트 정확도: 0.42465752\n",
      "[step: 911] cost: 1.4414602518081665\n",
      "[step: 912] cost: 1.4413049221038818\n",
      "[step: 913] cost: 1.4411488771438599\n",
      "[step: 914] cost: 1.440993309020996\n",
      "[step: 915] cost: 1.4408378601074219\n",
      "[step: 916] cost: 1.440682053565979\n",
      "[step: 917] cost: 1.4405267238616943\n",
      "[step: 918] cost: 1.4403712749481201\n",
      "[step: 919] cost: 1.440215826034546\n",
      "[step: 920] cost: 1.4400604963302612\n",
      "학습 정확도: 0.3647059\n",
      "테스트 정확도: 0.43835616\n",
      "[step: 921] cost: 1.4399054050445557\n",
      "[step: 922] cost: 1.439750075340271\n",
      "[step: 923] cost: 1.439595103263855\n",
      "[step: 924] cost: 1.4394402503967285\n",
      "[step: 925] cost: 1.4392855167388916\n",
      "[step: 926] cost: 1.4391306638717651\n",
      "[step: 927] cost: 1.4389758110046387\n",
      "[step: 928] cost: 1.43882155418396\n",
      "[step: 929] cost: 1.4386671781539917\n",
      "[step: 930] cost: 1.438512921333313\n",
      "학습 정확도: 0.3647059\n",
      "테스트 정확도: 0.4520548\n",
      "[step: 931] cost: 1.4383587837219238\n",
      "[step: 932] cost: 1.4382047653198242\n",
      "[step: 933] cost: 1.4380507469177246\n",
      "[step: 934] cost: 1.4378972053527832\n",
      "[step: 935] cost: 1.4377435445785522\n",
      "[step: 936] cost: 1.4375901222229004\n",
      "[step: 937] cost: 1.4374369382858276\n",
      "[step: 938] cost: 1.4372837543487549\n",
      "[step: 939] cost: 1.4371309280395508\n",
      "[step: 940] cost: 1.4369781017303467\n",
      "학습 정확도: 0.36764705\n",
      "테스트 정확도: 0.46575344\n",
      "[step: 941] cost: 1.4368255138397217\n",
      "[step: 942] cost: 1.4366731643676758\n",
      "[step: 943] cost: 1.4365209341049194\n",
      "[step: 944] cost: 1.4363688230514526\n",
      "[step: 945] cost: 1.436216950416565\n",
      "[step: 946] cost: 1.4360653162002563\n",
      "[step: 947] cost: 1.4359139204025269\n",
      "[step: 948] cost: 1.4357625246047974\n",
      "[step: 949] cost: 1.435611605644226\n",
      "[step: 950] cost: 1.4354605674743652\n",
      "학습 정확도: 0.36764705\n",
      "테스트 정확도: 0.45890412\n",
      "[step: 951] cost: 1.435309886932373\n",
      "[step: 952] cost: 1.4351595640182495\n",
      "[step: 953] cost: 1.4350090026855469\n",
      "[step: 954] cost: 1.4348589181900024\n",
      "[step: 955] cost: 1.4347091913223267\n",
      "[step: 956] cost: 1.4345593452453613\n",
      "[step: 957] cost: 1.4344100952148438\n",
      "[step: 958] cost: 1.434260606765747\n",
      "[step: 959] cost: 1.4341115951538086\n",
      "[step: 960] cost: 1.4339629411697388\n",
      "학습 정확도: 0.37058824\n",
      "테스트 정확도: 0.45890412\n",
      "[step: 961] cost: 1.433814287185669\n",
      "[step: 962] cost: 1.4336658716201782\n",
      "[step: 963] cost: 1.4335176944732666\n",
      "[step: 964] cost: 1.433369755744934\n",
      "[step: 965] cost: 1.4332220554351807\n",
      "[step: 966] cost: 1.4330743551254272\n",
      "[step: 967] cost: 1.4329272508621216\n",
      "[step: 968] cost: 1.432780146598816\n",
      "[step: 969] cost: 1.432633399963379\n",
      "[step: 970] cost: 1.4324867725372314\n",
      "학습 정확도: 0.37058824\n",
      "테스트 정확도: 0.45890412\n",
      "[step: 971] cost: 1.4323402643203735\n",
      "[step: 972] cost: 1.4321941137313843\n",
      "[step: 973] cost: 1.4320483207702637\n",
      "[step: 974] cost: 1.431902527809143\n",
      "[step: 975] cost: 1.4317572116851807\n",
      "[step: 976] cost: 1.4316120147705078\n",
      "[step: 977] cost: 1.4314674139022827\n",
      "[step: 978] cost: 1.4313225746154785\n",
      "[step: 979] cost: 1.4311785697937012\n",
      "[step: 980] cost: 1.4310346841812134\n",
      "학습 정확도: 0.37058824\n",
      "테스트 정확도: 0.47260273\n",
      "[step: 981] cost: 1.4308911561965942\n",
      "[step: 982] cost: 1.4307478666305542\n",
      "[step: 983] cost: 1.430604338645935\n",
      "[step: 984] cost: 1.4304600954055786\n",
      "[step: 985] cost: 1.4303158521652222\n",
      "[step: 986] cost: 1.4301726818084717\n",
      "[step: 987] cost: 1.4300308227539062\n",
      "[step: 988] cost: 1.4298890829086304\n",
      "[step: 989] cost: 1.4297469854354858\n",
      "[step: 990] cost: 1.4296045303344727\n",
      "학습 정확도: 0.37058824\n",
      "테스트 정확도: 0.48630136\n",
      "[step: 991] cost: 1.4294624328613281\n",
      "[step: 992] cost: 1.4293211698532104\n",
      "[step: 993] cost: 1.4291805028915405\n",
      "[step: 994] cost: 1.4290395975112915\n",
      "[step: 995] cost: 1.428898811340332\n",
      "[step: 996] cost: 1.428757905960083\n",
      "[step: 997] cost: 1.4286178350448608\n",
      "[step: 998] cost: 1.4284781217575073\n",
      "[step: 999] cost: 1.4283385276794434\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "ohe = OneHotEncoder()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "import_data = np.genfromtxt('../data/swr_ratio_classification_rnn.csv', delimiter=',', dtype='float')\n",
    "\n",
    "x_data = []\n",
    "\n",
    "for i in range(len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][0])\n",
    "    x_data.append(temp)\n",
    "\n",
    "y_data = []\n",
    "test_y = []\n",
    "\n",
    "for i in range(len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][1])\n",
    "    y_data.append(temp)\n",
    "\n",
    "raw_y = y_data\n",
    "    \n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "seq_length = 2\n",
    "data_dim = 1\n",
    "hidden_dim = 10\n",
    "output_dim = 5\n",
    "learning_rate = 0.001\n",
    "iterations = 1000\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(len(x_data) - seq_length):\n",
    "    _x = x_data[i:i + seq_length]\n",
    "    _y = y_data[i+seq_length]\n",
    "    dataX.append(_x)\n",
    "    dataY.append(_y)\n",
    "\n",
    "train_size = int(len(dataY) * 0.7)\n",
    "test_size = len(dataY) - train_size\n",
    "trainX, testX = np.array(dataX[0:train_size]), np.array(dataX[train_size:len(dataX)])\n",
    "trainY, testY = np.array(dataY[0:train_size]), np.array(dataY[train_size:len(dataY)])\n",
    "\n",
    "print(np.shape(trainX))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, output_dim])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([hidden_dim, output_dim]))\n",
    "b = tf.Variable(tf.random_normal([output_dim]))\n",
    "\n",
    "cell = tf.nn.rnn_cell.BasicLSTMCell(hidden_dim)\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "writer = tf.summary.FileWriter(\"./logs/swr_ratio_lstm_logs\", sess.graph)\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "for i in range(iterations):\n",
    "    _, step_cost = sess.run([optimizer, cost], feed_dict={X:trainX, Y:trainY})\n",
    "    print(\"[step: {}] cost: {}\".format(i, step_cost))\n",
    "    summary, acc = sess.run([merged, accuracy], feed_dict={X:testX, Y:testY})\n",
    "    writer.add_summary(summary, i)\n",
    "    if(i % 10 == 0):\n",
    "        print('학습 정확도:', sess.run(accuracy, feed_dict={X:trainX, Y:trainY}))\n",
    "        print('테스트 정확도:', sess.run(accuracy, feed_dict={X:testX, Y:testY}))\n",
    "\n",
    "# cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)\n",
    "# outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "# Y_pred = tf.contrib.layers.fully_connected(outputs[:, -1], output_dim, activation_fn=tf.nn.softmax)\n",
    "\n",
    "# loss = tf.reduce_sum(tf.square(Y_pred - Y))\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "# train = optimizer.minimize(loss)\n",
    "\n",
    "# targets = tf.placeholder(tf.float32, [None, 5])\n",
    "# predictions = tf.placeholder(tf.float32, [None, 5])\n",
    "# rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     init = tf.global_variables_initializer()\n",
    "#     sess.run(init)\n",
    "    \n",
    "#     for i in range(iterations):\n",
    "#         _, step_loss = sess.run([train, loss], feed_dict={X:trainX, Y:trainY})\n",
    "#         print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "        \n",
    "#     test_predict = sess.run(Y_pred, feed_dict={X:testX})\n",
    "#     rmse_val = sess.run(rmse, feed_dict={targets:testY, predictions:test_predict})\n",
    "#     print(\"RMSE:{}\".format(rmse_val))\n",
    "    \n",
    "#     print(sess.run(tf.argmax(test_predict, 1)))\n",
    "#     print(len(dataX), len(trainX), len(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6f73e7901064>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;36m55.17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RNN' is not defined"
     ]
    }
   ],
   "source": [
    "seq_length = 5\n",
    "RNN\n",
    "55.17\n",
    "\n",
    "LSTM\n",
    "55.17\n",
    "\n",
    "seq_length = 4\n",
    "RNN\n",
    "704\n",
    "52.74\n",
    "\n",
    "LSTM\n",
    "1000\n",
    "54.11\n",
    "\n",
    "seq_length = 3\n",
    "RNN\n",
    "52.05\n",
    "\n",
    "LSTM\n",
    "52.05\n",
    "\n",
    "seq_length = 2\n",
    "RNN\n",
    "50.68\n",
    "\n",
    "LSTM\n",
    "48.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
