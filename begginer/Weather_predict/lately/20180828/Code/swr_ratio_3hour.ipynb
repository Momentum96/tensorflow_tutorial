{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-13 7:35:00 7:35:00\n",
      "2017-12-13 17:35:00 17:35:00\n",
      "2017-12-13 am saved.\n",
      "2017-12-13 pm saved.\n",
      "2017-12-27 7:42:00 7:42:00\n",
      "2017-12-27 17:42:00 17:42:00\n",
      "2017-12-27 am saved.\n",
      "2017-12-27 pm saved.\n",
      "2017-12-28 7:43:00 7:43:00\n",
      "2017-12-28 17:43:00 17:43:00\n",
      "2017-12-28 am saved.\n",
      "2017-12-28 pm saved.\n",
      "2018-01-03 7:44:00 7:44:00\n",
      "2018-01-03 17:44:00 17:44:00\n",
      "2018-01-03 am saved.\n",
      "2018-01-03 pm saved.\n",
      "2018-01-05 7:45:00 7:44:00\n",
      "2018-01-05 17:44:00 17:44:00\n",
      "2018-01-05 am saved.\n",
      "2018-01-05 pm saved.\n",
      "2018-01-06 7:44:00 7:44:00\n",
      "2018-01-06 17:44:00 17:44:00\n",
      "2018-01-06 am saved.\n",
      "2018-01-06 pm saved.\n",
      "2018-01-07 7:44:00 7:44:00\n",
      "2018-01-07 17:44:00 17:44:00\n",
      "2018-01-07 am saved.\n",
      "2018-01-07 pm saved.\n",
      "2018-02-16 7:19:00 7:19:00\n",
      "2018-02-16 18:19:00 18:19:00\n",
      "2018-02-16 am saved.\n",
      "2018-02-16 pm saved.\n",
      "2018-02-17 7:18:00 7:18:00\n",
      "2018-02-17 18:18:00 18:18:00\n",
      "2018-02-17 am saved.\n",
      "2018-02-17 pm saved.\n",
      "2018-02-24 7:09:00 7:09:00\n",
      "2018-02-24 18:09:00 18:09:00\n",
      "2018-02-24 am saved.\n",
      "2018-02-24 pm saved.\n",
      "2018-02-25 7:08:00 7:08:00\n",
      "2018-02-25 18:08:00 18:08:00\n",
      "2018-02-25 am saved.\n",
      "2018-02-25 pm saved.\n",
      "2018-02-27 7:05:00 7:05:00\n",
      "2018-02-27 18:05:00 18:05:00\n",
      "2018-02-27 am saved.\n",
      "2018-02-27 pm saved.\n"
     ]
    }
   ],
   "source": [
    "# 분별 날짜 파일에 있는 날짜 기준으로 DB에서 데이터 받아와서 저장하기\n",
    "\n",
    "import MySQLdb\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# MySQL DB 연결\n",
    "db = MySQLdb.connect('210.102.142.13',\"root\", \"witlab8*\", \"cas_db\")\n",
    "c = db.cursor()\n",
    "\n",
    "# 분별 날짜\n",
    "date = np.genfromtxt('../data/date_winter.csv', delimiter=',', dtype='str')\n",
    "# date = np.genfromtxt('../data/test_date_summer.csv', delimiter=',', dtype='str')\n",
    "\n",
    "# csv 파일로 내보내기\n",
    "w = open('../data/db_connect_data_am.csv', 'w', encoding='utf-8')\n",
    "# w = open('../data/db_connect_test_data_am.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "# csv 파일로 내보내기\n",
    "w2 = open('../data/db_connect_data_pm.csv', 'w', encoding='utf-8')\n",
    "# w2 = open('../data/db_connect_test_data_pm.csv', 'w', encoding='utf-8')\n",
    "wr2 = csv.writer(w2)\n",
    "\n",
    "# 각 날짜별 데이터들 DB에서 가져오고 csv 파일로 저장\n",
    "# swr, mwr, lwr data 받아옴\n",
    "for j in range(len(date)):\n",
    "    sql = \"select time(date),cas_swr, cas_mwr, cas_lwr from natural_tracker left outer join cas_wave_ratio using(date) where date(date) = '\"+ str(date[j][0]) + \"' order by time(date)\"\n",
    "    c.execute(sql)\n",
    "    rows = c.fetchall()\n",
    "    \n",
    "     # 일출 후 6시간과 일몰 후 6시간 데이터 사용, 일출 혹은 일몰 당시 데이터가 없을 경우 가장 가까운 다른 데이터로 변환\n",
    "    sunrise = datetime.datetime.strptime(date[j][1], '%H:%M:%S')\n",
    "    sunset = datetime.datetime.strptime(date[j][2], '%H:%M:%S')\n",
    "    \n",
    "    standard = datetime.datetime.strptime('1900-01-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    sunrise = sunrise - standard\n",
    "    sunset = sunset - standard\n",
    "    \n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if(rows[i][0] >= sunrise):\n",
    "            start = i\n",
    "            print(date[j][0], rows[start][0], sunrise)\n",
    "            break;\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if(rows[i][0] >= sunset):\n",
    "            end = i\n",
    "            print(date[j][0], rows[end][0], sunset)\n",
    "            break;\n",
    "\n",
    "    # start에 저장된 index부터 772개 데이터 가져와서 저장\n",
    "    for l in range(start + 180, start + 360):\n",
    "        wr.writerow([rows[l][1], rows[l][2], rows[l][3]])\n",
    "    print(date[j][0] + \" am saved.\")\n",
    "    \n",
    "    for l in range(end - 360, end - 180):\n",
    "        wr2.writerow([rows[l][1], rows[l][2], rows[l][3]])\n",
    "    print(date[j][0] + \" pm saved.\")\n",
    "        \n",
    "w.close()\n",
    "w2.close()\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = np.genfromtxt('../data/date_winter.csv', delimiter=',', dtype='str')\n",
    "# date = np.genfromtxt('../data/test_date_summer.csv', delimiter=',', dtype='str')\n",
    "\n",
    "import_data = np.loadtxt('../data/db_connect_data_am.csv', delimiter=',')\n",
    "# import_data = np.loadtxt('../data/db_connect_test_data_am.csv', delimiter=',')\n",
    "# import_data = np.loadtxt('../data/db_connect_data_pm.csv', delimiter=',')\n",
    "# import_data = np.loadtxt('../data/db_connect_test_data_pm.csv', delimiter=',')\n",
    "\n",
    "one = import_data[:,0] # swr\n",
    "two = import_data[:,1] # mwr\n",
    "thr = import_data[:,2] # lwr\n",
    "\n",
    "swr = []\n",
    "mwr = []\n",
    "lwr = []\n",
    "\n",
    "for cnt in range(len(date)): # 전체 데이터 날짜 수 (행)\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    temp3 = []\n",
    "    for i in range(180): # 한 날짜의 데이터들 한 행에 저장 (열)\n",
    "        temp.append(one[i+180*cnt])\n",
    "        temp2.append(two[i+180*cnt])\n",
    "        temp3.append(thr[i+180*cnt])\n",
    "    swr.append(temp)\n",
    "    mwr.append(temp2)\n",
    "    lwr.append(temp3)\n",
    "\n",
    "w = open('../data/swr_ratio_calculation_am.csv', 'w', encoding='utf-8')\n",
    "# w = open('../data/swr_ratio_test_calculation_am.csv', 'w', encoding='utf-8')\n",
    "# w = open('../data/swr_ratio_calculation_pm.csv', 'w', encoding='utf-8')\n",
    "# w = open('../data/swr_ratio_test_calculation_pm.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range(len(date)):\n",
    "    all_hap = 0\n",
    "    swr_hap = 0\n",
    "    ratio = 0\n",
    "    grade = 0\n",
    "    \n",
    "    for j in range(len(swr[i])):\n",
    "        swr_hap += swr[i][j]\n",
    "        all_hap += swr[i][j] + mwr[i][j] + lwr[i][j]\n",
    "    \n",
    "    ratio = round(swr_hap / all_hap * 100, 2)\n",
    "    \n",
    "#     if(ratio >= 18.00):\n",
    "#         grade += 1\n",
    "#     if(ratio >= 20.00):\n",
    "#         grade += 1\n",
    "#     if(ratio >= 22.00):\n",
    "#         grade += 1\n",
    "#     if(ratio >= 24.00):\n",
    "#         grade += 1\n",
    "        \n",
    "    if(ratio >= 19.00):\n",
    "        grade += 1\n",
    "    if(ratio >= 21.00):\n",
    "        grade += 1\n",
    "    if(ratio >= 23.00):\n",
    "        grade += 1\n",
    "    if(ratio >= 24.00):\n",
    "        grade += 1\n",
    "    \n",
    "    wr.writerow([ratio, grade])\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data = np.genfromtxt('../data/swr_ratio_calculation_am.csv', delimiter=',', dtype='float')\n",
    "import_data2 = np.genfromtxt('../data/swr_ratio_test_calculation_am.csv', delimiter=',', dtype='float')\n",
    "w = open('../data/swr_ratio_classification_input_am.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range(len(import_data)):\n",
    "    wr.writerow(import_data[i][:])\n",
    "for i in range(len(import_data2)):\n",
    "    wr.writerow(import_data2[i][:])\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 25.920576\n",
      "train accuracy =  11.11111111111111\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "test accuracy =  0.0\n",
      "1000 1.401031\n",
      "train accuracy =  55.55555555555556\n",
      "[2]\n",
      "[2]\n",
      "[2]\n",
      "test accuracy =  66.66666666666666\n",
      "2000 1.3132244\n",
      "train accuracy =  66.66666666666666\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "test accuracy =  100.0\n",
      "3000 1.2097058\n",
      "train accuracy =  66.66666666666666\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "test accuracy =  100.0\n",
      "4000 1.106214\n",
      "train accuracy =  66.66666666666666\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "test accuracy =  100.0\n",
      "5000 1.0088959\n",
      "train accuracy =  66.66666666666666\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "test accuracy =  100.0\n",
      "6000 0.91913486\n",
      "train accuracy =  66.66666666666666\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "test accuracy =  100.0\n",
      "7000 0.83757263\n",
      "train accuracy =  77.77777777777779\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "test accuracy =  100.0\n",
      "8000 0.76469636\n",
      "train accuracy =  77.77777777777779\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "test accuracy =  100.0\n",
      "9000 0.70125836\n",
      "train accuracy =  77.77777777777779\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "test accuracy =  100.0\n",
      "10000 0.6464917\n",
      "train accuracy =  77.77777777777779\n",
      "[2]\n",
      "[1]\n",
      "[2]\n",
      "test accuracy =  100.0\n",
      "-----------------------------\n",
      "train_data =  9 test_data =  3\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 모델 생성 위한 import\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# 초기값 선정 xavier 알고리즘\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    \n",
    "    if uniform:\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)\n",
    "\n",
    "# 단파장 비율 학습 및 테스트 (편차 분포)\n",
    "\n",
    "import_data = np.genfromtxt('../data/swr_ratio_calculation_am.csv', delimiter=',', dtype='float')\n",
    "\n",
    "x_data = []\n",
    "for i in range(len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][0])\n",
    "    x_data.append(temp)\n",
    "    \n",
    "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# x_data = scaler.fit_transform(x_data)\n",
    "test_x = x_data[9:]\n",
    "x_data = x_data[:9]\n",
    "\n",
    "y_data = []\n",
    "test_y = []\n",
    "\n",
    "for i in range(9):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][1])\n",
    "    y_data.append(temp)\n",
    "\n",
    "raw_y = y_data\n",
    "    \n",
    "for i in range(9, len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][1])\n",
    "    test_y.append(temp)\n",
    "\n",
    "\n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 1])\n",
    "Y = tf.placeholder(\"float\", [None, 5])\n",
    "\n",
    "nb_classes = 5\n",
    "\n",
    "# W = tf.Variable(tf.random_normal([1, nb_classes]), name='weight')\n",
    "# b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# Xavier Initializer 추가 코드\n",
    "W = tf.get_variable(\"W\", shape=[1, nb_classes], initializer=xavier_init(1, nb_classes))\n",
    "b = tf.Variable(tf.zeros([nb_classes]))\n",
    "\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 1000 == 0:\n",
    "            train_accuracy = 0\n",
    "            test_accuracy = 0\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "            \n",
    "            for i in range(len(x_data)):\n",
    "                a = sess.run(H, feed_dict={X:[x_data[i]]})\n",
    "                if(sess.run(tf.argmax(a, 1)) == (raw_y[i][0])):\n",
    "                    train_accuracy += 1\n",
    "            print(\"train accuracy = \", float(train_accuracy / len(x_data) * 100))\n",
    "\n",
    "            for i in range(len(test_x)):\n",
    "                a = sess.run(H, feed_dict={X:[test_x[i]]})\n",
    "                if(sess.run(tf.argmax(a, 1)) == (test_y[i][0])):\n",
    "                    test_accuracy += 1\n",
    "                print(sess.run(tf.argmax(a, 1)))\n",
    "            print(\"test accuracy = \", float(test_accuracy / len(test_x) * 100))\n",
    "\n",
    "    print('-----------------------------')\n",
    "\n",
    "    print('train_data = ', len(x_data), 'test_data = ', len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "봄\n",
    "[1] 일출 후 3시간 ~ 일출 후 6시간 정확도 64.28% (2로만 나옴) 37,14\n",
    "[2] 일출 후 6시간 ~ 일몰 전 6시간-3시간 정확도 71.43% (3 두개, 나머지 모두 2) 37,14\n",
    "[3] 일몰 전 6시간-3시간 ~ 일몰 전 3시간 정확도 64.28% (1 하나, 4 하나, 나머지 모두 0) 37,14 \n",
    "\n",
    "여름\n",
    "[1] 정확도 20% 20, 15\n",
    "[2] 정확도 20% 20, 15\n",
    "[3] 정확도 46.67% (1 두개, 나머지 모두 0) 20, 15\n",
    "\n",
    "가을\n",
    "[1] 정확도 0% 16, 8\n",
    "[2] 정확도 50%\n",
    "[3] 정확도 75% (모두 0으로 예측)\n",
    "\n",
    "겨울\n",
    "[1] 정확도 0% 9, 3\n",
    "[2] 정확도 100%\n",
    "[3] 정확도 33.33%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
