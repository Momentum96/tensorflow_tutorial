{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분별 날짜 파일에 있는 날짜 기준으로 DB에서 데이터 받아와서 저장하기\n",
    "\n",
    "import MySQLdb\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "# MySQL DB 연결\n",
    "db = MySQLdb.connect('210.102.142.13',\"root\", \"witlab8*\", \"cas_db\")\n",
    "c = db.cursor()\n",
    "\n",
    "# 분별 날짜\n",
    "date = np.genfromtxt('./date.csv', delimiter=',', dtype='str')\n",
    "# date = np.genfromtxt('./test_date.csv', delimiter=',', dtype='str')\n",
    "\n",
    "# csv 파일로 내보내기\n",
    "w = open('classification_many_data.csv', 'w', encoding='utf-8')\n",
    "# w = open('rain_data_cct_swr_data.csv', 'w', encoding='utf-8')\n",
    "# w = open('rain_data.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6:00:00\n",
      "2017-04-13 saved.\n",
      "6:00:00\n",
      "2017-04-19 saved.\n",
      "6:00:00\n",
      "2017-04-21 saved.\n",
      "6:00:00\n",
      "2017-04-22 saved.\n",
      "6:00:00\n",
      "2017-04-24 saved.\n",
      "6:00:00\n",
      "2017-05-01 saved.\n",
      "6:01:00\n",
      "2017-05-02 saved.\n",
      "6:00:00\n",
      "2017-05-15 saved.\n",
      "6:00:00\n",
      "2017-05-17 saved.\n",
      "6:00:00\n",
      "2017-05-18 saved.\n",
      "6:00:00\n",
      "2017-05-22 saved.\n",
      "6:00:00\n",
      "2017-05-23 saved.\n",
      "6:00:00\n",
      "2017-05-25 saved.\n",
      "6:00:00\n",
      "2017-05-30 saved.\n",
      "6:00:00\n",
      "2017-06-02 saved.\n",
      "6:00:00\n",
      "2017-06-05 saved.\n",
      "6:00:00\n",
      "2017-06-09 saved.\n",
      "6:00:00\n",
      "2017-06-10 saved.\n",
      "6:00:00\n",
      "2017-06-14 saved.\n",
      "6:00:00\n",
      "2017-06-15 saved.\n",
      "6:00:00\n",
      "2017-06-19 saved.\n",
      "6:00:00\n",
      "2017-06-20 saved.\n",
      "6:00:00\n",
      "2017-06-21 saved.\n",
      "6:00:00\n",
      "2017-06-22 saved.\n",
      "6:00:00\n",
      "2017-07-12 saved.\n",
      "6:00:00\n",
      "2017-07-13 saved.\n",
      "6:00:00\n",
      "2017-07-20 saved.\n",
      "6:00:00\n",
      "2017-07-26 saved.\n",
      "6:00:00\n",
      "2017-07-27 saved.\n",
      "6:00:00\n",
      "2017-08-02 saved.\n",
      "6:00:00\n",
      "2017-08-22 saved.\n",
      "6:00:00\n",
      "2017-08-26 saved.\n",
      "6:00:00\n",
      "2017-08-30 saved.\n",
      "6:01:00\n",
      "2017-08-31 saved.\n",
      "6:00:00\n",
      "2017-09-01 saved.\n",
      "6:00:00\n",
      "2017-09-08 saved.\n",
      "6:00:00\n",
      "2017-09-09 saved.\n",
      "6:00:00\n",
      "2017-09-10 saved.\n",
      "6:00:00\n",
      "2017-09-12 saved.\n",
      "6:00:00\n",
      "2017-09-13 saved.\n",
      "6:00:00\n",
      "2017-09-14 saved.\n",
      "6:00:00\n",
      "2017-09-18 saved.\n",
      "6:00:00\n",
      "2017-09-21 saved.\n",
      "6:00:00\n",
      "2017-09-22 saved.\n",
      "6:00:00\n",
      "2017-09-24 saved.\n",
      "6:00:00\n",
      "2017-09-28 saved.\n",
      "6:00:00\n",
      "2017-10-08 saved.\n",
      "6:00:00\n",
      "2017-10-09 saved.\n",
      "6:00:00\n",
      "2017-10-14 saved.\n",
      "6:00:00\n",
      "2017-10-19 saved.\n",
      "6:00:00\n",
      "2017-10-21 saved.\n",
      "6:01:00\n",
      "2017-10-24 saved.\n",
      "6:00:00\n",
      "2017-10-30 saved.\n",
      "6:00:00\n",
      "2017-10-31 saved.\n",
      "6:00:00\n",
      "2017-11-11 saved.\n",
      "6:00:00\n",
      "2017-11-12 saved.\n",
      "6:00:00\n",
      "2017-11-15 saved.\n",
      "6:00:00\n",
      "2017-11-16 saved.\n",
      "6:00:00\n",
      "2017-12-13 saved.\n",
      "6:00:00\n",
      "2017-12-27 saved.\n",
      "6:00:00\n",
      "2017-12-28 saved.\n",
      "6:00:00\n",
      "2018-01-03 saved.\n",
      "6:00:00\n",
      "2018-01-05 saved.\n",
      "6:00:00\n",
      "2018-01-06 saved.\n",
      "6:00:00\n",
      "2018-01-07 saved.\n",
      "6:00:00\n",
      "2018-02-16 saved.\n",
      "6:00:00\n",
      "2018-02-17 saved.\n",
      "6:00:00\n",
      "2018-02-24 saved.\n",
      "6:00:00\n",
      "2018-02-25 saved.\n",
      "6:00:00\n",
      "2018-02-27 saved.\n",
      "6:00:00\n",
      "2018-03-03 saved.\n",
      "6:00:00\n",
      "2018-03-07 saved.\n",
      "6:00:00\n",
      "2018-03-10 saved.\n",
      "6:00:00\n",
      "2018-03-24 saved.\n",
      "6:00:00\n",
      "2018-03-26 saved.\n",
      "6:00:00\n",
      "2018-03-27 saved.\n",
      "6:00:00\n",
      "2018-03-31 saved.\n",
      "6:00:00\n",
      "2018-04-07 saved.\n",
      "6:00:00\n",
      "2018-04-09 saved.\n",
      "6:00:00\n",
      "2018-04-10 saved.\n",
      "6:00:00\n",
      "2018-04-12 saved.\n",
      "6:00:00\n",
      "2018-04-13 saved.\n",
      "6:00:00\n",
      "2018-04-16 saved.\n",
      "6:00:00\n",
      "2018-04-17 saved.\n",
      "6:00:00\n",
      "2018-04-18 saved.\n"
     ]
    }
   ],
   "source": [
    "# 각 날짜별 데이터들 DB에서 가져오고 csv 파일로 저장\n",
    "# 데이터는 cct, swr, uvb, uvi 순\n",
    "for j in range(len(date)):\n",
    "    sql = \"select time(date), date(date), cct, cas_swr, uvb from natural_tracker left outer join cas_wave_ratio using(date) where date(date) = '\"+ str(date[j]) + \"' order by time(date)\"\n",
    "    c.execute(sql)\n",
    "    rows = c.fetchall()\n",
    "    \n",
    "    # 오전 6:00:00 데이터부터 읽어들이기. 그 순간의 index를 start에 저장\n",
    "    start = 0\n",
    "    \n",
    "    for i in range(len(rows)):\n",
    "        if(str(rows[i][0]) == '6:00:00'):\n",
    "            start = i\n",
    "            print(rows[start][0])\n",
    "            break;\n",
    "        if(str(rows[i][0]) == '6:01:00'):\n",
    "            start = i\n",
    "            print(rows[start][0])\n",
    "            break;\n",
    "\n",
    "    # start에 저장된 index부터 772개 데이터 가져와서 저장\n",
    "    for l in range(start, start+772):\n",
    "        wr.writerow([rows[l][2], rows[l][3], rows[l][4]])\n",
    "    print(date[j] + \" saved.\")\n",
    "        \n",
    "w.close()\n",
    "db.close()\n",
    "\n",
    "# 데이터 받아오고 편차 계산히기\n",
    "import_data = np.loadtxt('./classification_many_data.csv', delimiter=',')\n",
    "\n",
    "one = import_data[:,0] # cct\n",
    "two = import_data[:,1] # cas_swr\n",
    "thr = import_data[:,2] # uvb\n",
    "\n",
    "\n",
    "# # 날짜별 772개의 데이터 모두 저장, 2차원 배열\n",
    "cct = []\n",
    "swr = []\n",
    "uvb = []\n",
    "\n",
    "\n",
    "# 날짜별 데이터의 편차 (데이터 수 - 1)개의 데이터 모두 저장, 2차원 배열\n",
    "delta_cct = []\n",
    "delta_swr = []\n",
    "delta_uvb = []\n",
    "\n",
    "# 각 날짜별 raw data 총 합 저장, 2차원 배열\n",
    "cct_hap = []\n",
    "swr_hap = []\n",
    "uvb_hap = []\n",
    "\n",
    "# raw data들 저장\n",
    "for cnt in range(len(date)): # 전체 데이터 날짜 수 (행)\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    temp3 = []\n",
    "    for i in range(772): # 한 날짜의 데이터들 한 행에 저장 (열)\n",
    "        temp.append(one[i+772*cnt])\n",
    "        temp2.append(two[i+772*cnt])\n",
    "        temp3.append(thr[i+772*cnt])\n",
    "    cct.append(temp)\n",
    "    swr.append(temp2)\n",
    "    uvb.append(temp3)\n",
    "\n",
    "# 편차 데이터 저장\n",
    "for cnt in range(len(date)): \n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    temp3 = []\n",
    "    for i in range(771):\n",
    "        temp.append(cct[cnt][i+1] - cct[cnt][i])\n",
    "        temp2.append(swr[cnt][i+1] - swr[cnt][i])\n",
    "        temp3.append(uvb[cnt][i+1] - uvb[cnt][i])\n",
    "    delta_cct.append(temp)\n",
    "    delta_swr.append(temp2)\n",
    "    delta_uvb.append(temp3)\n",
    "\n",
    "# temp = []\n",
    "# temp2 = []\n",
    "# temp3 = []\n",
    "# for i in range(771):\n",
    "#     temp.append(cct[i+1] - cct[i])\n",
    "#     temp2.append(swr[i+1] - swr[i])\n",
    "#     temp3.append(uvb[i+1] - uvb[i])\n",
    "# delta_cct.append(temp)\n",
    "# delta_swr.append(temp2)\n",
    "# delta_uvb.append(temp3)\n",
    "\n",
    "\n",
    "# raw data 합 저장\n",
    "for i in range(len(date)):\n",
    "    temp1 = 0\n",
    "    temp2 = 0\n",
    "    temp3 = 0\n",
    "    for j in range(len(cct[0])):\n",
    "        temp1 += cct[i][j]\n",
    "        temp2 += swr[i][j]\n",
    "        temp3 += uvb[i][j]\n",
    "    cct_hap.append(temp1)\n",
    "    swr_hap.append(temp2)\n",
    "    uvb_hap.append(temp3)\n",
    "    \n",
    "# temp1 = 0\n",
    "# temp2 = 0\n",
    "# temp3 = 0\n",
    "# for j in range(len(cct)):\n",
    "#     temp1 += cct[j]\n",
    "#     temp2 += swr[j]\n",
    "#     temp3 += uvb[j]\n",
    "# cct_hap.append(temp1)\n",
    "# swr_hap.append(temp2)\n",
    "# uvb_hap.append(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql = \"select time(date), date(date), cct, cas_swr, uvb from natural_tracker left outer join cas_wave_ratio using(date) where date(date) = '2017-08-17' order by time(date)\"\n",
    "# c.execute(sql)\n",
    "# rows = c.fetchall()\n",
    "    \n",
    "#     # 오전 6:00:00 데이터부터 읽어들이기. 그 순간의 index를 start에 저장\n",
    "# start = 0\n",
    "\n",
    "# print(len(rows))\n",
    "\n",
    "# for i in range(len(rows)):\n",
    "# #     if(str(rows[i][0]) == '6:00:00'):\n",
    "#     if(str(rows[i][0]) == '6:00:46'):\n",
    "#         start = i\n",
    "#         print(rows[start][0])\n",
    "#         break;\n",
    "#     if(str(rows[i][0]) == '6:01:00'):\n",
    "#         start = i\n",
    "#         print(rows[start][0])\n",
    "#         break;\n",
    "\n",
    "# # start에 저장된 index부터 772개 데이터 가져와서 저장\n",
    "# for l in range(start, start+772):\n",
    "#     wr.writerow([rows[l][2], rows[l][3], rows[l][4]])\n",
    "# print(\" saved.\")\n",
    "\n",
    "# import_data = np.loadtxt('./rain_data.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = open('rain_data_cct_swr_data.csv', 'w', encoding='utf-8')\n",
    "# w = open('rain_data_cct_swr.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range(len(delta_cct)):\n",
    "    up_dot_25 = 0\n",
    "    up_dot_50 = 0\n",
    "    up_dot_100 = 0\n",
    "    up_dot_150 = 0\n",
    "    up_dot_200 = 0\n",
    "    up_dot_250 = 0\n",
    "    up_dot_300 = 0\n",
    "    up_dot_350 = 0\n",
    "    up_dot_400 = 0\n",
    "    up_dot_450 = 0\n",
    "    up_dot_500 = 0\n",
    "\n",
    "    # 위 변수들을 비율로 계산\n",
    "    percent_1 = 0\n",
    "    percent_2 = 0\n",
    "    percent_3 = 0\n",
    "    percent_4 = 0\n",
    "    percent_5 = 0\n",
    "    percent_6 = 0\n",
    "    percent_7 = 0\n",
    "    percent_8 = 0\n",
    "    percent_9 = 0\n",
    "    percent_10 = 0\n",
    "    percent_11 = 0\n",
    "\n",
    "    # 편차의 합, 평균, 등급 저장\n",
    "    hap = 0\n",
    "    avg = 0\n",
    "    grade = 0\n",
    "\n",
    "    # 편차 절댓값을 기준으로 갯수 저장\n",
    "    for j in range(len(delta_cct[i])):\n",
    "        if(abs(delta_cct[i][j]) >= 25):\n",
    "            up_dot_25 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 50):\n",
    "            up_dot_50 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 100):\n",
    "            up_dot_100 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 150):\n",
    "            up_dot_150 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 200):\n",
    "            up_dot_200 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 250):\n",
    "            up_dot_250 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 300):\n",
    "            up_dot_300 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 350):\n",
    "            up_dot_350 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 400):\n",
    "            up_dot_400 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 450):\n",
    "            up_dot_450 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 500):\n",
    "            up_dot_500 += 1\n",
    "        \n",
    "        # 편차 합 및 평균 저장\n",
    "        hap += abs(delta_cct[i][j])\n",
    "        avg = hap / 771\n",
    "\n",
    "        # 편차 갯수들이 차지하는 비율 소수점 둘째짜리까지 계산\n",
    "        percent_1 = round(up_dot_25 / 772 * 100, 2)\n",
    "        percent_2 = round(up_dot_50 / 772 * 100, 2)\n",
    "        percent_3 = round(up_dot_100 / 772 * 100, 2)\n",
    "        percent_4 = round(up_dot_150 / 772 * 100, 2)\n",
    "        percent_5 = round(up_dot_200 / 772 * 100, 2)\n",
    "        percent_6 = round(up_dot_250 / 772 * 100, 2)\n",
    "        percent_7 = round(up_dot_300 / 772 * 100, 2)\n",
    "        percent_8 = round(up_dot_350 / 772 * 100, 2)\n",
    "        percent_9 = round(up_dot_400 / 772 * 100, 2)\n",
    "        percent_10 = round(up_dot_450 / 772 * 100, 2)\n",
    "        percent_11 = round(up_dot_500 / 772 * 100, 2)\n",
    "\n",
    "    # 등급 선정 기준\n",
    "#     if(percent_2 > 15.0):\n",
    "#         grade += 1\n",
    "    \n",
    "#     if(cct_hap[i] < 3900000.0 or cct_hap[i] > 4100000.0):\n",
    "#         grade += 1\n",
    "    \n",
    "#     if(percent_1 > 30.0):\n",
    "#         grade += 1\n",
    "        \n",
    "#     if(hap > 30000.0):\n",
    "#         grade += 1\n",
    "        \n",
    "        # 편차의 절대값이 0.1 ~ 5이상인 경우의 갯수 저장\n",
    "    up_dot_1 = 0\n",
    "    up_dot_2 = 0\n",
    "    up_dot_3 = 0\n",
    "    up_dot_4 = 0\n",
    "    up_dot_5 = 0\n",
    "    up_dot_6 = 0\n",
    "    up_dot_7 = 0\n",
    "    up_dot_8 = 0\n",
    "    up_dot_9 = 0\n",
    "    up_dot_10 = 0\n",
    "    up_dot_20 = 0\n",
    "    up_dot_30 = 0\n",
    "    up_dot_40 = 0\n",
    "    up_dot_50_2 = 0\n",
    "\n",
    "    # 위의 갯수가 하루 전체 데이터에서 차지하는 비율 저장\n",
    "    percent_1 = 0\n",
    "    percent_2 = 0\n",
    "    percent_3 = 0\n",
    "    percent_4 = 0\n",
    "    percent_5 = 0\n",
    "    percent_6 = 0\n",
    "    percent_7 = 0\n",
    "    percent_8 = 0\n",
    "    percent_9 = 0\n",
    "    percent_10 = 0\n",
    "    percent_20 = 0\n",
    "    percent_30 = 0\n",
    "    percent_40 = 0\n",
    "    percent_50_2 = 0\n",
    "\n",
    "    # 편차의 합, 평균, 등급 저장\n",
    "    hap_2 = 0\n",
    "    avg_2 = 0\n",
    "    grade = 0\n",
    "\n",
    "    for j in range(len(delta_swr[i])):\n",
    "        if(abs(delta_swr[i][j]) >= 0.1):\n",
    "            up_dot_1 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.2):\n",
    "            up_dot_2 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.3):\n",
    "            up_dot_3 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.4):\n",
    "            up_dot_4 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.5):\n",
    "            up_dot_5 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.6):\n",
    "            up_dot_6 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.7):\n",
    "            up_dot_7 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.8):\n",
    "            up_dot_8 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.9):\n",
    "            up_dot_9 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 1):\n",
    "            up_dot_10 += 1\n",
    "        if(abs(delta_swr[i][j] >= 2)):\n",
    "            up_dot_20 += 1\n",
    "        if(abs(delta_swr[i][j] >= 3)):\n",
    "            up_dot_30 += 1\n",
    "        if(abs(delta_swr[i][j] >= 4)):\n",
    "            up_dot_40 += 1\n",
    "        if(abs(delta_swr[i][j] >= 5)):\n",
    "            up_dot_50_2 += 1\n",
    "\n",
    "        hap_2 += abs(delta_swr[i][j])\n",
    "        avg_2 = hap / 771\n",
    "\n",
    "        percent_1 = round(up_dot_1 / 772 * 100, 2);\n",
    "        percent_2 = round(up_dot_2 / 772 * 100, 2);\n",
    "        percent_3 = round(up_dot_3 / 772 * 100, 2);\n",
    "        percent_4 = round(up_dot_4 / 772 * 100, 2);\n",
    "        percent_5 = round(up_dot_5 / 772 * 100, 2);\n",
    "        percent_6 = round(up_dot_6 / 772 * 100, 2);\n",
    "        percent_7 = round(up_dot_7 / 772 * 100, 2);\n",
    "        percent_8 = round(up_dot_8 / 772 * 100, 2);\n",
    "        percent_9 = round(up_dot_9 / 772 * 100, 2);\n",
    "        percent_10 = round(up_dot_10 / 772 * 100, 2);\n",
    "        percent_20 = round(up_dot_20 / 772 * 100, 2);\n",
    "        percent_30 = round(up_dot_30 / 772 * 100, 2);\n",
    "        percent_40 = round(up_dot_40 / 772 * 100, 2);\n",
    "        percent_50 = round(up_dot_50 / 772 * 100, 2);\n",
    "\n",
    "        # 등급 기준 1\n",
    "    # 편차의 합이 100 이상일 경우 +1, 400 이상일 경우 +2\n",
    "#     if(hap >= 100.0):\n",
    "#         grade += 1\n",
    "    if(swr_hap[i] <= 15500.0 or swr_hap[i] >= 16500.0):\n",
    "        grade += 1\n",
    "\n",
    "    # 등급 기준 2\n",
    "    # 편차의 절대값이 0.1 이상인 경우가 전체 데이터의 25% + 1, 30%를 넘을 경우 +1, 40%를 넘을 경우 +2, 50%를 넘길 경우 +3\n",
    "    if(percent_1 >= 25.0):\n",
    "        grade += 1\n",
    "\n",
    "#     if(percent_1 >= 30.0):\n",
    "#         grade += 1\n",
    "\n",
    "    if(percent_1 >= 40.0):\n",
    "        grade += 1\n",
    "\n",
    "#     if(percent_1 >= 50.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     if(percent_1 >= 60.0):\n",
    "#         grade += 1\n",
    "\n",
    "    # 등급 기준 3\n",
    "    # 편차의 절대값이 1 이상인 경우가 전체 데이터의 5%를 넘을 경우 +1, 10%를 넘을 경우 +2\n",
    "#     if(percent_10 >= 5.0):\n",
    "#         grade += 1\n",
    "    if(percent_10 >= 10.0):\n",
    "        grade += 1\n",
    "        \n",
    "    wr.writerow([date[i], up_dot_25, up_dot_50, up_dot_100, up_dot_150, up_dot_200, up_dot_250, up_dot_300, up_dot_350, up_dot_400, up_dot_450, up_dot_500, up_dot_1, up_dot_2, up_dot_3, up_dot_4, up_dot_5, up_dot_6, up_dot_7, up_dot_8, up_dot_9, up_dot_10, up_dot_20, up_dot_30, up_dot_40, up_dot_50_2, grade])\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 색온도의 편차의 분포, 합, 평균 및 raw data 면적\n",
    "w = open('naturalLight_classification_criteria_data_cct.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "# 첫 행에 데이터 설명\n",
    "row = ['date', '25', '50', '100', '150', '200', '250', '300', '350', '400', '450', '500', 'percent_1', 'percent_2', 'percent_3', 'percent_4', 'percent_5', 'percent_6', 'percent_7', 'percent_8', 'percent_9', 'percent_10', 'percent_11', 'hap(y2-y1)', 'hap(raw)', 'avg', 'grade']\n",
    "wr.writerow(row)\n",
    "\n",
    "for i in range(len(delta_cct)):\n",
    "    # 편차가 일정 비율 이상일 때 그 갯수를 저장하는 변수들\n",
    "    up_dot_25 = 0\n",
    "    up_dot_50 = 0\n",
    "    up_dot_100 = 0\n",
    "    up_dot_150 = 0\n",
    "    up_dot_200 = 0\n",
    "    up_dot_250 = 0\n",
    "    up_dot_300 = 0\n",
    "    up_dot_350 = 0\n",
    "    up_dot_400 = 0\n",
    "    up_dot_450 = 0\n",
    "    up_dot_500 = 0\n",
    "\n",
    "    # 위 변수들을 비율로 계산\n",
    "    percent_1 = 0\n",
    "    percent_2 = 0\n",
    "    percent_3 = 0\n",
    "    percent_4 = 0\n",
    "    percent_5 = 0\n",
    "    percent_6 = 0\n",
    "    percent_7 = 0\n",
    "    percent_8 = 0\n",
    "    percent_9 = 0\n",
    "    percent_10 = 0\n",
    "    percent_11 = 0\n",
    "\n",
    "    # 편차의 합, 평균, 등급 저장\n",
    "    hap = 0\n",
    "    avg = 0\n",
    "    grade = 0\n",
    "\n",
    "    # 편차 절댓값을 기준으로 갯수 저장\n",
    "    for j in range(len(delta_cct[i])):\n",
    "        if(abs(delta_cct[i][j]) >= 25):\n",
    "            up_dot_25 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 50):\n",
    "            up_dot_50 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 100):\n",
    "            up_dot_100 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 150):\n",
    "            up_dot_150 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 200):\n",
    "            up_dot_200 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 250):\n",
    "            up_dot_250 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 300):\n",
    "            up_dot_300 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 350):\n",
    "            up_dot_350 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 400):\n",
    "            up_dot_400 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 450):\n",
    "            up_dot_450 += 1\n",
    "        if(abs(delta_cct[i][j]) >= 500):\n",
    "            up_dot_500 += 1\n",
    "        \n",
    "        # 편차 합 및 평균 저장\n",
    "        hap += abs(delta_cct[i][j])\n",
    "        avg = hap / 771\n",
    "\n",
    "        # 편차 갯수들이 차지하는 비율 소수점 둘째짜리까지 계산\n",
    "        percent_1 = round(up_dot_25 / 772 * 100, 2)\n",
    "        percent_2 = round(up_dot_50 / 772 * 100, 2)\n",
    "        percent_3 = round(up_dot_100 / 772 * 100, 2)\n",
    "        percent_4 = round(up_dot_150 / 772 * 100, 2)\n",
    "        percent_5 = round(up_dot_200 / 772 * 100, 2)\n",
    "        percent_6 = round(up_dot_250 / 772 * 100, 2)\n",
    "        percent_7 = round(up_dot_300 / 772 * 100, 2)\n",
    "        percent_8 = round(up_dot_350 / 772 * 100, 2)\n",
    "        percent_9 = round(up_dot_400 / 772 * 100, 2)\n",
    "        percent_10 = round(up_dot_450 / 772 * 100, 2)\n",
    "        percent_11 = round(up_dot_500 / 772 * 100, 2)\n",
    "\n",
    "    # 등급 선정 기준\n",
    "    if(percent_2 > 15.0):\n",
    "        grade += 1\n",
    "    \n",
    "    if(cct_hap[i] < 3900000.0 or cct_hap[i] > 4100000.0):\n",
    "        grade += 1\n",
    "    \n",
    "    if(percent_1 > 30.0):\n",
    "        grade += 1\n",
    "        \n",
    "    if(hap > 30000.0):\n",
    "        grade += 1\n",
    "\n",
    "    wr.writerow([date[i], up_dot_25, up_dot_50, up_dot_100, up_dot_150, up_dot_200, up_dot_250, up_dot_300, up_dot_350, up_dot_400, up_dot_450, up_dot_500,percent_1, percent_2, percent_3, percent_4, percent_5, percent_6, percent_7, percent_8, percent_9,percent_10, percent_11, hap, cct_hap[i], avg, grade])\n",
    "w.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단파장의 편차 분포 및 raw data 면적\n",
    "w = open('naturalLight_classification_criteria_data_swr.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "row = ['date', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1','2', '3', '4', '5', 'percent_1', 'percent_2', 'percent_3', 'percent_4', 'percent_5', 'percent_6', 'percent_7', 'percent_8', 'percent_9', 'percent_10', 'percent_20', 'percent_30', 'percent_40', 'percent_50', 'hap(y2-y1)', 'hap(raw)', 'avg', 'grade']\n",
    "wr.writerow(row)\n",
    "\n",
    "for i in range(len(delta_swr)):\n",
    "    # 편차의 절대값이 0.1 ~ 5이상인 경우의 갯수 저장\n",
    "    up_dot_1 = 0\n",
    "    up_dot_2 = 0\n",
    "    up_dot_3 = 0\n",
    "    up_dot_4 = 0\n",
    "    up_dot_5 = 0\n",
    "    up_dot_6 = 0\n",
    "    up_dot_7 = 0\n",
    "    up_dot_8 = 0\n",
    "    up_dot_9 = 0\n",
    "    up_dot_10 = 0\n",
    "    up_dot_20 = 0\n",
    "    up_dot_30 = 0\n",
    "    up_dot_40 = 0\n",
    "    up_dot_50 = 0\n",
    "\n",
    "    # 위의 갯수가 하루 전체 데이터에서 차지하는 비율 저장\n",
    "    percent_1 = 0\n",
    "    percent_2 = 0\n",
    "    percent_3 = 0\n",
    "    percent_4 = 0\n",
    "    percent_5 = 0\n",
    "    percent_6 = 0\n",
    "    percent_7 = 0\n",
    "    percent_8 = 0\n",
    "    percent_9 = 0\n",
    "    percent_10 = 0\n",
    "    percent_20 = 0\n",
    "    percent_30 = 0\n",
    "    percent_40 = 0\n",
    "    percent_50 = 0\n",
    "\n",
    "    # 편차의 합, 평균, 등급 저장\n",
    "    hap = 0\n",
    "    avg = 0\n",
    "    grade = 0\n",
    "\n",
    "    for j in range(len(delta_swr[i])):\n",
    "        if(abs(delta_swr[i][j]) >= 0.1):\n",
    "            up_dot_1 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.2):\n",
    "            up_dot_2 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.3):\n",
    "            up_dot_3 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.4):\n",
    "            up_dot_4 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.5):\n",
    "            up_dot_5 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.6):\n",
    "            up_dot_6 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.7):\n",
    "            up_dot_7 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.8):\n",
    "            up_dot_8 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.9):\n",
    "            up_dot_9 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 1):\n",
    "            up_dot_10 += 1\n",
    "        if(abs(delta_swr[i][j] >= 2)):\n",
    "            up_dot_20 += 1\n",
    "        if(abs(delta_swr[i][j] >= 3)):\n",
    "            up_dot_30 += 1\n",
    "        if(abs(delta_swr[i][j] >= 4)):\n",
    "            up_dot_40 += 1\n",
    "        if(abs(delta_swr[i][j] >= 5)):\n",
    "            up_dot_50 += 1\n",
    "\n",
    "        hap += abs(delta_swr[i][j])\n",
    "        avg = hap / 771\n",
    "\n",
    "        percent_1 = round(up_dot_1 / 772 * 100, 2);\n",
    "        percent_2 = round(up_dot_2 / 772 * 100, 2);\n",
    "        percent_3 = round(up_dot_3 / 772 * 100, 2);\n",
    "        percent_4 = round(up_dot_4 / 772 * 100, 2);\n",
    "        percent_5 = round(up_dot_5 / 772 * 100, 2);\n",
    "        percent_6 = round(up_dot_6 / 772 * 100, 2);\n",
    "        percent_7 = round(up_dot_7 / 772 * 100, 2);\n",
    "        percent_8 = round(up_dot_8 / 772 * 100, 2);\n",
    "        percent_9 = round(up_dot_9 / 772 * 100, 2);\n",
    "        percent_10 = round(up_dot_10 / 772 * 100, 2);\n",
    "        percent_20 = round(up_dot_20 / 772 * 100, 2);\n",
    "        percent_30 = round(up_dot_30 / 772 * 100, 2);\n",
    "        percent_40 = round(up_dot_40 / 772 * 100, 2);\n",
    "        percent_50 = round(up_dot_50 / 772 * 100, 2);\n",
    "\n",
    "        # 등급 기준 1\n",
    "    # 편차의 합이 100 이상일 경우 +1, 400 이상일 경우 +2\n",
    "#     if(hap >= 100.0):\n",
    "#         grade += 1\n",
    "    if(swr_hap[i] <= 15500.0 or swr_hap[i] >= 16500.0):\n",
    "        grade += 1\n",
    "\n",
    "    # 등급 기준 2\n",
    "    # 편차의 절대값이 0.1 이상인 경우가 전체 데이터의 25% + 1, 30%를 넘을 경우 +1, 40%를 넘을 경우 +2, 50%를 넘길 경우 +3\n",
    "    if(percent_1 >= 25.0):\n",
    "        grade += 1\n",
    "\n",
    "#     if(percent_1 >= 30.0):\n",
    "#         grade += 1\n",
    "\n",
    "    if(percent_1 >= 40.0):\n",
    "        grade += 1\n",
    "\n",
    "#     if(percent_1 >= 50.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     if(percent_1 >= 60.0):\n",
    "#         grade += 1\n",
    "\n",
    "    # 등급 기준 3\n",
    "    # 편차의 절대값이 1 이상인 경우가 전체 데이터의 5%를 넘을 경우 +1, 10%를 넘을 경우 +2\n",
    "#     if(percent_10 >= 5.0):\n",
    "#         grade += 1\n",
    "    if(percent_10 >= 10.0):\n",
    "        grade += 1\n",
    "\n",
    "    wr.writerow([date[i], up_dot_1, up_dot_2, up_dot_3, up_dot_4, up_dot_5, up_dot_6, up_dot_7, up_dot_8, up_dot_9, up_dot_10, up_dot_20, up_dot_30, up_dot_40, up_dot_50, percent_1, percent_2, percent_3, percent_4, percent_5, percent_6, percent_7, percent_8, percent_9, percent_10, percent_20, percent_30, percent_40, percent_50, hap,swr_hap[i], avg, grade])\n",
    "w.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 37 is out of bounds for axis 0 with size 37",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2dfd379de602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mgrade\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_dot_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_dot_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_dot_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_dot_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_dot_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_dot_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_dot_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_dot_8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_dot_9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_dot_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpercent_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0muvb_hap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrade\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 37 is out of bounds for axis 0 with size 37"
     ]
    }
   ],
   "source": [
    "# UVB의 편차 분포 및 raw data 면적\n",
    "w = open('naturalLight_classification_criteria_data_uvb.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "row = ['date', '0.01', '0.02', '0.03', '0.04', '0.05', '0.06', '0.07', '0.08', '0.09', '0.1', 'percent_1', 'percent_2', 'percent_3', 'percent_4', 'percent_5', 'percent_6', 'percent_7', 'percent_8', 'percent_9', 'percent_10', 'hap(y2-y1)','hap(raw)', 'avg', 'grade']\n",
    "wr.writerow(row)\n",
    "\n",
    "for i in range(len(delta_uvb)):\n",
    "    # 편차의 절대값이 0.1 ~ 5이상인 경우의 갯수 저장\n",
    "    up_dot_1 = 0\n",
    "    up_dot_2 = 0\n",
    "    up_dot_3 = 0\n",
    "    up_dot_4 = 0\n",
    "    up_dot_5 = 0\n",
    "    up_dot_6 = 0\n",
    "    up_dot_7 = 0\n",
    "    up_dot_8 = 0\n",
    "    up_dot_9 = 0\n",
    "    up_dot_10 = 0\n",
    "\n",
    "    # 위의 갯수가 하루 전체 데이터에서 차지하는 비율 저장\n",
    "    percent_1 = 0\n",
    "    percent_2 = 0\n",
    "    percent_3 = 0\n",
    "    percent_4 = 0\n",
    "    percent_5 = 0\n",
    "    percent_6 = 0\n",
    "    percent_7 = 0\n",
    "    percent_8 = 0\n",
    "    percent_9 = 0\n",
    "    percent_10 = 0\n",
    "\n",
    "    # 편차의 합, 평균, 등급 저장\n",
    "    hap = 0\n",
    "    avg = 0\n",
    "    grade = 0\n",
    "\n",
    "    for j in range(len(delta_uvb[i])):\n",
    "        if(abs(delta_uvb[i][j]) >= 0.01):\n",
    "            up_dot_1 += 1\n",
    "        if(abs(delta_uvb[i][j]) >= 0.02):\n",
    "            up_dot_2 += 1\n",
    "        if(abs(delta_uvb[i][j]) >= 0.03):\n",
    "            up_dot_3 += 1\n",
    "        if(abs(delta_uvb[i][j]) >= 0.04):\n",
    "            up_dot_4 += 1\n",
    "        if(abs(delta_uvb[i][j]) >= 0.05):\n",
    "            up_dot_5 += 1\n",
    "        if(abs(delta_uvb[i][j]) >= 0.06):\n",
    "            up_dot_6 += 1\n",
    "        if(abs(delta_uvb[i][j]) >= 0.07):\n",
    "            up_dot_7 += 1\n",
    "        if(abs(delta_uvb[i][j]) >= 0.08):\n",
    "            up_dot_8 += 1\n",
    "        if(abs(delta_uvb[i][j]) >= 0.09):\n",
    "            up_dot_9 += 1\n",
    "        if(abs(delta_uvb[i][j]) >= 0.1):\n",
    "            up_dot_10 += 1\n",
    "\n",
    "        hap += abs(delta_uvb[i][j])\n",
    "        avg = hap / 771\n",
    "\n",
    "        percent_1 = round(up_dot_1 / 772 * 100, 2);\n",
    "        percent_2 = round(up_dot_2 / 772 * 100, 2);\n",
    "        percent_3 = round(up_dot_3 / 772 * 100, 2);\n",
    "        percent_4 = round(up_dot_4 / 772 * 100, 2);\n",
    "        percent_5 = round(up_dot_5 / 772 * 100, 2);\n",
    "        percent_6 = round(up_dot_6 / 772 * 100, 2);\n",
    "        percent_7 = round(up_dot_7 / 772 * 100, 2);\n",
    "        percent_8 = round(up_dot_8 / 772 * 100, 2);\n",
    "        percent_9 = round(up_dot_9 / 772 * 100, 2);\n",
    "        percent_10 = round(up_dot_10 / 772 * 100, 2);\n",
    "\n",
    "    # 등급 기준 1\n",
    "    # 편차의 합이 100 이상일 경우 +1, 400 이상일 경우 +2\n",
    "#     if(hap >= 100.0):\n",
    "#         grade += 1\n",
    "    if(percent_1 >= 25.0):\n",
    "        grade += 1\n",
    "\n",
    "    # 등급 기준 2\n",
    "    # 편차의 절대값이 0.1 이상인 경우가 전체 데이터의 25% + 1, 30%를 넘을 경우 +1, 40%를 넘을 경우 +2, 50%를 넘길 경우 +3\n",
    "    \n",
    "\n",
    "#     if(percent_1 >= 30.0):\n",
    "#         grade += 1\n",
    "\n",
    "    if(percent_2 >= 10.0):\n",
    "        grade += 1\n",
    "\n",
    "#     if(percent_1 >= 50.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     if(percent_1 >= 60.0):\n",
    "#         grade += 1\n",
    "\n",
    "    # 등급 기준 3\n",
    "    # 편차의 절대값이 1 이상인 경우가 전체 데이터의 5%를 넘을 경우 +1, 10%를 넘을 경우 +2\n",
    "#     if(percent_10 >= 5.0):\n",
    "#         grade += 1\n",
    "    if(hap >= 3.0):\n",
    "        grade += 1\n",
    "        \n",
    "    if(hap >= 6.0):\n",
    "        grade += 1\n",
    "\n",
    "    wr.writerow([date[i], up_dot_1, up_dot_2, up_dot_3, up_dot_4, up_dot_5, up_dot_6, up_dot_7, up_dot_8, up_dot_9, up_dot_10, percent_1, percent_2, percent_3, percent_4, percent_5, percent_6, percent_7, percent_8, percent_9, percent_10, hap,uvb_hap[i], avg, grade])\n",
    "w.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단파장의 편차 분포 및 raw data 면적\n",
    "w = open('naturalLight_classification_criteria_data_swr.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "row = ['date', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1','2', '3', '4', '5', 'percent_1', 'percent_2', 'percent_3', 'percent_4', 'percent_5', 'percent_6', 'percent_7', 'percent_8', 'percent_9', 'percent_10', 'percent_20', 'percent_30', 'percent_40', 'percent_50', 'hap(y2-y1)', 'hap(raw)', 'avg', 'grade']\n",
    "wr.writerow(row)\n",
    "\n",
    "for i in range(len(delta_swr)):\n",
    "    # 편차의 절대값이 0.1 ~ 5이상인 경우의 갯수 저장\n",
    "    up_dot_1 = 0\n",
    "    up_dot_2 = 0\n",
    "    up_dot_3 = 0\n",
    "    up_dot_4 = 0\n",
    "    up_dot_5 = 0\n",
    "    up_dot_6 = 0\n",
    "    up_dot_7 = 0\n",
    "    up_dot_8 = 0\n",
    "    up_dot_9 = 0\n",
    "    up_dot_10 = 0\n",
    "    up_dot_20 = 0\n",
    "    up_dot_30 = 0\n",
    "    up_dot_40 = 0\n",
    "    up_dot_50 = 0\n",
    "\n",
    "    # 위의 갯수가 하루 전체 데이터에서 차지하는 비율 저장\n",
    "    percent_1 = 0\n",
    "    percent_2 = 0\n",
    "    percent_3 = 0\n",
    "    percent_4 = 0\n",
    "    percent_5 = 0\n",
    "    percent_6 = 0\n",
    "    percent_7 = 0\n",
    "    percent_8 = 0\n",
    "    percent_9 = 0\n",
    "    percent_10 = 0\n",
    "    percent_20 = 0\n",
    "    percent_30 = 0\n",
    "    percent_40 = 0\n",
    "    percent_50 = 0\n",
    "\n",
    "    # 편차의 합, 평균, 등급 저장\n",
    "    hap = 0\n",
    "    avg = 0\n",
    "    grade = 0\n",
    "\n",
    "    for j in range(len(delta_swr[i])):\n",
    "        if(abs(delta_swr[i][j]) >= 0.1):\n",
    "            up_dot_1 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.2):\n",
    "            up_dot_2 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.3):\n",
    "            up_dot_3 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.4):\n",
    "            up_dot_4 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.5):\n",
    "            up_dot_5 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.6):\n",
    "            up_dot_6 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.7):\n",
    "            up_dot_7 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.8):\n",
    "            up_dot_8 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 0.9):\n",
    "            up_dot_9 += 1\n",
    "        if(abs(delta_swr[i][j]) >= 1):\n",
    "            up_dot_10 += 1\n",
    "        if(abs(delta_swr[i][j] >= 2)):\n",
    "            up_dot_20 += 1\n",
    "        if(abs(delta_swr[i][j] >= 3)):\n",
    "            up_dot_30 += 1\n",
    "        if(abs(delta_swr[i][j] >= 4)):\n",
    "            up_dot_40 += 1\n",
    "        if(abs(delta_swr[i][j] >= 5)):\n",
    "            up_dot_50 += 1\n",
    "\n",
    "        hap += abs(delta_swr[i][j])\n",
    "        avg = hap / 771\n",
    "\n",
    "        percent_1 = round(up_dot_1 / 772 * 100, 2);\n",
    "        percent_2 = round(up_dot_2 / 772 * 100, 2);\n",
    "        percent_3 = round(up_dot_3 / 772 * 100, 2);\n",
    "        percent_4 = round(up_dot_4 / 772 * 100, 2);\n",
    "        percent_5 = round(up_dot_5 / 772 * 100, 2);\n",
    "        percent_6 = round(up_dot_6 / 772 * 100, 2);\n",
    "        percent_7 = round(up_dot_7 / 772 * 100, 2);\n",
    "        percent_8 = round(up_dot_8 / 772 * 100, 2);\n",
    "        percent_9 = round(up_dot_9 / 772 * 100, 2);\n",
    "        percent_10 = round(up_dot_10 / 772 * 100, 2);\n",
    "        percent_20 = round(up_dot_20 / 772 * 100, 2);\n",
    "        percent_30 = round(up_dot_30 / 772 * 100, 2);\n",
    "        percent_40 = round(up_dot_40 / 772 * 100, 2);\n",
    "        percent_50 = round(up_dot_50 / 772 * 100, 2);\n",
    "\n",
    "        # 등급 기준 1\n",
    "    # 편차의 합이 100 이상일 경우 +1, 400 이상일 경우 +2\n",
    "#     if(hap >= 100.0):\n",
    "#         grade += 1\n",
    "    if(swr_hap[i] <= 15500.0 or swr_hap[i] >= 16500.0):\n",
    "        grade += 1\n",
    "\n",
    "    # 등급 기준 2\n",
    "    # 편차의 절대값이 0.1 이상인 경우가 전체 데이터의 25% + 1, 30%를 넘을 경우 +1, 40%를 넘을 경우 +2, 50%를 넘길 경우 +3\n",
    "    if(percent_1 >= 25.0):\n",
    "        grade += 1\n",
    "\n",
    "#     if(percent_1 >= 30.0):\n",
    "#         grade += 1\n",
    "\n",
    "    if(percent_1 >= 40.0):\n",
    "        grade += 1\n",
    "\n",
    "#     if(percent_1 >= 50.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     if(percent_1 >= 60.0):\n",
    "#         grade += 1\n",
    "\n",
    "    # 등급 기준 3\n",
    "    # 편차의 절대값이 1 이상인 경우가 전체 데이터의 5%를 넘을 경우 +1, 10%를 넘을 경우 +2\n",
    "#     if(percent_10 >= 5.0):\n",
    "#         grade += 1\n",
    "    if(percent_10 >= 10.0):\n",
    "        grade += 1\n",
    "\n",
    "    wr.writerow([date[i], up_dot_1, up_dot_2, up_dot_3, up_dot_4, up_dot_5, up_dot_6, up_dot_7, up_dot_8, up_dot_9, up_dot_10, up_dot_20, up_dot_30, up_dot_40, up_dot_50, percent_1, percent_2, percent_3, percent_4, percent_5, percent_6, percent_7, percent_8, percent_9, percent_10, percent_20, percent_30, percent_40, percent_50, hap,swr_hap[i], avg, grade])\n",
    "w.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = open('naturalLight_classification_criteria_data_uvi.csv', 'w', encoding='utf-8')\n",
    "# wr = csv.writer(w)\n",
    "\n",
    "# row = ['date', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1','2', '3', '4', '5', 'percent_1', 'percent_2', 'percent_3', 'percent_4', 'percent_5', 'percent_6', 'percent_7', 'percent_8', 'percent_9', 'percent_10', 'percent_20', 'percent_30', 'percent_40', 'percent_50', 'hap', 'avg', 'grade']\n",
    "# wr.writerow(row)\n",
    "\n",
    "# for i in range(len(delta_uvi)):\n",
    "#     # 편차의 절대값이 0.1 ~ 5이상인 경우의 갯수 저장\n",
    "#     up_dot_1 = 0\n",
    "#     up_dot_2 = 0\n",
    "#     up_dot_3 = 0\n",
    "#     up_dot_4 = 0\n",
    "#     up_dot_5 = 0\n",
    "#     up_dot_6 = 0\n",
    "#     up_dot_7 = 0\n",
    "#     up_dot_8 = 0\n",
    "#     up_dot_9 = 0\n",
    "#     up_dot_10 = 0\n",
    "#     up_dot_20 = 0\n",
    "#     up_dot_30 = 0\n",
    "#     up_dot_40 = 0\n",
    "#     up_dot_50 = 0\n",
    "\n",
    "#     # 위의 갯수가 하루 전체 데이터에서 차지하는 비율 저장\n",
    "#     percent_1 = 0\n",
    "#     percent_2 = 0\n",
    "#     percent_3 = 0\n",
    "#     percent_4 = 0\n",
    "#     percent_5 = 0\n",
    "#     percent_6 = 0\n",
    "#     percent_7 = 0\n",
    "#     percent_8 = 0\n",
    "#     percent_9 = 0\n",
    "#     percent_10 = 0\n",
    "#     percent_20 = 0\n",
    "#     percent_30 = 0\n",
    "#     percent_40 = 0\n",
    "#     percent_50 = 0\n",
    "\n",
    "#     # 편차의 합, 평균, 등급 저장\n",
    "#     hap = 0\n",
    "#     avg = 0\n",
    "#     grade = 0\n",
    "\n",
    "#     for j in range(len(delta_uvi[i])):\n",
    "#         if(abs(delta_uvi[i][j]) >= 0.1):\n",
    "#             up_dot_1 += 1\n",
    "#         if(abs(delta_uvi[i][j]) >= 0.2):\n",
    "#             up_dot_2 += 1\n",
    "#         if(abs(delta_uvi[i][j]) >= 0.3):\n",
    "#             up_dot_3 += 1\n",
    "#         if(abs(delta_uvi[i][j]) >= 0.4):\n",
    "#             up_dot_4 += 1\n",
    "#         if(abs(delta_uvi[i][j]) >= 0.5):\n",
    "#             up_dot_5 += 1\n",
    "#         if(abs(delta_uvi[i][j]) >= 0.6):\n",
    "#             up_dot_6 += 1\n",
    "#         if(abs(delta_uvi[i][j]) >= 0.7):\n",
    "#             up_dot_7 += 1\n",
    "#         if(abs(delta_uvi[i][j]) >= 0.8):\n",
    "#             up_dot_8 += 1\n",
    "#         if(abs(delta_uvi[i][j]) >= 0.9):\n",
    "#             up_dot_9 += 1\n",
    "#         if(abs(delta_uvi[i][j]) >= 1):\n",
    "#             up_dot_10 += 1\n",
    "#         if(abs(delta_uvi[i][j] >= 2)):\n",
    "#             up_dot_20 += 1\n",
    "#         if(abs(delta_uvi[i][j] >= 3)):\n",
    "#             up_dot_30 += 1\n",
    "#         if(abs(delta_uvi[i][j] >= 4)):\n",
    "#             up_dot_40 += 1\n",
    "#         if(abs(delta_uvi[i][j] >= 5)):\n",
    "#             up_dot_50 += 1\n",
    "\n",
    "#         hap += abs(delta_uvi[i][j])\n",
    "#         avg = hap / 771\n",
    "\n",
    "#         percent_1 = round(up_dot_1 / 772 * 100, 2);\n",
    "#         percent_2 = round(up_dot_2 / 772 * 100, 2);\n",
    "#         percent_3 = round(up_dot_3 / 772 * 100, 2);\n",
    "#         percent_4 = round(up_dot_4 / 772 * 100, 2);\n",
    "#         percent_5 = round(up_dot_5 / 772 * 100, 2);\n",
    "#         percent_6 = round(up_dot_6 / 772 * 100, 2);\n",
    "#         percent_7 = round(up_dot_7 / 772 * 100, 2);\n",
    "#         percent_8 = round(up_dot_8 / 772 * 100, 2);\n",
    "#         percent_9 = round(up_dot_9 / 772 * 100, 2);\n",
    "#         percent_10 = round(up_dot_10 / 772 * 100, 2);\n",
    "#         percent_20 = round(up_dot_20 / 772 * 100, 2);\n",
    "#         percent_30 = round(up_dot_30 / 772 * 100, 2);\n",
    "#         percent_40 = round(up_dot_40 / 772 * 100, 2);\n",
    "#         percent_50 = round(up_dot_50 / 772 * 100, 2);\n",
    "\n",
    "#     # 등급 기준 1\n",
    "#     # 편차의 합이 100 이상일 경우 +1, 400 이상일 경우 +2\n",
    "# #     if(hap >= 100.0):\n",
    "# #         grade += 1\n",
    "#     if(hap >= 400.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     # 등급 기준 2\n",
    "#     # 편차의 절대값이 0.1 이상인 경우가 전체 데이터의 25% + 1, 30%를 넘을 경우 +1, 40%를 넘을 경우 +2, 50%를 넘길 경우 +3\n",
    "#     if(percent_1 >= 25.0):\n",
    "#         grade += 1\n",
    "\n",
    "# #     if(percent_1 >= 30.0):\n",
    "# #         grade += 1\n",
    "\n",
    "#     if(percent_1 >= 40.0):\n",
    "#         grade += 1\n",
    "\n",
    "# #     if(percent_1 >= 50.0):\n",
    "# #         grade += 1\n",
    "\n",
    "# #     if(percent_1 >= 60.0):\n",
    "# #         grade += 1\n",
    "\n",
    "#     # 등급 기준 3\n",
    "#     # 편차의 절대값이 1 이상인 경우가 전체 데이터의 5%를 넘을 경우 +1, 10%를 넘을 경우 +2\n",
    "# #     if(percent_10 >= 5.0):\n",
    "# #         grade += 1\n",
    "#     if(percent_10 >= 10.0):\n",
    "#         grade += 1\n",
    "\n",
    "#     wr.writerow([date[i], up_dot_1, up_dot_2, up_dot_3, up_dot_4, up_dot_5, up_dot_6, up_dot_7, up_dot_8, up_dot_9, up_dot_10, up_dot_20, up_dot_30, up_dot_40, up_dot_50, percent_1, percent_2, percent_3, percent_4, percent_5, percent_6, percent_7, percent_8, percent_9, percent_10, percent_20, percent_30, percent_40, percent_50, hap, avg, grade])\n",
    "#  w.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기상청 데이터 분류 (진행중)\n",
    "\n",
    "w = open('kma_witlab.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "# 1시간 단위로 cct, swr 저장\n",
    "cct_1hour = []\n",
    "swr_1hour = []\n",
    "\n",
    "for i in range(len(cct)):\n",
    "    temp = []\n",
    "    temp2 = []\n",
    "    for j in range(14):\n",
    "        temp.append(cct[i][0+55*j])\n",
    "        temp2.append(swr[i][0+55*j])\n",
    "    cct_1hour.append(temp)\n",
    "    swr_1hour.append(temp2)\n",
    "\n",
    "for i in range(len(cct)):\n",
    "    wr.writerow([cct_1hour[i][0], cct_1hour[i][1], cct_1hour[i][2], cct_1hour[i][3], cct_1hour[i][4], cct_1hour[i][5], cct_1hour[i][6], cct_1hour[i][7], cct_1hour[i][8], cct_1hour[i][9], cct_1hour[i][10], cct_1hour[i][11], cct_1hour[i][12], cct_1hour[i][13], swr_1hour[i][0], swr_1hour[i][1], swr_1hour[i][2], swr_1hour[i][3], swr_1hour[i][4], swr_1hour[i][5], swr_1hour[i][6], swr_1hour[i][7], swr_1hour[i][8], swr_1hour[i][9], swr_1hour[i][10], swr_1hour[i][11], swr_1hour[i][12], swr_1hour[i][13]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단파장의 raw data 면적\n",
    "w = open('naturalLight_classification_criteria_data_swr_area.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "row = ['date', 'area', '15500to', 'grade']\n",
    "wr.writerow(row)\n",
    "\n",
    "for i in range(len(swr)):\n",
    "    area = 0\n",
    "    for j in range(len(swr[i])):\n",
    "        area += swr[i][j]\n",
    "\n",
    "    to = abs(area-15500.0)\n",
    "    grade = 0\n",
    "    \n",
    "    if(to > 100):\n",
    "        grade += 1\n",
    "    if(to > 200):\n",
    "        grade += 1\n",
    "    if(to > 500):\n",
    "        grade += 1\n",
    "    if(to > 1000):\n",
    "        grade += 1\n",
    "    \n",
    "    wr.writerow([date[i], area, to, grade])\n",
    "w.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data = np.genfromtxt('./naturalLight_classification_criteria_data_cct.csv', delimiter=',', dtype='float')\n",
    "import_data2 = np.genfromtxt('./naturalLight_classification_criteria_data_cct_test.csv', delimiter=',', dtype='float')\n",
    "w = open('./cct_test.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range (1, len(import_data)):\n",
    "    wr.writerow(import_data[i][1:])\n",
    "for i in range(1, len(import_data2)):\n",
    "    wr.writerow(import_data[i][1:])\n",
    "w.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data = np.genfromtxt('./naturalLight_classification_criteria_data_swr.csv', delimiter=',', dtype='float')\n",
    "import_data2 = np.genfromtxt('./naturalLight_classification_criteria_data_swr_test.csv', delimiter=',', dtype='float')\n",
    "w = open('./swr_test.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range (1, len(import_data)):\n",
    "    wr.writerow(import_data[i][1:])\n",
    "for i in range(1, len(import_data2)):\n",
    "    wr.writerow(import_data[i][1:])\n",
    "w.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data = np.genfromtxt('./cct_swr.csv', delimiter=',', dtype='float')\n",
    "import_data2 = np.genfromtxt('./cct_swr_test.csv', delimiter=',', dtype='float')\n",
    "w = open('./swr_cct_test.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range (len(import_data)):\n",
    "    wr.writerow(import_data[i][:])\n",
    "for i in range(len(import_data2)):\n",
    "    wr.writerow(import_data2[i][:])\n",
    "w.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data = np.genfromtxt('./naturalLight_classification_criteria_data_swr_area.csv', delimiter=',', dtype='float')\n",
    "import_data2 = np.genfromtxt('./naturalLight_classification_criteria_data_swr_area_test.csv', delimiter=',', dtype='float')\n",
    "w = open('./swr_area_test.csv', 'w', encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range (1, len(import_data)):\n",
    "    wr.writerow(import_data[i][1:])\n",
    "for i in range(1, len(import_data2)):\n",
    "    wr.writerow(import_data[i][1:])\n",
    "w.close();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_data = np.genfromtxt('./rain_data_cct_swr_data.csv', delimiter=',', dtype='float')\n",
    "import_data2 = np.genfromtxt('./rain_data_cct_swr.csv', delimiter=',', dtype='float')\n",
    "w = open('./cct_swr_test.csv','w',encoding='utf-8')\n",
    "wr = csv.writer(w)\n",
    "\n",
    "for i in range(len(import_data)):\n",
    "    wr.writerow(import_data[i][1:])\n",
    "wr.writerow(import_data2[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텐서플로우 모델 생성 위한 import\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "# 초기값 선정 xavier 알고리즘\n",
    "def xavier_init(n_inputs, n_outputs, uniform=True):\n",
    "    \n",
    "    if uniform:\n",
    "        init_range = tf.sqrt(6.0 / (n_inputs + n_outputs))\n",
    "        return tf.random_uniform_initializer(-init_range, init_range)\n",
    "    else:\n",
    "        stddev = tf.sqrt(3.0 / (n_inputs + n_outputs))\n",
    "        return tf.truncated_normal_initializer(stddev=stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1705022\n",
      "1000 0.7436571\n",
      "2000 0.68247545\n",
      "3000 0.6490764\n",
      "4000 0.6262853\n",
      "5000 0.6090189\n",
      "6000 0.59515446\n",
      "7000 0.5836153\n",
      "8000 0.573778\n",
      "9000 0.565246\n",
      "10000 0.55774873\n",
      "11000 0.5510921\n",
      "12000 0.5451311\n",
      "13000 0.53975445\n",
      "14000 0.5348745\n",
      "15000 0.53042096\n",
      "16000 0.52633685\n",
      "17000 0.52257526\n",
      "18000 0.51909715\n",
      "19000 0.51586956\n",
      "20000 0.51286477\n",
      "21000 0.51005894\n",
      "22000 0.50743175\n",
      "23000 0.50496554\n",
      "24000 0.5026449\n",
      "25000 0.5004565\n",
      "26000 0.4983886\n",
      "27000 0.4964307\n",
      "28000 0.4945736\n",
      "29000 0.49280927\n",
      "30000 0.4911301\n",
      "31000 0.48952994\n",
      "32000 0.48800266\n",
      "33000 0.48654294\n",
      "34000 0.4851461\n",
      "35000 0.48380768\n",
      "36000 0.4825238\n",
      "37000 0.48129082\n",
      "38000 0.48010552\n",
      "39000 0.47896504\n",
      "40000 0.4778664\n",
      "41000 0.4768071\n",
      "42000 0.47578493\n",
      "43000 0.47479773\n",
      "44000 0.47384343\n",
      "45000 0.47292027\n",
      "46000 0.47202644\n",
      "47000 0.47116044\n",
      "48000 0.4703209\n",
      "49000 0.46950638\n",
      "50000 0.46871558\n",
      "-----------------------------\n",
      "[0] [0.0]\n",
      "[0] [0.0]\n",
      "[4] [3.0]\n",
      "[1] [0.0]\n",
      "[0] [0.0]\n",
      "[3] [1.0]\n",
      "[4] [4.0]\n",
      "[0] [1.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[1] [0.0]\n",
      "[4] [1.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[0] [1.0]\n",
      "[1] [1.0]\n",
      "[0] [0.0]\n",
      "[4] [1.0]\n",
      "[4] [2.0]\n",
      "[4] [4.0]\n",
      "[4] [4.0]\n",
      "[0] [0.0]\n",
      "[0] [1.0]\n",
      "[0] [1.0]\n",
      "[1] [1.0]\n",
      "[4] [4.0]\n",
      "[0] [0.0]\n",
      "[0] [1.0]\n",
      "[4] [4.0]\n",
      "[4] [3.0]\n",
      "[4] [2.0]\n",
      "[4] [4.0]\n",
      "[0] [1.0]\n",
      "[4] [3.0]\n",
      "[4] [4.0]\n",
      "[0] [1.0]\n",
      "[4] [4.0]\n",
      "accuracy =  54.054054054054056\n"
     ]
    }
   ],
   "source": [
    "# 단파장 학습 및 테스트\n",
    "import_data = np.genfromtxt('./naturalLight_classification_criteria_data_cct.csv', delimiter=',', dtype='float')\n",
    "date = np.genfromtxt('./test_date.csv', delimiter=',', dtype='str')\n",
    "import_data2 = np.genfromtxt('./naturalLight_classification_criteria_data_cct_test.csv', delimiter=',', dtype='float')\n",
    "\n",
    "x_data = import_data[1:, 1:12]\n",
    "y_data = []\n",
    "\n",
    "test_x = import_data2[1:, 1:12]\n",
    "test_y = []\n",
    "\n",
    "for i in range(1, len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][26])\n",
    "    y_data.append(temp)\n",
    "\n",
    "for i in range(1, len(import_data2)):\n",
    "    temp = []\n",
    "    temp.append(import_data2[i][26])\n",
    "    test_y.append(temp)\n",
    "    \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "test_x = scaler.fit_transform(test_x)\n",
    "\n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 11])\n",
    "Y = tf.placeholder(\"float\", [None, 5])\n",
    "nb_classes = 5\n",
    "\n",
    "# Xavier Initializer 추가 코드\n",
    "W = tf.get_variable(\"W\", shape=[11, nb_classes], initializer=xavier_init(11, nb_classes))\n",
    "b = tf.Variable(tf.zeros([nb_classes]))\n",
    "\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# W = tf.Variable(tf.random_normal([11, nb_classes]), name='weight')\n",
    "# b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    accuracy = 0\n",
    "    \n",
    "    for step in range(50001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 1000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "            \n",
    "    print('-----------------------------')\n",
    "    \n",
    "    for i in range(len(test_x)):\n",
    "        a = sess.run(H, feed_dict={X:[test_x[i]]})\n",
    "        print(sess.run(tf.argmax(a, 1)), test_y[i])\n",
    "        if(sess.run(tf.argmax(a, 1)) == test_y[i]):\n",
    "            accuracy += 1\n",
    "    print(\"accuracy = \", float(accuracy / len(test_x) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4979215\n",
      "10000 0.60111153\n",
      "20000 0.5400761\n",
      "30000 0.50621045\n",
      "40000 0.483115\n",
      "50000 0.46590185\n",
      "-----------------------------\n",
      "[0] [0]\n",
      "[2] [0]\n",
      "[3] [2]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[2] [1]\n",
      "[3] [3]\n",
      "[2] [0]\n",
      "[3] [2]\n",
      "[4] [4]\n",
      "[2] [0]\n",
      "[2] [2]\n",
      "[4] [3]\n",
      "[4] [3]\n",
      "[1] [1]\n",
      "[2] [1]\n",
      "[0] [0]\n",
      "[2] [2]\n",
      "[3] [2]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[2] [0]\n",
      "[0] [0]\n",
      "[1] [1]\n",
      "[2] [2]\n",
      "[4] [4]\n",
      "[0] [0]\n",
      "[2] [1]\n",
      "[4] [3]\n",
      "[2] [2]\n",
      "[3] [2]\n",
      "[4] [3]\n",
      "[0] [1]\n",
      "[3] [3]\n",
      "[4] [3]\n",
      "[1] [1]\n",
      "[4] [3]\n",
      "accuracy =  48.64864864864865\n"
     ]
    }
   ],
   "source": [
    "# 단파장 학습 및 테스트\n",
    "import_data = np.genfromtxt('./naturalLight_classification_criteria_data_swr.csv', delimiter=',', dtype='int')\n",
    "date = np.genfromtxt('./test_date.csv', delimiter=',', dtype='str')\n",
    "import_data2 = np.genfromtxt('./naturalLight_classification_criteria_data_swr_test.csv', delimiter=',', dtype='int')\n",
    "\n",
    "x_data = import_data[1:, 1:15]\n",
    "y_data = []\n",
    "\n",
    "test_x = import_data2[1:, 1:15]\n",
    "test_y = []\n",
    "\n",
    "for i in range(1, len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][32])\n",
    "    y_data.append(temp)\n",
    "    \n",
    "for i in range(1, len(import_data2)):\n",
    "    temp = []\n",
    "    temp.append(import_data2[i][32])\n",
    "    test_y.append(temp)\n",
    "    \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "test_x = scaler.fit_transform(test_x)\n",
    "\n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 14])\n",
    "Y = tf.placeholder(\"float\", [None, 5])\n",
    "nb_classes = 5\n",
    "\n",
    "# Xavier Initializer 추가 코드\n",
    "W = tf.get_variable(\"W\", shape=[14, nb_classes], initializer=xavier_init(14, nb_classes))\n",
    "b = tf.Variable(tf.zeros([nb_classes]))\n",
    "\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# W = tf.Variable(tf.random_normal([14, nb_classes]), name='weight')\n",
    "# b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    accuracy = 0\n",
    "    \n",
    "    for step in range(50001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 10000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "            \n",
    "    print('-----------------------------')\n",
    "    \n",
    "    for i in range(len(test_x)):\n",
    "        a = sess.run(H, feed_dict={X:[test_x[i]]})\n",
    "        print(sess.run(tf.argmax(a, 1)), test_y[i])\n",
    "        if(sess.run(tf.argmax(a, 1)) == test_y[i]):\n",
    "            accuracy += 1\n",
    "    print(\"accuracy = \", float(accuracy / len(test_x) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.322031\n",
      "5000 0.36044064\n",
      "10000 0.29982528\n",
      "15000 0.26863167\n",
      "20000 0.24785219\n",
      "25000 0.23236698\n",
      "30000 0.22008914\n",
      "35000 0.20996393\n",
      "40000 0.201383\n",
      "45000 0.19396074\n",
      "50000 0.18743792\n",
      "-----------------------------\n",
      "[1]\n",
      "[1]\n",
      "[4]\n",
      "[0]\n",
      "[1]\n",
      "[4]\n",
      "[4]\n",
      "[0]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[1]\n",
      "[4]\n",
      "[4]\n",
      "[1]\n",
      "[4]\n",
      "[1]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "# uvb 학습 및 테스트\n",
    "import_data = np.genfromtxt('./naturalLight_classification_criteria_data_uvb.csv', delimiter=',', dtype='int')\n",
    "import_data2 = np.genfromtxt('./naturalLight_classification_criteria_data_uvb_test.csv', delimiter=',', dtype='int')\n",
    "\n",
    "x_data = import_data[1:, 1:11]\n",
    "y_data = []\n",
    "\n",
    "test_x = import_data2[1:, 1:11]\n",
    "\n",
    "for i in range(1, len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][23])\n",
    "    y_data.append(temp)\n",
    "    \n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "test_x = scaler.fit_transform(test_x)\n",
    "\n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 10])\n",
    "Y = tf.placeholder(\"float\", [None, 5])\n",
    "nb_classes = 5\n",
    "\n",
    "W = tf.Variable(tf.random_normal([10, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    accuracy = 0\n",
    "    \n",
    "    for step in range(50001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 5000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "            \n",
    "    print('-----------------------------')\n",
    "    \n",
    "    for i in range(len(test_x)):\n",
    "        a = sess.run(H, feed_dict={X:[test_x[i]]})\n",
    "        print(sess.run(tf.argmax(a, 1)), test_y[i])\n",
    "        if(sess.run(tf.argmax(a, 1)) == test_y[i]):\n",
    "            accuracy += 1\n",
    "    print(\"accuracy = \", float(accuracy / len(test_x) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.5656818\n",
      "10000 0.46358883\n",
      "20000 0.38603136\n",
      "30000 0.3425974\n",
      "40000 0.31252843\n",
      "50000 0.28970394\n",
      "-----------------------------\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[2] [2]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[1] [1]\n",
      "[2] [2]\n",
      "[1] [0]\n",
      "[3] [2]\n",
      "[4] [4]\n",
      "[1] [0]\n",
      "[1] [1]\n",
      "[4] [2]\n",
      "[4] [2]\n",
      "[1] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[1] [1]\n",
      "[3] [1]\n",
      "[4] [3]\n",
      "[4] [4]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[1] [1]\n",
      "[4] [3]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[3] [2]\n",
      "[2] [1]\n",
      "[2] [1]\n",
      "[3] [2]\n",
      "[0] [0]\n",
      "[2] [2]\n",
      "[4] [3]\n",
      "[1] [0]\n",
      "[2] [2]\n",
      "accuracy =  43.24324324324324\n"
     ]
    }
   ],
   "source": [
    "# 단파장, 색온도 학습 및 테스트\n",
    "import_data = np.genfromtxt('./cct_swr.csv', delimiter=',', dtype='int')\n",
    "date = np.genfromtxt('./test_date.csv', delimiter=',', dtype='str')\n",
    "import_data2 = np.genfromtxt('./cct_swr_test.csv', delimiter=',', dtype='int')\n",
    "\n",
    "x_data = import_data[:, :25]\n",
    "y_data = []\n",
    "\n",
    "test_x = import_data2[:, :25]\n",
    "test_y = []\n",
    "\n",
    "for i in range(len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data[i][25])\n",
    "    y_data.append(temp)\n",
    "    \n",
    "for i in range(len(import_data2)):\n",
    "    temp = []\n",
    "    temp.append(import_data2[i][25])\n",
    "    test_y.append(temp)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "test_x = scaler.fit_transform(test_x)\n",
    "\n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 25])\n",
    "Y = tf.placeholder(\"float\", [None, 5])\n",
    "nb_classes = 5\n",
    "\n",
    "# Xavier Initializer 추가 코드\n",
    "W = tf.get_variable(\"W\", shape=[25, nb_classes], initializer=xavier_init(25, nb_classes))\n",
    "b = tf.Variable(tf.zeros([nb_classes]))\n",
    "\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# W = tf.Variable(tf.random_normal([25, nb_classes]), name='weight')\n",
    "# b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    accuracy = 0\n",
    "    \n",
    "    for step in range(50001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 10000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "            \n",
    "    print('-----------------------------')\n",
    "    \n",
    "    for i in range(len(test_x)):\n",
    "        a = sess.run(H, feed_dict={X:[test_x[i]]})\n",
    "        print(sess.run(tf.argmax(a, 1)), test_y[i])\n",
    "        if(sess.run(tf.argmax(a, 1)) == test_y[i]):\n",
    "            accuracy += 1\n",
    "    print(\"accuracy = \", float(accuracy / len(test_x) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.544451\n",
      "10000 1.0584091\n",
      "20000 0.976461\n",
      "30000 0.92648697\n",
      "40000 0.8904095\n",
      "50000 0.8620344\n",
      "60000 0.83858925\n",
      "70000 0.81860334\n",
      "80000 0.80119556\n",
      "90000 0.78579026\n",
      "100000 0.7719943\n",
      "110000 0.759518\n",
      "120000 0.7481449\n",
      "130000 0.73770845\n",
      "140000 0.7280848\n",
      "150000 0.71916175\n",
      "-----------------------------\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [2]\n",
      "[1] [1]\n",
      "[4] [3]\n",
      "[4] [3]\n",
      "[4] [4]\n",
      "[4] [3]\n",
      "[4] [3]\n",
      "[4] [4]\n",
      "[1] [2]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [3]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [3]\n",
      "[4] [3]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [3]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "[4] [3]\n",
      "[4] [4]\n",
      "[4] [4]\n",
      "accuracy =  70.27027027027027\n"
     ]
    }
   ],
   "source": [
    "# 단파장 면적 학습 및 테스트\n",
    "import_data = np.genfromtxt('./naturalLight_classification_criteria_data_swr_area.csv', delimiter=',', dtype='float')\n",
    "import_data_y = np.genfromtxt('./naturalLight_classification_criteria_data_swr_area.csv', delimiter=',', dtype='int')\n",
    "date = np.genfromtxt('./test_date.csv', delimiter=',', dtype='str')\n",
    "import_data2 = np.genfromtxt('./naturalLight_classification_criteria_data_swr_area_test.csv', delimiter=',', dtype='float')\n",
    "import_data2_y = np.genfromtxt('./naturalLight_classification_criteria_data_swr_area_test.csv', delimiter=',', dtype='int')\n",
    "\n",
    "x_data = import_data[1:, 1:3]\n",
    "y_data = []\n",
    "\n",
    "test_x = import_data2[1:, 1:3]\n",
    "test_y = []\n",
    "\n",
    "for i in range(1, len(import_data)):\n",
    "    temp = []\n",
    "    temp.append(import_data_y[i][3])\n",
    "    y_data.append(temp)\n",
    "    \n",
    "for i in range(1, len(import_data2)):\n",
    "    temp = []\n",
    "    temp.append(import_data2_y[i][3])\n",
    "    test_y.append(temp)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "test_x = scaler.fit_transform(test_x)\n",
    "\n",
    "y_data = ohe.fit_transform(y_data)\n",
    "y_data = y_data.toarray();\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 2])\n",
    "Y = tf.placeholder(\"float\", [None, 5])\n",
    "nb_classes = 5\n",
    "\n",
    "# Xavier Initializer 추가 코드\n",
    "# W = tf.get_variable(\"W\", shape=[2, nb_classes], initializer=xavier_init(2, nb_classes))\n",
    "# b = tf.Variable(tf.zeros([nb_classes]))\n",
    "\n",
    "# H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "H = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(H), axis=1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "tf.summary.scalar('cost', cost)\n",
    "summary = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    accuracy = 0\n",
    "    \n",
    "    for step in range(150001):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 10000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={X:x_data, Y:y_data}))\n",
    "            \n",
    "    print('-----------------------------')\n",
    "    \n",
    "    for i in range(len(test_x)):\n",
    "        a = sess.run(H, feed_dict={X:[test_x[i]]})\n",
    "        print(sess.run(tf.argmax(a, 1)), test_y[i])\n",
    "        if(sess.run(tf.argmax(a, 1)) == test_y[i]):\n",
    "            accuracy += 1\n",
    "    print(\"accuracy = \", float(accuracy / len(test_x) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
