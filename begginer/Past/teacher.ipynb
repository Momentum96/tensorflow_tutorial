{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 그래프 외부에 출력\n",
    "%matplotlib tk\n",
    "\n",
    "tf.set_random_seed(777)  # 어느 컴퓨터에서 이 코드를 실행해도 학습 방향이 같도록, 다시 수행해도 같도록\n",
    "\n",
    "if \"DISPLAY\" not in os.environ:\n",
    "    # remove Travis CI Error\n",
    "    matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30, 1)\n",
      "(5, 30, 1)\n",
      "(5, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "# train Parameters\n",
    "seq_length = 5\n",
    "data_dim = 2\n",
    "hidden_dim = 10\n",
    "output_dim = 1\n",
    "learning_rate = 0.01\n",
    "iterations =30\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1)) # 데이터 일반화\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1)) # 데이터 일반화\n",
    "\n",
    "xy = np.loadtxt('./teacher_data/train_data_v2_index.csv', delimiter=',')\n",
    "\n",
    "x = scaler.fit_transform(xy[:, 0:-1])\n",
    "y = scaler2.fit_transform(xy[:, [-1]]) \n",
    "\n",
    "# build a dataset\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "# for i in range(0, len(x) - seq_length): # 한 행씩 dataX, Y에 추가\n",
    "#     _x = x[i:i + seq_length]\n",
    "#     _y = y[i + seq_length]  # Next close price\n",
    "#     dataX.append(_x)\n",
    "#     dataY.append(_y)\n",
    "\n",
    "for i in range(0, seq_length):\n",
    "    tmp12 = []\n",
    "    tmp122 = []\n",
    "    for j in range(0, 30):\n",
    "        tmp1 = x[j+((i*30)%150), 0:-1]\n",
    "        tmp2 = y[j+((i*30)%150), [-1]]\n",
    "        tmp12.append(tmp1)\n",
    "        tmp122.append(tmp2)\n",
    "    dataX.append(tmp12)\n",
    "    dataY.append(tmp122)\n",
    "    \n",
    "xy2 = np.loadtxt('./teacher_data/test_data_v2_index.csv', delimiter=',') # 예측할 날짜\n",
    "\n",
    "x2 = scaler.fit_transform(xy2) # 데이터 없을때 (데이터란 ptmt 값)\n",
    "# x2 = scaler.fit_transform(xy2[:, 0:-1]) # 데이터 있을때\n",
    "# y2 = scaler2.fit_transform(xy2[:, [-1]]) #데이터 있을때\n",
    "\n",
    "dataX2 = []\n",
    "\n",
    "# dataY2 = [] #데이터 있을때\n",
    "for i in range(0, len(x2) - seq_length):\n",
    "    _x2 = x2[i:i+seq_length]\n",
    "#     _y2 = y2[i+seq_length] #데이터 있을때\n",
    "    dataX2.append(_x2)\n",
    "#     dataY2.append(_y2) #데이터 있을때\n",
    "\n",
    "# train/test split\n",
    "\n",
    "train_size = len(dataX)\n",
    "test_size = len(dataX2)\n",
    "\n",
    "# print(len(dataX))\n",
    "# print(len(dataX2))\n",
    "\n",
    "trainX, testX = np.array(dataX[0:train_size]),np.array(dataX2[0:test_size])\n",
    "trainY = np.array(dataY[0:train_size])\n",
    "\n",
    "print(np.shape(trainX))\n",
    "print(np.shape(trainY))\n",
    "print(np.shape(testX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gw/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, data_dim])\n",
    "Y = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "# build a LSTM network\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(\n",
    "    num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "Y_pred = tf.contrib.layers.fully_connected(\n",
    "    outputs[:, -1], output_dim, activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "# cost/loss\n",
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))  # sum of the squares\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0] loss: 2022.7044677734375\n",
      "[step: 1] loss: 1363.018798828125\n",
      "[step: 2] loss: 895.7305908203125\n",
      "[step: 3] loss: 606.277587890625\n",
      "[step: 4] loss: 482.8088073730469\n",
      "[step: 5] loss: 483.0735778808594\n",
      "[step: 6] loss: 536.4558715820312\n",
      "[step: 7] loss: 573.4605712890625\n",
      "[step: 8] loss: 575.3316040039062\n",
      "[step: 9] loss: 552.8365478515625\n",
      "[step: 10] loss: 521.30810546875\n",
      "[step: 11] loss: 491.998046875\n",
      "[step: 12] loss: 470.81927490234375\n",
      "[step: 13] loss: 459.4259338378906\n",
      "[step: 14] loss: 456.6819152832031\n",
      "[step: 15] loss: 459.95147705078125\n",
      "[step: 16] loss: 466.11016845703125\n",
      "[step: 17] loss: 472.32464599609375\n",
      "[step: 18] loss: 476.5727233886719\n",
      "[step: 19] loss: 477.86016845703125\n",
      "[step: 20] loss: 476.1408996582031\n",
      "[step: 21] loss: 472.0621337890625\n",
      "[step: 22] loss: 466.6416320800781\n",
      "[step: 23] loss: 460.97039794921875\n",
      "[step: 24] loss: 455.985595703125\n",
      "[step: 25] loss: 452.32708740234375\n",
      "[step: 26] loss: 450.2729797363281\n",
      "[step: 27] loss: 449.74725341796875\n",
      "[step: 28] loss: 450.3902587890625\n",
      "[step: 29] loss: 451.6761779785156\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (0,) for Tensor 'Placeholder:0', which has shape '(?, 100, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-14d628765c87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[step: {}] loss: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Test step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtest_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1114\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1116\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1117\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (0,) for Tensor 'Placeholder:0', which has shape '(?, 100, 2)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training step\n",
    "    for i in range(iterations):\n",
    "        _, step_loss = sess.run([train, loss], feed_dict={\n",
    "                                X: trainX, Y: trainY})\n",
    "        print(\"[step: {}] loss: {}\".format(i, step_loss))\n",
    "    # Test step\n",
    "    test_predict = sess.run(Y_pred, feed_dict={X: testX})\n",
    "    \n",
    "    test_predict = scaler2.inverse_transform(test_predict)\n",
    "#     dataY2 = scaler2.inverse_transform(dataY2) # 데이터 있을때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.plot(dataY2, label='row data') # 데이터 있을때\n",
    "time = xy2[:, 1];\n",
    "\n",
    "# plt.scatter(time, test_predict, label='predict')\n",
    "# plt.xlabel(\"Time Period\")\n",
    "# plt.ylabel(\"photometric\")\n",
    "# plt.xticks(np.arange(9, 19, step=1), ['9:00','10:00','11:00','12:00','13:00','14:00','15:00','16:00','17:00','18:00']) # v2 모델\n",
    "# # plt.ylabel(\"cct\")\n",
    "# plt.grid(True)\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_y = []\n",
    "\n",
    "for i in range(len(test_predict)):\n",
    "    bar_y.append(test_predict[i][0])\n",
    "\n",
    "plt.bar(time, bar_y, tick_label=('9:00','10:00','11:00','12:00','13:00','14:00','15:00','16:00','17:00','18:00'), align='center', color='green');\n",
    "plt.ylim(0, 1000)\n",
    "plt.xlabel(\"Time Period\")\n",
    "plt.ylabel(\"photometric\")\n",
    "# plt.twiny()\n",
    "plt.twinx()\n",
    "plt.plot(time, bar_y, 'r.-')\n",
    "plt.ylim(0, 1000)\n",
    "plt.title(\"predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
