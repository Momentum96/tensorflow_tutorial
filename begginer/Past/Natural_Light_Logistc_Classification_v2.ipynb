{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10808,)\n"
     ]
    }
   ],
   "source": [
    "# UVI 데이터 가져오기\n",
    "# UVI 배열에 저장\n",
    "\n",
    "import_data = np.loadtxt('./classification_v2/ForClassification_v2.csv', delimiter=',')\n",
    "import_UVI = import_data[:]\n",
    "\n",
    "import_data2 = np.loadtxt('./classification_v2/test_data.csv', delimiter=',')\n",
    "import_test = import_data2[:]\n",
    "\n",
    "import_y = np.loadtxt('./classification_v2/ydata.csv', delimiter=',')\n",
    "\n",
    "print(np.shape(import_test))\n",
    "\n",
    "UVI = []\n",
    "test_UVI = []\n",
    "y_data = []\n",
    "\n",
    "for i in range(88):\n",
    "    UVI.append(import_UVI[i*772:(i+1)*772])\n",
    "    y_data.append(import_y[i:i+1])\n",
    "\n",
    "for i in range((int)(len(import_test)/772)):\n",
    "    test_UVI.append(import_test[i*772:(i+1)*772])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "UVI_scaler = scaler.fit_transform(UVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분별 UVI의 변화율 계산\n",
    "# delta_UVI에 저장\n",
    "\n",
    "delta_UVI = []\n",
    "delta_UVI_test = []\n",
    "\n",
    "for i in range(len(UVI)):\n",
    "    temp = []\n",
    "    for j in range(771):\n",
    "        temp.append((UVI[i][j+1] - UVI[i][j]))\n",
    "    delta_UVI.append(temp)\n",
    "\n",
    "for i in range(len(test_UVI)):\n",
    "    temp = []\n",
    "    for j in range(771):\n",
    "        temp.append(test_UVI[i][j+1]-test_UVI[i][j])\n",
    "    delta_UVI_test.append(temp)\n",
    "    \n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "train_data = scaler2.fit_transform(delta_UVI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습시킬 UVI 데이터 분별하여 라벨링\n",
    "# x_data = UVI 변화율 데이터\n",
    "# y_data = 흐린날, 맑은날 (0, 1)\n",
    "# 맑은날 8, 흐린날 8\n",
    "\n",
    "# test 1\n",
    "# x_data = [delta_UVI[8], delta_UVI[19], delta_UVI[42], delta_UVI[54], delta_UVI[57], delta_UVI[66], delta_UVI[78], delta_UVI[83], delta_UVI[11], delta_UVI[16],\n",
    "#          delta_UVI[17], delta_UVI[18], delta_UVI[21], delta_UVI[22], delta_UVI[24], delta_UVI[26]]\n",
    "# y_data = [[1],[1],[1],[1],[1],[1],[1],[1],[0],[0],[0],[0],[0],[0],[0],[0]]\n",
    "\n",
    "# test_x_data = [delta_UVI[0], delta_UVI[1], delta_UVI[2], delta_UVI[3], delta_UVI[4], delta_UVI[5], delta_UVI[6], delta_UVI[7]]\n",
    "# test_y_data = [[1], [1], [0], [0], [1], [1], [0], [1]]\n",
    "\n",
    "# test2\n",
    "# x_data = []\n",
    "# for i in range(30):\n",
    "#     x_data.append(delta_UVI[i])\n",
    "# y_data = [[1], [1], [0], [0], [1], [1], [0], [1], [1], [0]\n",
    "#           , [0], [0], [0], [0], [1], [0], [0], [0], [0], [1]\n",
    "#          , [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]\n",
    "\n",
    "# test_x_data = []\n",
    "# for i in range(30, 40):\n",
    "#     test_x_data.append(delta_UVI[i])\n",
    "# test_y_data = [[0], [1], [0], [0], [1], [0], [0], [0], [0], [1]]\n",
    "   \n",
    "# test 3    \n",
    "# x_data = []\n",
    "# for i in range(30):\n",
    "#     x_data.append(UVI_scaler[i])\n",
    "# y_data = [[1], [1], [0], [0], [1], [1], [0], [1], [1], [0]\n",
    "#           , [0], [0], [0], [0], [1], [0], [0], [0], [0], [1]\n",
    "#          , [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]\n",
    "\n",
    "# test_x_data = []\n",
    "# for i in range(30, 40):\n",
    "#     test_x_data.append(UVI_scaler[i])\n",
    "# test_y_data = [[0], [1], [0], [0], [1], [0], [0], [0], [0], [1]]\n",
    "\n",
    "# test 4\n",
    "# x_data = [UVI_scaler[8], UVI_scaler[19], UVI_scaler[42], UVI_scaler[54], UVI_scaler[57], UVI_scaler[66], UVI_scaler[78], UVI_scaler[83], UVI_scaler[11], UVI_scaler[16],\n",
    "#          UVI_scaler[17], UVI_scaler[18], UVI_scaler[21], UVI_scaler[22], UVI_scaler[24], UVI_scaler[26]]\n",
    "# y_data = [[1],[1],[1],[1],[1],[1],[1],[1],[0],[0],[0],[0],[0],[0],[0],[0]]\n",
    "\n",
    "# test 5\n",
    "# x_data = []\n",
    "# for i in range(len(UVI_scaler)):\n",
    "#     x_data.append(UVI_scaler[i])\n",
    "\n",
    "# test_x_data = []\n",
    "# for i in range(30):\n",
    "#     test_x_data.append(UVI_scaler[i])\n",
    "# test_y_data = [[1], [1], [0], [0], [1], [1], [0], [1], [1], [0]\n",
    "#           , [0], [0], [0], [0], [1], [0], [0], [0], [0], [1]\n",
    "#          , [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]\n",
    "\n",
    "#test 6\n",
    "x_data = []\n",
    "for i in range(len(delta_UVI)):\n",
    "    x_data.append(delta_UVI[i])\n",
    "\n",
    "# test_x_data = []\n",
    "# for i in range(30):\n",
    "#     test_x_data.append(delta_UVI[i])\n",
    "# test_y_data = [[1], [1], [0], [0], [1], [1], [0], [1], [1], [0]\n",
    "#           , [0], [0], [0], [0], [1], [0], [0], [0], [0], [1]\n",
    "#          , [0], [0], [0], [0], [0], [0], [0], [0], [0], [0]]\n",
    "\n",
    "test_x_data=[]\n",
    "for i in range(len(delta_UVI_test)):\n",
    "    test_x_data.append(delta_UVI_test[i])\n",
    "test_y_data = [[0], [0], [0], [0], [1], [0], [0], [1], [0], [0], [1], [0], [0], [0]]\n",
    "        \n",
    "X = tf.placeholder(tf.float32, shape=[None, 771])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([771, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "H = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(H) + (1 - Y) * tf.log(1 - H))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.001).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(H > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.9824822\n",
      "2000 1.5805168\n",
      "4000 1.3421054\n",
      "6000 1.182479\n",
      "8000 1.0573403\n",
      "10000 0.9623427\n",
      "12000 0.888228\n",
      "14000 0.8265639\n",
      "16000 0.7726717\n",
      "18000 0.7245146\n",
      "20000 0.68092996\n",
      "22000 0.64091426\n",
      "24000 0.60374886\n",
      "26000 0.5691147\n",
      "28000 0.53703785\n",
      "30000 0.5076776\n",
      "32000 0.48105204\n",
      "34000 0.4568778\n",
      "36000 0.4347208\n",
      "38000 0.41418716\n",
      "40000 0.39499846\n",
      "42000 0.37696216\n",
      "44000 0.3599511\n",
      "46000 0.34387672\n",
      "48000 0.32867548\n",
      "50000 0.31430465\n",
      "52000 0.3007237\n",
      "54000 0.28790772\n",
      "56000 0.27582064\n",
      "58000 0.2644342\n",
      "60000 0.2537216\n",
      "62000 0.2436481\n",
      "64000 0.23416883\n",
      "66000 0.22525142\n",
      "68000 0.21686329\n",
      "70000 0.20896946\n",
      "72000 0.20153493\n",
      "74000 0.1945283\n",
      "76000 0.18791848\n",
      "78000 0.18168479\n",
      "80000 0.17579812\n",
      "82000 0.17023231\n",
      "84000 0.16496696\n",
      "86000 0.15998687\n",
      "88000 0.15526949\n",
      "90000 0.15079556\n",
      "92000 0.14655122\n",
      "94000 0.14252353\n",
      "96000 0.13869387\n",
      "98000 0.13505171\n",
      "100000 0.1315844\n",
      "\n",
      "Hypothesis (sigmoid output)\n",
      "  [[1.0000000e+00]\n",
      " [9.8355931e-01]\n",
      " [3.9398903e-03]\n",
      " [5.0664499e-02]\n",
      " [3.4165643e-02]\n",
      " [9.9814332e-01]\n",
      " [8.4520590e-01]\n",
      " [8.1970471e-01]\n",
      " [2.8658481e-04]\n",
      " [5.6531392e-03]\n",
      " [9.9998260e-01]\n",
      " [1.0000000e+00]\n",
      " [1.6253031e-04]\n",
      " [9.5360225e-01]] \n",
      "\n",
      "test_y_data [[0], [0], [0], [0], [1], [0], [0], [1], [0], [0], [1], [0], [0], [0]] \n",
      "\n",
      "Correct (predicted data)\n",
      "  [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]] \n",
      "\n",
      "Accuracy (정확도) :  0.5\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(100001):\n",
    "        cost_val, _ = sess.run([cost, train], feed_dict={X:x_data, Y:y_data})\n",
    "        if step % 2000 == 0:\n",
    "            print(step, cost_val)\n",
    "            jY:y_data})\n",
    "    h, c, a = sess.run([H,predicted, accuracy], feed_dict={X:test_x_data, Y:test_y_data})\n",
    "#     print(\"\\nHypothesis (sigmoid output)\\n \", h, \"\\n\\ntest_y_data\", y_data, \"\\n\\nCorrect (predicted data)\\n \", c, \"\\n\\nAccuracy (정확도) : \", a)\n",
    "#     print(\"\\nHypothesis (sigmoid output)\\n \", h, \"\\n\\ntest_y_data\", import_y, \"\\n\\nCorrect (predicted data)\\n \", c, \"\\n\\nAccuracy (정확도) : \", a)\n",
    "    print(\"\\nHypothesis (sigmoid output)\\n \", h, \"\\n\\ntest_y_data\", test_y_data, \"\\n\\nCorrect (predicted data)\\n \", c, \"\\n\\nAccuracy (정확도) : \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
